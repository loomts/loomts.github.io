[{"content":"Reed-Solomon 是 目前工业界最常用的纠删码（Erasure Code）之一，本文主要讲述其在存储领域如何进行数据容错，并且附带简要实现思路。\nReed-Solomon 原理 Reed-Solomon 通过数据冗余实现容错，并且根据冗余数据的大小实现与其一致的容错。\n比如我有两个数字 1 和 2，那么可以通过构造出 3 = 1 + 2，并将其存储起来，就能在某个数字丢失的时候将 3 取出并恢复原来的数字。假设数字 1 丢失了，那么可以通过 3-2 = 1 的方式重新得到正确的数据。\n上面通过简单相加的过程实现了最简单的数据冗余，但怎么实现更强的容错呢？我们可以设定不一样的系数。比如令 x = 1, y = 2，那么可以通过构造不同的系数得到不同的冗余数据，下面随便举几个例子。\n$$0 \\times x + 0 \\times y = 0$$ $$0 \\times x + 1 \\times y = 2$$ $$1 \\times x + 0 \\times y = 1$$ $$1 \\times x + 2 \\times y = 5$$ $$2 \\times x + 1 \\times y = 4$$\n当 x 丢失的时候，我们可以发现公式 1、2 无法为重构 x 提供帮助的，因为其系数为 0，冗余的值与 x 线性无关。\n所以，正常情况下，我们需要尽可能地保证方程要包含所有数据块的信息。\n P.S. XORing Elephants: Novel Erasure Codes for Big Data 论文中的 LRCs 能够通过构造两个半数线性无关的行列式，通过 14%的追加冗余，提高近乎两倍的数据恢复效率\n 但是我们需要对现实中计算机存储的数据冗余，这又要如何做到呢？\n首先，我们知道计算机存储的数据都是由 0 和 1 组成的，因此可以对文件读进内存，并且以 byte 为单位对数据本身进行计算。\nRS 的冗余计算方式是将文件切成 K 个数据块（data shards），假设 N 个数据块排成一列，通过对数据从开头到结尾进行多项式计算来生成 M 个校验块（parity shards），这样得到的校验块就包含了 N 个数据块的信息。\n刚刚提到的“对数据从开头到结尾进行多项式计算”，其实就是用线性代数的知识对矩阵进行简单的加减乘除。\n首先是编码矩阵的选取，常见的有 Vandermonde 和 Cauchy，klauspost/rs 的默认实现是 Vandermonde 矩阵，通过将其与上半部分（k*k）的逆矩阵相乘得到（k* k）的单位矩阵和（m*k）的下半部分矩阵。\n$$ \\begin{bmatrix} 1 \u0026 1 \u0026 1 \u0026 \\dots \u0026 1 \\\\ 1 \u0026 2 \u0026 2^2 \u0026 \\dots \u0026 2^{k-1} \\\\ 1 \u0026 3 \u0026 3^2 \u0026 \\dots \u0026 3^{k-1} \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 1 \u0026 k+m \u0026 (k+m)^2 \u0026 \\dots \u0026 (k+m)^{k-1} \\end{bmatrix} \\Longrightarrow \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 \\dots \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 \\dots \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 \\dots \u0026 0 \\\\ \\vdots \u0026 \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ 0 \u0026 0 \u0026 0 \u0026 \\dots \u0026 1 \\\\ \\alpha \u0026 \\beta \u0026 \\gamma \u0026 \\dots \u0026 \\delta \\\\ \\epsilon \u0026 \\zeta \u0026 \\eta \u0026 \\dots \u0026 \\theta \\end{bmatrix} $$\n得到编码矩阵后，将其与数据块相乘，就能得到校验块。\n但是如果直接相乘，就会导致一个问题：因为 K 个 1byte 数据的行列式计算结果很有可能会大于 1byte，导致校验块的大小不可控。\n这个时候就要引入伽罗华域，伽罗华域又名有限域，包含有限个元素，这里我们选取包含 2^8 个元素的伽罗华域，在这个域中，每个元素可以表示为 8bit 的字节，所以校验块的大小不会膨胀。GF(2^8)中的所有多项式都可以通过多项式生成元 g 通过求幂得到。即域中的任意元素 $a \\in \\lbrace 0, 1, 2, \\ldots, 255 \\rbrace$，都存在一个 k，使得 a = g^k。为了更方便地在 GF 中进行乘除，我们需要创建两个表：对数表和指数表。对数表可以根据给定的指数查找 GF 中相应的对数；指数表则是反过来，根据对数得到 GF 中对应的指数。\n打表：先确定 GF(2^8)的素多项式 $P_8(x) = x^8 + x^4 + x^3 + x^2 + 1 = 285$ 和生成元 $g(x)=2$，而后按顺序递推得到\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  logTable := make([]int, 256) expTable := make([]int, 256) logTable[0] = -1 // undefined expTable[0] = 1 // g^0 = 1 for i := 1; i \u003c 256; i++ { expTable[i] = expTable[i-1] \u003c\u003c 1 // g = 2  for expTable[i] \u003e= 256 { // if expTable[i] bigger than x^8  expTable[i] ^= 0x11d // P_8(x) = x^8 + x^4 + x^3 + x^2 + 1  } logTable[expTable[i]] = i } logTable[1] = 0 // exptable[255]=exptable[0]=1, and g^0 must be 1, so reset logtable[1] = 0  // logTable: -1 0 1 25 2 50 26 198 3 223 51 238 27 104 199 75 4 100 224 14 52 141 239 129 28 193 105 248 200 8 76 113 5 138 101 47 225 36 15 33 53 147 142 218 240 18 130 69 29 181 194 125 106 39 249 185 201 154 9 120 77 228 114 166 6 191 139 98 102 221 48 253 226 152 37 179 16 145 34 136 54 208 148 206 143 150 219 189 241 210 19 92 131 56 70 64 30 66 182 163 195 72 126 110 107 58 40 84 250 133 186 61 202 94 155 159 10 21 121 43 78 212 229 172 115 243 167 87 7 112 192 247 140 128 99 13 103 74 222 237 49 197 254 24 227 165 153 119 38 184 180 124 17 68 146 217 35 32 137 46 55 63 209 91 149 188 207 205 144 135 151 178 220 252 190 97 242 86 211 171 20 42 93 158 132 60 57 83 71 109 65 162 31 45 67 216 183 123 164 118 196 23 73 236 127 12 111 246 108 161 59 82 41 157 85 170 251 96 134 177 187 204 62 90 203 89 95 176 156 169 160 81 11 245 22 235 122 117 44 215 79 174 213 233 230 231 173 232 116 214 244 234 168 80 88 175 // expTable: 1 2 4 8 16 32 64 128 29 58 116 232 205 135 19 38 76 152 45 90 180 117 234 201 143 3 6 12 24 48 96 192 157 39 78 156 37 74 148 53 106 212 181 119 238 193 159 35 70 140 5 10 20 40 80 160 93 186 105 210 185 111 222 161 95 190 97 194 153 47 94 188 101 202 137 15 30 60 120 240 253 231 211 187 107 214 177 127 254 225 223 163 91 182 113 226 217 175 67 134 17 34 68 136 13 26 52 104 208 189 103 206 129 31 62 124 248 237 199 147 59 118 236 197 151 51 102 204 133 23 46 92 184 109 218 169 79 158 33 66 132 21 42 84 168 77 154 41 82 164 85 170 73 146 57 114 228 213 183 115 230 209 191 99 198 145 63 126 252 229 215 179 123 246 241 255 227 219 171 75 150 49 98 196 149 55 110 220 165 87 174 65 130 25 50 100 200 141 7 14 28 56 112 224 221 167 83 166 81 162 89 178 121 242 249 239 195 155 43 86 172 69 138 9 18 36 72 144 61 122 244 245 247 243 251 235 203 139 11 22 44 88 176 125 250 233 207 131 27 54 108 216 173 71 142 1   下面以 ABCDEFGHIJKLNMOP 为例，模拟 RS 生成校验块并在部分数据块丢失的情况下恢复全量数据的过程。\n令 K = 4，M = 2，将其切成 4 份，并且读取其 byte，我们可以得到其二进制表示（ASCII）。\n$$ \\begin{bmatrix} A\u0026 B\u0026 C\u0026 D \\\\ E\u0026 F\u0026 G\u0026 H \\\\ I\u0026 J\u0026 K\u0026 L \\\\ N\u0026 M\u0026 O\u0026 P \\\\ \\end{bmatrix} → \\begin{bmatrix} 65 \u0026 66 \u0026 67 \u0026 68 \\\\ 69 \u0026 70 \u0026 71 \u0026 72 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix} $$\n再通过与(4+2,4)的 GF(2^8)编码矩阵相乘，得到校验块 $$ \\begin{bmatrix} 1 \u0026 0 \u0026 0 \u0026 0 \\\\ 0 \u0026 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \u0026 0 \\\\ 0 \u0026 0 \u0026 0 \u0026 1 \\\\ 27 \u0026 28 \u0026 18 \u0026 20 \\\\ 28 \u0026 27 \u0026 20 \u0026 18 \\\\ \\end{bmatrix}\\times \\begin{bmatrix} 65 \u0026 66 \u0026 67 \u0026 68 \\\\ 69 \u0026 70 \u0026 71 \u0026 72 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix}= \\begin{bmatrix} 65 \u0026 66 \u0026 67 \u0026 68 \\\\ 69 \u0026 70 \u0026 71 \u0026 72 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ 81 \u0026 82 \u0026 83 \u0026 73 \\\\ 85 \u0026 86 \u0026 87 \u0026 37 \\\\ \\end{bmatrix} $$\n令第一和第二个数据块丢失，模拟重构数据块的过程 $$ \\begin{bmatrix} 1\u0026 0\u0026 0\u0026 0 \\\\ 0\u0026 1\u0026 0\u0026 0 \\\\ 0\u0026 0\u0026 1\u0026 0 \\\\ 0\u0026 0\u0026 0\u0026 1 \\\\ 27\u0026 28\u0026 18\u0026 20 \\\\ 28\u0026 27\u0026 20\u0026 18 \\\\ \\end{bmatrix}× \\begin{bmatrix} d_1 \\\\ d_2 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix}= \\begin{bmatrix} d_1 \\\\ d_2 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ 81 \u0026 82 \u0026 83 \u0026 73 \\\\ 85 \u0026 86 \u0026 87 \u0026 37 \\\\ \\end{bmatrix} $$\n$$\\downarrow$$ $$ \\begin{bmatrix} 0\u0026 0\u0026 1\u0026 0 \\\\ 0\u0026 0\u0026 0\u0026 1 \\\\ 27\u0026 28\u0026 18\u0026 20 \\\\ 28\u0026 27\u0026 20\u0026 18 \\\\ \\end{bmatrix}× \\begin{bmatrix} d_1 \\\\ d_2 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix}= \\begin{bmatrix} 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ 81 \u0026 82 \u0026 83 \u0026 73 \\\\ 85 \u0026 86 \u0026 87 \u0026 37 \\\\ \\end{bmatrix} $$ $$\\downarrow$$ $$ \\begin{bmatrix} d_1 \\\\ d_2 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix}= \\begin{bmatrix} 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ 81 \u0026 82 \u0026 83 \u0026 73 \\\\ 85 \u0026 86 \u0026 87 \u0026 37 \\\\ \\end{bmatrix}× \\begin{bmatrix} 0\u0026 0\u0026 1\u0026 0 \\\\ 0\u0026 0\u0026 0\u0026 1 \\\\ 27\u0026 28\u0026 18\u0026 20 \\\\ 28\u0026 27\u0026 20\u0026 18 \\\\ \\end{bmatrix}^{-1}= \\begin{bmatrix} 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ 81 \u0026 82 \u0026 83 \u0026 73 \\\\ 85 \u0026 86 \u0026 87 \u0026 37 \\\\ \\end{bmatrix}× \\begin{bmatrix} 208 \u0026 107 \u0026 104\u0026 210\\\\ 107 \u0026 208 \u0026 210\u0026 104\\\\ 1\u0026 0\u0026 0\u0026 0 \\\\ 0\u0026 1\u0026 0\u0026 0\\\\ \\end{bmatrix}= \\begin{bmatrix} 65 \u0026 66 \u0026 67 \u0026 68 \\\\ 69 \u0026 70 \u0026 71 \u0026 72 \\\\ 73 \u0026 74 \u0026 75 \u0026 76 \\\\ 77 \u0026 78 \u0026 79 \u0026 80 \\\\ \\end{bmatrix} $$ $$\\downarrow$$ $$ d_1 = [65,66,67,68] \\\\ d_2 = [69,70,71,72] $$\n因此，我们可以通过构造校验块并将每个数据块和校验块分开存储的方式对数据进行容错。\n reference\n https://drmingdrmer.github.io/tech/distributed/2017/02/01/ec.html\nhttps://www.cnblogs.com/codingtao/p/5916786.html\nhttps://en.wikipedia.org/wiki/Vandermonde_matrix\n","description":"","tags":null,"title":"Reed Solomon原理与简单实现","uri":"/posts/reed-solomon%E5%8E%9F%E7%90%86%E4%B8%8E%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/"},{"content":"reference schedule\ntranslation\n添加用户函数 在 Makefile 的 UPROGS 处添加\n添加系统调用 .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\n系统调用的用户空间代码在user/user.h和user/usys.pl中。\n内核空间代码是kernel/syscall.h、kernel/syscall.c。\n与进程相关的代码是kernel/proc.h和kernel/proc.c。\n  kernel/syscall.h 枚举 SYS_xxx kernel/syscall.c 的两处地方按照格式添加 kernel/sysfile.c 添加 sys_xxx 函数（主要实现） user/user.h 添加系统调用函数的定义 user/usys.pl 添加系统调用的 entry  系统调用的步骤  操作系统初始化时注册系统调用 系统调用函数将对应的调用存到寄存器 保存用户空间的状态 执行 ECALL 指令，提升权限 执行 trampoline 里面的 uservec() ，保存现有的用户寄存器到 trapframe，切换页表 执行 usertrap()，判断陷入类型并处理 执行 syscall()，进行系统调用 执行 usertrapret() ，设置 trapframe 执行 trampoline 里面的 userret，恢复寄存器，返回用户空间  ","description":"","tags":null,"title":"6.S081","uri":"/posts/6.s081/"},{"content":"RT，如果要公网访问服务器的 Redis，要将 redis-cluster 部署在公网上（似乎是废话，但是如果 Redis 服务发现端口是本地的话，就没法公网访问）。\nconfig 中有几个很重要的参数：\n# redis-cluster.conf cluster-announce-ip 116.205.130.21 # 公网ip cluster-announce-port 8003 # redis service 暴露给外部的端口 cluster-announce-bus-port 18003 # redis 集群总线端口 其他就不说了，主要是总线端口，它是 cluster 服务发现的端口，如果填的是局域网 ip（192.168.xxx.xxx）那么就无法被外部访问，因为在 Redis 对 key 进行 hash 的时候，如果处理 key 分片不是本 Redis 服务器的话，会提示Redirected to slot [5798] located at 192.168.xxx.xxx:$xxx（重定向到其他 Redis 服务器），无法被公网访问。 所以要将 cluster 服务发现的 ip 设为公网 ip，还要记得在服务器上暴露服务 ip 和服务发现 ip 以及关闭对应的防火墙。\n# 8000/redis-cluster.conf protected-mode no port 8000 tcp-backlog 511 timeout 0 tcp-keepalive 300 daemonize no supervised no pidfile /var/run/redis_8000.pid loglevel notice logfile \"\" databases 16 always-show-logo yes save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes rdbcompression yes rdbchecksum yes dbfilename dump8000.rdb rdb-del-sync-files no dir ./ replica-serve-stale-data yes replica-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-diskless-load disabled repl-disable-tcp-nodelay no replica-priority 100 acllog-max-len 128 lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no lazyfree-lazy-user-del no appendonly yes appendfilename \"appendonly8000.aof\" appendfsync everysec no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes aof-use-rdb-preamble yes lua-time-limit 5000 cluster-enabled yes cluster-config-file nodes-8000.conf cluster-node-timeout 15000 cluster-announce-ip 116.205.130.21 cluster-announce-port 8000 cluster-announce-bus-port 18000 slowlog-log-slower-than 10000 slowlog-max-len 128 latency-monitor-threshold 0 notify-keyspace-events \"\" hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-size -2 list-compress-depth 0 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 stream-node-max-bytes 4096 stream-node-max-entries 100 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 dynamic-hz yes aof-rewrite-incremental-fsync yes rdb-save-incremental-fsync yes jemalloc-bg-thread yes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  version:'3.3'services:redis-cluster:image:redis:latestcommand:redis-cli --cluster create 116.205.130.21:8000 116.205.130.21:8001 116.205.130.21:8002 116.205.130.21:8003 116.205.130.21:8004 116.205.130.21:8005 --cluster-replicas 1 --cluster-yesdepends_on:- redis-8000- redis-8001- redis-8002- redis-8003- redis-8004- redis-8005redis-8000:# 服务名称image:redis:latest# 创建容器时所需的镜像container_name:redis-8000# 容器名称ports:- 8000:8000- 18000:18000volumes:# 数据卷，目录挂载- ./8000/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8000/data:/datacommand:redis-server /usr/local/etc/redis/redis.conf# 覆盖容器启动后默认执行的命令redis-8001:image:redis:latestcontainer_name:redis-8001ports:- 8001:8001- 18001:18001volumes:- ./8001/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8001/data:/datacommand:redis-server /usr/local/etc/redis/redis.confredis-8002:image:redis:latestcontainer_name:redis-8002ports:- 8002:8002- 18002:18002volumes:- ./8002/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8002/data:/datacommand:redis-server /usr/local/etc/redis/redis.confredis-8003:image:redis:latestcontainer_name:redis-8003ports:- 8003:8003- 18003:18003volumes:- ./8003/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8003/data:/datacommand:redis-server /usr/local/etc/redis/redis.confredis-8004:image:redis:latestcontainer_name:redis-8004ports:- 8004:8004- 18004:18004volumes:- ./8004/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8004/data:/datacommand:redis-server /usr/local/etc/redis/redis.confredis-8005:image:redis:latestcontainer_name:redis-8005ports:- 8005:8005- 18005:18005volumes:- ./8005/redis-cluster.conf:/usr/local/etc/redis/redis.conf- ./8005/data:/datacommand:redis-server /usr/local/etc/redis/redis.conf  ","description":"","tags":null,"title":"Redis Cluster 公网部署","uri":"/posts/redis-cluster%E5%85%AC%E7%BD%91%E9%83%A8%E7%BD%B2/"},{"content":"Task 完成 Multi-Raft\n  lab4A：完成 Multi-Raft 控制中心（和 lab3 内容差不多，一句话就是 shardctrler 是一个将 Config 作为日志进行维护的单 Raft 集群，并且不需要实现快照和持久化） 需要注意的地方是 Join 和 Leave 操作 shards 应该怎么平均且有序地分配给 gids（注意在 Leave 操作中，Group 里面可能有多余的 gid，此时需要注意将其算在 gids 里面），主要逻辑和 lab3 差不多，比较简单。\n  lab4B：实现一个拥有分片功能，能够随时加入退出成员，可以根据配置同步迁移数据，支持断线重连日志快速追赶和快照功能并且能够保证线性一致性的 kv 数据库。 虽然叠了很多 buff，但很多地方我们之前已经实现了，比如加入退出成员和日志同步在 lab4A；断线重连和日志快速追赶在 lab2；线性一致性的 kv 数据库在 lab3。\n  所以我们在 lab4B 的主要任务是根据最新配置来实现分片的处理，进行分片处理和回复客户端的请求都需要通过 Raft 层实现一致性，所以都要调用kv.rf.Start()并启动一个 go routine 处理 Raft 层回调的 applyCh。\n首先是 shard，我们需要将 Client 的 PUT、GET、APPEND 请求通过 key 值的 hash 分配给不同的 shard，shard2gid 数组可以通过读取配置获取。为了防止重复 apply，我们要在 shard 结构加上去重表。所以我实现的 shard 结构体如下：\n1 2 3 4 5  type Shard struct { Log map[string]string LastCommand map[int64]int Status int }   考虑更新 config，leader 需要另起一个 go routine 不断读取新配置，在更新配置之前我们需要判断当前 gid 是否需要 pull 或 push（存下 lastcfg，用来与当前 cfg 作比较）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  func (kv *ShardKV) allSentL() bool { for shard, gid := range kv.lastcfg.Shards { if gid == kv.gid \u0026\u0026 kv.cfg.Shards[shard] != kv.gid \u0026\u0026 kv.stateMachine[shard].Status != Serving { return false } } return true } func (kv *ShardKV) allReceivedL() bool { for shard, gid := range kv.lastcfg.Shards { if gid != kv.gid \u0026\u0026 kv.cfg.Shards[shard] == kv.gid \u0026\u0026 kv.stateMachine[shard].Status != Serving { return false } } return true }   若需要，则等待相关 shards处理完毕再查询新一个 config（因为步子不能迈得太大，需要一个个 config 地进行状态机的更新，原因之一是更新过程会涉及到 shard 的切换）。\n若有一个 gid 需要 push，则另一个就必然需要 pull。无论是用 push 还是用 pull 处理都是可以的。考虑到 Challenge 任务需要在 push 之后删除废弃 shard 释放内存。push 至少比 pull 少一个 RPC 请求，所以我选择了 push。\npush 主要是需要发送 RPC 给对应 status 为 pulling 的 shard，并等待 receiver 接受并 apply 回复 OK 后进行 delete。\n还要记得在一个节点刚成为 leader 的时候发送空日志以 apply 旧的日志。\ntips：  TestConcurrent2 测的是宕机再重启 Service 层不借助 snapshot，用 raft 层的日志快速追赶，然后我的 Get 结果总是与正确答案不一致，表现在前面正确，后面正确，中间缺失。原来是在 shardkv 初始化的时候，cfg 不能初始化为kv.sc.Query(-1)，因为我将 cfg 初始化为最新值，被 Raft 层推到 Service 层的日志在应用在状态机的时候因为 cfgNum 不等于当前的 cfg，所以自动屏蔽掉了（其实这个问题应该不难发现，但我在打 log 的时候没有将 cfgNum 作为 log 头，就没怎么注意到，找了好久。 需要思考怎么做到 Multi-Raft 的幂等和线性一致性。  ","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab4","uri":"/posts/6.824-lab4/"},{"content":"Task 在 raft 框架的基础上建立一个容错的 KV 数据库。重点在于理解 Service 层和 Raft 层的交互，代码方面较为简单，故不进行赘述。\nStep  在 client 和 service 两层完成 Get(), Append(), Put() 对重复的 Append 或 Put 进行去重 service 层的快照与持久化（快照存储的是 Key/Value 等元数据）   tips： 值得一提的是在写完 lab3 的大概框架后，TestSpeed3A 一直不通过，因为要求是平均 33ms 一个 commit，但正常来说 commit 时间应该和 heartbeat timeout 差不多，遂修改 Start() 函数，在 command 被 Service 送来的时候发起一次心跳，进行日志同步。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  func (rf *Raft) Start(command interface{}) (int, int, bool) { rf.mu.Lock() defer rf.mu.Unlock() if rf.state != Leader { return NULL, NULL, false } index, term := rf.getLastLogL().Index+1, rf.currentTerm rf.log = append(rf.log, Entry{ Command: command, Term: term, Index: index, }) DPrintf(dInfo, \"S%v \u003c- %vst command %v\", rf.me, index, command) rf.persist() rf.startHeartbeatL(false) rf.heartbeatTimer.Reset(getHeartbeatDuration()) return index, term, true }   我们还可以进行一点优化：当 Leader 发送心跳时，加上一个 bool，表明 Leader 真的只是发送心跳，或者是为了快速同步日志，如果是后者，还需要判断每一个 Follower 的 nextIndex 是否需要同步，如果不满足 (rf.getLastLogL().Index \u003e rf.nextIndex[i])，则不再同步日志。\n正常来说到这一步就没问题了，但是我又发现了 lab2 的一个遗留 bug，当 commit 频率变得很快时 Leader 就会暴毙（之前的测试仅仅通过 heartbeat timeout 同步日志，频率较低，基本没有出现这个问题）。通过打 log，发现 commit 是通过单独的 go routine 接收 channel 的信号实现的，因为 channel 初始化为make(chan int,1)，在 Leader 连续 commit 时容易堵塞，其实理论上会缓慢通过，但还是暴毙了，属于是一个很玄学的 bug。最后将 channel 扩容成 100 就轻松过了:)\n","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab3","uri":"/posts/6.824-lab3/"},{"content":" 前置芝士\n Task 完成 Raft 的快照功能（涉及到较多的与 Service 层的交互。\n 为什么要有 snapshot?  snapshot 可以将 log 压缩，比如将 10 个 log 压缩成 9 个（当两个 log 修改的 key 值一样时）。 snapshot 可以减少 Raft 层 log 的长度，帮助进度较慢的 Raft 节点快速恢复状态机（减短 raft 中 log 的长度）。snapshot 区别于持久化 log，后者主要是不让宕机的 raft 丢失太多日志。   在 2D 中，snapshot 会涉及到 raft 层与 service 层的多次交互，看这个 diagram of Raft interactions 或许可以帮助理解 Raft 协议不同层次的功能与特性。 snapshot 作用于每一个 Raft 节点，我们需要记录 snapshot 最后一个 index 和 term，用于一致性检查。  Step  Snapshot() 被 service 层调用，约莫 10 次 commit 调用一次，用于保存快照。需要注意的是快照是 service 传给 raft 层的，而不是我们在 raft 层写入日志创建的，我们不需要创建快照，仅需要处理 Service 层传进来的 snapshot，进行日志截断和快照持久化。  1 2 3 4 5 6 7 8 9 10 11 12 13  func (rf *Raft) Snapshot(index int, snapshot []byte) { rf.mu.Lock() defer rf.mu.Unlock() if rf.lastIncludedIndex() \u003e= index { return } term := rf.logAt(index).Term rf.log = rf.log[index-rf.lastIncludedIndex():] rf.setLastIncludedIndex(index) rf.setLastIncludedTerm(term) rf.persister.SaveStateAndSnapshot(rf.getEncodeStateL(), snapshot) DPrintf(dSnap, \"S%v last: %v\", rf.me, index) }   2. InstallSnapshot：\n  Leader 方面，当$nextIndex[Follower] \\leq Leader.lastIncludeIndex$的时候，由于 Leader 已经没有这部分的日志，Leader 会发送 InstallSnapshot RPC 给 Follower，请求 Follower 安装快照（快速追赶），并且在成功收到返回值后，Leader 会更新 nextIndex 和 matchIndex\n  Follower 方面，如果 Follower 收到 Leader 的任期没有过期的话，只能执行。与论文不同的是：不需要考虑分块发送 snapshot，所以offset 和done都不需要考虑，相应的，在实现的时候也不需要考虑第 2,3,4 点 implementation。最后另起一个 go routine 传 snapshot 以及其他必要参数给 applyCh 让 service 更新状态机（发送给 service 后 service 不会立刻拿 snapshot 更新状态机，会先调用 CondInstallsnapshot 来询问 Follower 在这期间有没有 commit，若没有，才会用 snapshot 更新状态机。\n   CondInstallSnapshot：若 $lastIncludedIndex\\leq commitIndex$ ，则返回false，此时 service 不会应用 snapshot；否则剪短自己的 log，并更新 snapshot、lastIncludedTerm 和 lastIncludedIndex，并进行持久化。  tips：   在持久化的时候考虑 lastIncludedIndex 和 lastIncludedTerm，并应用到 commitIndex 和 lastApplied。\n  因为我们要删掉已经被 snapshot 的 log，所以需要改变 log 的索引方式。\n  对 condInstallsnapshot 的解释：Follower 收到 InstallSnapshot，向服务器请求应用 snapshot 的时候，如果服务器发送 condInstallSnapshot 的那一刻 lastCommit 还没被修改的话，就保证了原子操作。为什么需要保证原子操作？因为节点通过 applychan 向 service 通信的情况有两种，一种是 commit 到状态机，另一种是 snapshot 到状态机，两者是并行的，互不干扰。只要 raft 节点在发送 snapshot channel 到 service 接收到这个 channel 之间有 commit channel，也就是当 $lastIncludedIndex\\leq commitIndex$ 的时候，snapshot 发送的 log 就很有可能被应用到状态机了。\n  ","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab2D","uri":"/posts/6.824-lab2d/"},{"content":" 前置芝士\n Task 完成 Raft 的持久化。\nStep 如果前面做得好，只需要完成持久化。\n 持久化至 Service 层  1  persist()   Crash 后从 Service 层恢复  1  readPersist(data []byte)   如果和我一样前面差点意思，就要小修一下 guide   AppendEntries Handler 中，Follower 引入 XTerm 和 XIndex 来快速调整 nextIndex。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  if args.PrevLogIndex \u003e rf.getLastLogL().Index { reply.Success, reply.Term = false, rf.currentTerm reply.XIndex = rf.getLastLogL().Index + 1 // Follower's nextIndex  return } // entry logAt prevLogIndex whose term doesn't match prevLogTerm DPrintf(dInfo, \"S%v prevLogTerm:%v, prevLogIndex:%v,log[prevLogIndex].Term:%v\", rf.me, args.PrevLogTerm, args.PrevLogIndex, rf.logAt(args.PrevLogIndex).Term) if args.PrevLogTerm != rf.logAt(args.PrevLogIndex).Term { reply.Success, reply.Term = false, rf.currentTerm reply.XIndex, reply.XTerm = rf.commitIndex+1, rf.logAt(args.PrevLogIndex).Term for i := args.PrevLogIndex; i \u003e rf.commitIndex+1; i-- { if reply.XTerm != rf.logAt(i-1).Term { reply.XIndex = i return } } DPrintf(dInfo, \"S%v XIndex = %v\", rf.me, rf.commitIndex+1) return }    Leader 对 XTerm 和 XIndex 的处理  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  if rf.sendAppendEntries(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if reply.Term \u003e rf.currentTerm { //changeState but not update election timer  } else if args.Term == rf.currentTerm { if reply.Success { // update nextIndex, matchIndex \u0026 commit  } else if reply.Term == rf.currentTerm{ // adjust nextIndex  if reply.XIndex != NULL { DPrintf(dHeart, \"S%v \u003c- S%v heartbeat XIndex:%v, XTerm:%v\", rf.me, peer, reply.XIndex, reply.XTerm) if reply.XTerm == NULL { rf.nextIndex[peer] = reply.XIndex } else { ok := false for i := rf.nextIndex[peer] - 1; i \u003e rf.lastIncludedIndex() \u0026\u0026 reply.XTerm \u003c= rf.logAt(i).Term; i-- { if rf.logAt(i).Term == reply.XTerm { ok = true rf.nextIndex[peer] = i + 1 break } } if !ok { rf.nextIndex[peer] = reply.XIndex } } } } } }    electionTimer 不能在每次变成 Follower 的时候重置。   If election timeout elapses without receiving AppendEntries RPC from current Leader or granting vote to Candidate: convert to Candidate.\n  The distinction turns out to matter a lot, as the former implementation can result in significantly reduced liveness in certain situations.\n electionTimer 重置仅在以下情况发生：\n 刚成为 Candidate。 给别人投票后。 Follower 收到 AppendEntries 或者 InstallSnapshot，并且 args.Term 等于自己当前的 term（在前置芝士有谈到，其实这个 bug 是我在 2C 的时候才修的）。  我在 Follower 收到 AppendEntries 或者 InstallSnapshot，并且 args.Term 大于 currentTerm 的时候也重置了 electionTimer。改为不重置后，直观的结果是跑 2C 的 test 平均快了 15s，并且不会出现fail to reach agreement了。\n","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab2C","uri":"/posts/6.824-lab2c/"},{"content":" 前置芝士\n Task 处理日志，具体来说是接收 Service 层发来的日志，日志复制，应用日志。\n涉及到一点 Raft 层与 Service 层的交互，比如 Leader 接受 command 并保存为日志；Apply 日志到 Service 层。\nStep  选举的时候需要额外注意一个限制：只投票给 log 比自己新的 Candidate。 Leader 接受 command，append 进 log，返回此 command 的下标，此时 log 在状态机中还没被应用。 心跳时顺便发送日志给 Follower（也可以分开）。   AppendEntries RPC 参数中的 log 需要深拷贝才能免遭 data race。 发送的 log 并不是从头开始，而是从 nextIndex 开始。 在不可靠网络中，收到 RPC 结果的时候可能已经过了几个任期，此时需要先检查一下 args.Term 还等不等于 currentTerm，但在此之前，如果返回的任期比 currentTerm 还要大，那么无论是不是不可靠网络，这个 Leader 都要转为 Follower（同样的，因为不确定他有没有资格成为 Candidate，所以没有必要将其转为 Candidate，反正任期增加后总会有 Candidate 产生）；如果返回的任期小于等于 currentTerm，那么 Leader 只需要正常处理。  1 2 3 4 5 6 7 8 9 10 11 12 13  if rf.sendAppendEntries(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if reply.Term \u003e rf.currentTerm { //changeState but not update election timer  } else if args.Term == rf.currentTerm { if reply.Success { // update nextIndex, matchIndex \u0026 commit  } else if reply.Term == rf.currentTerm{ // adjust nextIndex  rf.nextIndex[peer] = max(1,rf.nextIndex[peer]-1) } }   Follower 进行日志复制（需严格按照论文）。  1 2 3 4 5 6 7 8 9 10 11 12 13  prevLogIndex := rf.nextIndex[i] - 1 prevLogTerm := rf.logAt(prevLogIndex).Term args := \u0026AppendEntriesArgs{ Term: rf.currentTerm, LeaderId: rf.me, PrevLogIndex: prevLogIndex, PrevLogTerm: prevLogTerm, Entries: make([]Entry, rf.getLastLogL().Index-prevLogIndex), LeaderCommit: rf.commitIndex, } // 必须要复制一遍才能免遭 data race copy(args.Entries, rf.log[prevLogIndex+1-rf.lastIncludedIndex():]) go rf.foraHeartbeat(i, args)   AppendEntries RPC 回复后应如何改变自身状态。   先进行一个 term 的处理  1 2 3 4 5 6 7 8 9 10  if args.Term \u003c rf.currentTerm { reply.Term, reply.Success = rf.currentTerm, false return } if args.Term \u003e rf.currentTerm { rf.changeStateL(Follower, args.Term, NULL) } else { rf.changeStateL(Follower, rf.currentTerm, rf.votedFor) rf.electionTimer.Reset(getElectionDuration()) }    再看看自己的 log 与 RPC 传来的 entries 有没有冲突，有的话以 Leader 为准；返回参数调整自己在 Leader 那边的 nextIndex，直到和 Leader prevLogIndex 的 term 一致为止，才能真正 append entries。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // last log index is too small // entry logAt prevLogIndex whose term doesn't match prevLogTerm if args.PrevLogIndex \u003e rf.getLastLogL().Index || args.PrevLogTerm != rf.logAt(args.PrevLogIndex).Term{ reply.Success, reply.Term = false, rf.currentTerm return } // log 比 Leader 短 || log 比 Leader 长并且存在不匹配 -\u003e 截断并补上 needReplace := rf.getLastLogL().Index \u003c= args.PrevLogIndex+len(args.Entries) if len(args.Entries) \u003e 0 { for i := args.PrevLogIndex + 1; i \u003c= args.PrevLogIndex+len(args.Entries); i++ { // idx and term can identify a log  if rf.getLastLogL().Index \u003e= i \u0026\u0026 rf.logAt(i).Term != args.Entries[i-args.PrevLogIndex-1].Term { needReplace = true break } } if needReplace { rf.log = append(rf.log[:args.PrevLogIndex+1-rf.lastIncludedIndex()], args.Entries...) } }    commit 自己的日志。  1 2 3 4 5 6 7 8 9 10 11  if args.LeaderCommit \u003e rf.commitIndex { rf.commitIndex = args.LeaderCommit if len(args.Entries) \u003e 0 { rf.commitIndex = min(rf.commitIndex, args.Entries[len(args.Entries)-1].Index) } DPrintf(dInfo, \"S%v lastIndex:%v, commIndex:%v, lastApplied:%v\", rf.me, rf.getLastLogL().Index, rf.commitIndex, rf.lastApplied) if rf.commitIndex \u003e rf.lastApplied { rf.applyWaker \u003c- 1 } } reply.Term, reply.Success = rf.currentTerm, true   Leader 方面，只有当大部分 Follower 的 matchIndex 更新（log 存到 Follower）了，Leader 的 commitIndex 才能同步更新。这部分我直接从后往前遍历，因为日志的任期是按顺序增长的，所以如果遇到日志任期小于当前任期直接 break，因为 Leader 只能将自己任期的日志 commit，对于其他任期的日志，只能被动 commit。在 lab 中，没有需要 Leader及时更新旧 commit 的情况，所以不做特殊处理（在成为 Leader 的时候发一个空日志）。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  for i := rf.getLastLogL().Index; i \u003e rf.commitIndex; i-- { if rf.logAt(i).Term != rf.currentTerm { break } cnt := 1 for p := range rf.peers { if p != rf.me \u0026\u0026 rf.matchIndex[p] \u003e= i { cnt++ } } if cnt \u003e len(rf.peers)/2 { rf.commitIndex = i rf.applyWaker \u003c- 1 break } }   Tips  在 currentTerm \u003c args.Term 的时候，我们其实是不需要重置选举时间的，因为如果出现了一个 Leader 比自己任期大，说明自己没有给他投过票，但他得到了半数节点的支持，说明至少半数节点有成为 Candidate 的潜质，并且如果自己真的开始选举的话，会发送无用的 RPC，降低 Raft 的运行效率。   If you follow the rule from Figure 2, the servers with the more up-to-date logs won’t be interrupted by outdated servers’ elections, and so are more likely to complete the election and become the Leader.\n 发送 heartbeat 的时候需要注意自己还是不是 Leader。  因为我忽略了这个点，导致 Leader crash 再恢复的时候有很小的概率出现一个有点怪的 bug：恢复的一瞬间，Leader 想将自己积累已久的日志发给其他节点，被拒收后发现自己的 term 过期了，于是将自己转为 Follower…… 好像没什么问题，但无法完成一致性检验，通过打 log 发现 Leader 在转为 Follower 后的一瞬间发送了最后一波心跳，于是检查代码，发现我在发送心跳给不同的 peer 的时候用的是 go routine 套 go routine，未能保证原子操作，在将要发送心跳的时候，Leader 已经不再是 Leader 了，但还是做出了 Leader 的行为，所以需要在发送前核验自己的 Leader 身份。\n在 updateCommit 的时候我想直接判断成功返回 AppendEntries RPC 的 Follower 数量，如果超过一半就更新 Leader commitIndex = lastLog.index，但因为发送和接受 RPC 并非原子，可能会存在前面的 Follower 未包含后面新增的 log 的情况。   If there exists an N such that N \u003e commitIndex, a majority of matchIndex[i] ≥ N, and log[N].term == currentTerm: set commitIndex = N (§5.3, §5.4).\n ","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab2B","uri":"/posts/6.824-lab2b/"},{"content":"Task 完成各种情况的领导人选举。\n我们首先需要熟悉一下 Raft 的工作原理，建议先过一遍 前置芝士。\nStep  先完善 Raft 结构和 Make 函数，再结合 Gif 思考单个节点的状态。 节点开始时的状态是 Follower，election timeout 后，状态会改为 Candidate。我们应该如何设计选举超时，当然是开一个 go routinerf.ticker() 对超时进行检测。那么是用time.Sleep还是time.Timer实现呢？官方的建议是用 sleep，但我用的是 timer，也能够正常实现，并且我还实现了 sleep 的版本，感觉速度上相差无几。   ticker  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func (rf *Raft) ticker() { for !rf.killed() { select { case \u003c-rf.heartbeatTimer.C: rf.mu.Lock() if rf.state == Leader { rf.startHeartbeatL(true) rf.heartbeatTimer.Reset(getHeartbeatDuration()) rf.electionTimer.Reset(getElectionDuration()) } rf.mu.Unlock() case \u003c-rf.electionTimer.C: rf.mu.Lock() rf.startElectionL() rf.electionTimer.Reset(getElectionDuration()) rf.mu.Unlock() } } }   节点成为 Candidate 后并发发送 RequestVote RPC，自己如何处理 RPC 返回的结果，如何判断投给自己的节点数量是否超过半数？   Leader election  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  func (rf *Raft) foraVote(peer int, args *RequestVoteArgs, cnt *int) { reply := RequestVoteReply{} DPrintf(dVote, \"S%v -\u003e S%v send vote\", rf.me, peer) if rf.sendRequestVote(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if args.Term == rf.currentTerm \u0026\u0026 rf.state == Candidate { if reply.VoteGranted { DPrintf(dVote, \"S%v \u003c- S%v voted\", rf.me, peer) *cnt++ if *cnt \u003e len(rf.peers)/2 { for i := range rf.peers { rf.nextIndex[i] = rf.getLastLogL().Index + 1 rf.matchIndex[i] = 0 DPrintf(dHeart, \"S%v \u003c- S%v nextIndex:%v\", rf.me, i, rf.nextIndex[i]) } rf.changeStateL(Leader) } } else if reply.Term \u003e rf.currentTerm { DPrintf(dVote, \"S%v \u003c- S%v ~voted\", rf.me, peer) rf.changeStateL(Follower, reply.Term, NULL) rf.persist() } } } }   peer 节点从哪些方面处理投票逻辑，任期？日志情况（2B）？   Follower RequestVote RPC handler  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.mu.Lock() defer rf.mu.Unlock() defer rf.persist() // currTerm higher || voted \tif rf.currentTerm \u003e args.Term || (rf.votedFor != NULL \u0026\u0026 rf.currentTerm == args.Term) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } if rf.currentTerm \u003c args.Term { rf.changeStateL(Follower, args.Term, NULL) } // check log leader \t// candidate lastLogTerm to short || (lastLogTerm=rf.lastLogTerm \u0026\u0026 candidate lastLogIndex to short) \tif rf.getLastLogL().Term \u003e args.LastLogTerm || (rf.getLastLogL().Term == args.LastLogTerm \u0026\u0026 rf.getLastLogL().Index \u003e args.LastLogIndex) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } rf.changeStateL(Follower, args.Term, args.CandidateId) rf.electionTimer.Reset(getElectionDuration()) reply.Term, reply.VoteGranted = rf.currentTerm, true }   Tips   Candidate 选举前要先自增 currentTerm。\n  在 2A 中，我们处理 RequestVote Handler 的时候还不需要关注日志的新旧（2B），rf.persist() 也还不需要关注（2C），仅需要思考任期应该如何处理。\n  因为处理投票 RPC 的返回时需要加锁保证 rf 结构的原子读取和写入，顺便就可以进行投票数量的计数。\n  Candidate 成为 Leader 时，需要及时发送 heartbeat，告诉别人自己是老大，阻止他们的选举。\n  heartbeat 频率不能太高，控制在每秒 10 次以内，否则会突然宕机（但其实我亲测 heartbeatTimeout 设为 60ms，election 设为 rand(180)+180，test 了 1k 次没一次是 fail 的）。\n The paper’s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the Leader sends heartbeats considerably more often than once per 150 milliseconds (e.g., once per 10 milliseconds). Because the tester limits you tens of heartbeats per second, you will have to use an election timeout larger than the paper’s 150 to 300 milliseconds, but not too large, because then you may fail to elect a Leader within five seconds.\n   ","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab2A","uri":"/posts/6.824-lab2a/"},{"content":"Raft Raft 是一个实现分布式共识的协议，主要解决的是分布式一致性的问题。\nOverview 假设现在有一个 Raft 架构的服务。我们将这个服务分为三层，Client，Service，Raft。Client 层首先发送请求给 Service 层，然后 Service 层解析请求为command，将command发送给 Raft 层的 Leader。Leader 在一定时间内通知 Service 层 “apply” 包含这个command的日志，Service 层才可以将这条日志保存到状态机，进而返回对应的结果给 Client 层。并且因为 Raft 层不应该存储过多的 log，所以 Service 层还会将 applied 的 log 压缩成快照，以便快速应用。\n我们的任务就是用 go 实现基础的 Raft 层架构。\n 领导人选举   最初，所有 Raft 节点都是 Follower，如果在election timeout内未收到当前term的heartbeat，就会转为 Candidate。  election timeout: 选举超时时间。大概是heartbeat timeout的 3 倍。 term：任期。每个用于实现一致性共识。 heartbeat：心跳。Raft 节点有三种状态：Follower，Candidate，Leader。Leader 为了维持自己的领导，需要每隔一段时间发送一次心跳。   转为 Candidate 之后，term++，给自己投票，并发送请求投票的 RPC 给 peer 节点。 收到请求 RPC 的 peer 满足以下两个条件才可以投票：  peer 任期小于 Candidate 的任期或者 peer 任期等于 Candidate 并且当前任期没投过。 peer 的 log 没有 Candidate 新。   Candidate 得到的票数超过半数的 peer 就可以成为 Leader，因为上述限制，一个集群同一个term只会选出一个 Leader。 Leader 每隔一次heartbeat timeout就发送一次包含 snapshot 或 log 的 heartbeat，发送快照还是日志根据 peer 的 nextIndex 而定。  nextIndex 是 Leader 对 peer 日志长度的乐观推测，成为 Leader 后会对所有 peer 的 nextIndex 赋值为自己的 lastLogIndex+1，而后会根据 heartbeat 结果更改 nextIndex。 lastIncludeIndex 每个节点都有，表示 snapshot 包含的最后一个日志的下标，初始为 0。 如果 $nextIndex \\leq lastIncludedIndex$ ，发送 InstallSnapshot RPC，否则发送 AppendEntries RPC。   Follower 需要对 Leader 发送的心跳进行处理。   日志复制    Service 层会通过 Start(cmd) 发送 command 给 Leader。\n  Leader 需要保存 command 至 log，并在心跳的时候向 Follower 发送他没有的 log。\n  Leader 等待一半以上的 Follower 写入自己的日志，再进行 commit。\n 判断 Follower 写入日志的标准是 matchIndex，上面有提到 nextIndex 是 Leader 对 peer 日志长度的乐观推测，matchIndex 则是相对悲观的推测，只有在 AppendEntries RPC 返回成功后 Leader 才会更新相应 Follower 的 matchIndex。 并且考虑 RPC 调用的非线性返回，需要在修改 matchIndex 的时候判断需要修改的值是否真的大于当前的 matchIndex 的值。    Leader commit 后修改 commitIndex 的值，并另开一个 go routine 将从lastApplied+1 到 commitIndex 的值推到 applyCh，再修改lastApplied = commitIndex。\n  Follower 在 Leader commit 后也会以 Leader 的 commitIndex 作为限制 commit 自己的 log，并和 Leader 一样，将日志交给 service apply。\n   日志压缩   Service 层在若干 commit 后，会压缩已提交的日志，并通过 Snapshot(index,snapshot) 提醒 raft 层。 raft 层则需要进行一些处理，比如删掉被压缩的日志，改变日志的索引方式，持久化 snapshot 的信息（但不需要保存 snapshot，snapshot 仅存在 Service 层）。 对于 Leader，在 heartbeat 时，若满足 $nextIndex \\leq lastIncludedIndex$ ，则通过 persister.ReadSnapshot() 读取 snapshot 给 Follower。 如果 Follower term \u003c= Leader term，只能接受 snapshot，并删掉被压缩的日志，改变日志的索引方式，持久化 snapshot 的信息。  Tips   注意 data race，对大部分 rf 结构的修改和读取都要上锁。\n  所有 RPC 都要检测任期，并对过期状态进行处理。\n  在 lab2D 中，需要改变下标的索引方式。\n   Each log entry also has an integer index iden-tifying its position in the log.\n 但这个其实很容易改，所以推荐在 2D 之前不要去管下标的问题，直接用 log 数组自己的下标就可以了。\nstruct 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  const NULL int = -1 const ( _ = iota Follower Candidate Leader ) type ApplyMsg struct { CommandValid bool Command interface{} CommandIndex int SnapshotValid bool Snapshot []byte SnapshotTerm int SnapshotIndex int } type Entry struct { Command interface{} // Command for state machine \tTerm int // Command received Term \tIndex int } // A Go object implementing a single Raft peer. type Raft struct { mu sync.Mutex // Lock to protect shared access to this peer's state \tpeers []*labrpc.ClientEnd // RPC end points of all peers \tpersister *Persister // Object to hold this peer's persisted state \tme int // this peer's index into peers[] \tdead int32 // set by Kill()  // Persistent state \tcurrentTerm int // 0... \tvotedFor int // null if none \tlog []Entry // index 1...  // Volatile state \tcommitIndex int // most of the server has been replicated and durable, 0... \tlastApplied int // highest entry applied to state machine, 0... \tstate int heartbeatTimer *time.Timer electionTimer *time.Timer applyCh chan ApplyMsg applyWaker chan int // for leader (reinitialized after election) \tnextIndex []int // last log index+1... \tmatchIndex []int // highest log entry be replicated on server, 0..., update: PrevLogIndex+len(Entries) } func (rf *Raft) lastIncludedTerm() int { return rf.log[0].Term } func (rf *Raft) lastIncludedIndex() int { return rf.log[0].Index } func (rf *Raft) setLastIncludedTerm(term int) { rf.log[0].Term = term } func (rf *Raft) setLastIncludedIndex(index int) { rf.log[0].Index = index } func getHeartbeatDuration() time.Duration { return time.Millisecond * 60 } func getElectionDuration() time.Duration { return time.Millisecond * time.Duration(rand.Int31n(180)+180) }   res reference\nhttps://thesquareplanet.com/blog/students-guide-to-raft/\nhttps://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf\nhttps://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf\nhttp://thesecretlivesofdata.com/raft/\nhttps://pdos.csail.mit.edu/6.824/labs/raft-structure.txt\nhttps://pdos.csail.mit.edu/6.824/labs/raft-locking.txt\nhttps://blog.josejg.com/debugging-pretty/\nhttps://flaneur2020.github.io/2020/11/07/mit6-824-raft/\nhttps://github.com/OneSizeFitsQuorum/MIT6.824-2021/blob/master/docs/lab2.md\n","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab2","uri":"/posts/6.824-lab2/"},{"content":"Lab1 MapReduce Paper MapReduce: Simplified Data Processing on Large Clusters\nMapReduce 将分布式系统处理数据的细节（并行、容错、局部性优化、负载均衡等）隐藏起来，提供一套简化方案，解决了在多台机器处理大量逻辑简单的计算（分布式计算）实现复杂的问题。\n实现 本实验可以由 1 个 coordinator/master 调度若干个 worker。先完成所有 map 任务，生成中间键值对并将其存在中间文件后再进行 reduce 任务，最后将 reduce 任务的结果输出到文本。\n需要我们修改的文件为 mr/*\n worker 通过 RPC 循环请求任务。 coordinator 读取 8 个给定的文件分给不同的 worker 进行 map 任务，这部分如果喜欢也可以按固定 bytes 进行切割但我懒得处理了。 worker 读取文件并扔给fmap进行处理，生成中间键值对，计算字符串的 hash 后将key-intermediate_value存在 mr-taskid-ihash(str) 里面。   fmap 函数通过编译生成的 *.so 调用\n .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\n看到一些同学是先 os.CreateTemp(\"\", tmpFileName) 存在临时文件里面，等处理完了再 rename 成mr-taskid-ihash(str)。这样应该会更加规范一些，但不创建 tempfile 在 lab1 理论上应该也是可行的。\n当文件没完全写完 worker 就 crash 时，这个任务会被 coordinator 发现并交给别的 worker 重做。因为用的是os.Create()，文件会被新的覆盖，直到 worker 成功完成任务为止。\n如果逻辑允许两个 worker 同时处理一个任务的话，就需要创建 tempFile 再 rename 的方式，因为需要保证创建的（临时）文件内容不重复。\n map 任务全部完成后 coordinator 分配 NReduce 个 reduce 任务给不同的 worker 处理。 worker 读取中间文件，并将key-list(intermediate_value)扔给freduce处理成key-value 写入mr-out-ihash(str)。 coordinator 发现任务全都处理完后踢走 worker，并在若干秒后退出。  Tips   结构\n  go 可以用 const 和 iota 代替 enum。\n  WorkerInfo 在这个实验可以省略，不需要保留 worker 的状态，但我写了就不想删了。\n  本来还想往结构体内置一个 logger 的，但 RPC 调用需要 gob 序列化，而 logger 不知道为啥会序列化失败，不知道是啥 bug，以后再瞅瞅。\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  const ( _ = iota // MAP REDUCE WAIT: Task type \tMAP REDUCE WAIT // IDLE BUSY DONE: Task status || WorkerInfo status \tIDLE BUSY DONE ) type Coordinator struct { NMap int // map 任务的个数 \tNReduce int // reduce 任务的个数 \tDMap int // 记录 map task 完成的个数 \tDReduce int // 记录 reduce task 完成的个数 \tWorkerId int // 为新的 worker 分配 workerIds \tTaskDone map[int]bool // 记录 task 是否被完成 \tMap chan *Task // 待取出的 map task \tReduce chan *Task // 待取出的 reduce task \tTaskMutex sync.Mutex // 用于任务分发相关数据的 mutex \tDoneMutex sync.Mutex // 用于完成任务相关数据的 mutex \tMutex sync.Mutex // 用于其他细节的 mutex } type Task struct { StartTime time.Time NReduce int // 传给 worker，用于 ihash 的 mod \tType int // MAP REDUCE WAIT \tStatus int // IDLE BUSY DONE \tFileName string TaskId int WorkerId int } type WorkerInfo struct { WorkerId int TaskId int Type int Status int //Lg *log.Logger \t//Why this error? \t//gob: type log.Logger has no exported fields \t//2023/01/31 14:34:13 RPC getWork failed \t//exit status 1 } // Map functions return a slice of KeyValue. type KeyValue struct { Key string Value string }   RPC 写入 reply 的时候不能直接将 reply 指向一个新的地址，而是要修改 reply 地址的值。  1 2 3 4 5 6 7 8 9 10 11 12  //reply = \u0026GetWorkReply{\u0026Task{...}} \t//上面的方法不会返回想要的 reply，因为 reply 指向的是新的 GetWorkReply 值在 rpc 服务器的指针。这部分客户端的内存和服务器的不一样，所以得到的是空值；下面的方法因为 reply 是共享内存的，所以服务器和客户端都可以访问 \u0026reply。 \t//在 RPC 调用时，要避免传递指针参数，如果传递的参数是值类型，那么这个值将会被复制到另一个地址 \t*reply = GetWorkReply{Task{ StartTime: time.Now(), Type: MAP, Status: BUSY, FileName: mapTask.FileName, NReduce: c.NReduce, WorkerId: args.WorkerId, TaskId: mapTask.TaskId, }} // equal to reply.Task = \u0026Task{...}   clash test，需要 coordinator 在 worker 宕机 10s 后为同一个任务重新分配 worker，这部分需要考虑一下注意一下 data race  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  go func(taskId int, filename string) { select { case \u003c-time.After(12 * time.Second): c.Mutex.Lock() if !c.TaskDone[taskId] { c.Mutex.Unlock() dosomething } else { c.Mutex.Unlock() dootherthing } // default:{  // }  // default 不能写，如果写了就会直接跳到 default，不会进入 12s 的 case  } return }(maptask.TaskId, mapTask.FileName)   并发编程细节  因为 MapReduce 的特性，map task 可以并发，reduce task 可以并发，但两种任务不能同时并发，所以需要等到 map task 跑完才可以进行 reduce task。如果同时读写同一个变量，需要加锁。其实还可以用 chan 实现 lock-free，以后试试，如果有时间的话。\n随手写的 makefile  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # location: src/Makefile ntest := 50 lab1: @cd main;\\  for i in $$(seq 1 $(ntest)) ; do\\  bash test-mr.sh \u003e res$$i;\\  done;\\  cnt=0;\\ \tfor i in $$(seq 1 $$(expr $(ntest) - 1)); do\\ \tif cmp res$$i res$$(expr $$i + 1); then \\ \tcnt=$$(expr $$cnt + 1); \\ \tfi;\\ \tdone;\\ \techo \"same file num:\"$$(expr $$cnt + 1) ;\\ \tif [ $$cnt -eq $$(expr $(ntest) - 1) ]; then \\ \techo \"****************************************************************\";\\ \techo \"all res is the same!\";\\ \techo \"result content as follow.\";\\ \techo \"****************************************************************\";\\ \tcat main/res1;\\ \techo \"****************************************************************\";\\ \tfi   result  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  same file num:50 **************************************************************** all res is the same! result content as follow. **************************************************************** *** Starting wc test. --- wc test: PASS *** Starting indexer test. --- indexer test: PASS *** Starting map parallelism test. --- map parallelism test: PASS *** Starting reduce parallelism test. --- reduce parallelism test: PASS *** Starting job count test. --- job count test: PASS *** Starting early exit test. --- early exit test: PASS *** Starting crash test. --- crash test: PASS *** PASSED ALL TESTS ****************************************************************   ","description":"","tags":["Raft","分布式","6.824"],"title":"6.824 Lab1","uri":"/posts/6.824-lab1/"},{"content":"MIT 6.824（现在好像变成了 6.5840 reference schedule\ngo concurrency\nPingCAP Raft\nWenzha Zhang\nOneSizeFitsQuorum\nEfficient debug and test Debugging by Pretty Printing\n Humans are visual creatures so it’s a good idea to make use of visual tools like colors or columns to encode different types of information.\n  dslogs.py -\u003e build pretty printer for logs  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115  #!/usr/bin/env python import sys import shutil from typing import Optional, List, Tuple, Dict import typer from rich import print from rich.columns import Columns from rich.console import Console from rich.traceback import install # fmt: off # Mapping from topics to colors TOPICS = { \"TIMR\": \"#9a9a99\", \"VOTE\": \"#67a0b2\", \"LEAD\": \"#d0b343\", \"TERM\": \"#70c43f\", \"LOG1\": \"#4878bc\", \"LOG2\": \"#398280\", \"CMIT\": \"#98719f\", \"PERS\": \"#d08341\", \"SNAP\": \"#FD971F\", \"DROP\": \"#ff615c\", \"CLNT\": \"#00813c\", \"TEST\": \"#fe2c79\", \"INFO\": \"#ffffff\", \"WARN\": \"#d08341\", \"ERRO\": \"#fe2626\", \"TRCE\": \"#fe2626\", \"FORC\": \"#3571a4\", \"HEAR\": \"#ffcf3e\", \"STAT\": \"#cf5fb4\" } # fmt: on def list_topics(value: Optional[str]): if value is None: return value topics = value.split(\",\") for topic in topics: if topic not in TOPICS: raise typer.BadParameter(f\"topic {topic}not recognized\") return topics def main( file: typer.FileText = typer.Argument(None, help=\"File to read, stdin otherwise\"), colorize: bool = typer.Option(True, \"--no-color\"), n_columns: Optional[int] = typer.Option(None, \"--columns\", \"-c\"), ignore: Optional[str] = typer.Option(None, \"--ignore\", \"-i\", callback=list_topics), just: Optional[str] = typer.Option(None, \"--just\", \"-j\", callback=list_topics), ): topics = list(TOPICS) # We can take input from a stdin (pipes) or from a file input_ = file if file else sys.stdin # Print just some topics or exclude some topics (good for avoiding verbose ones) if just: topics = just if ignore: topics = [lvl for lvl in topics if lvl not in set(ignore)] topics = set(topics) console = Console() width = console.size.width panic = False for line in input_: try: time, topic, *msg = line.strip().split(\" \") # To ignore some topics if topic not in topics: continue msg = \" \".join(msg) # Debug calls from the test suite aren't associated with # any particular peer. Otherwise we can treat second column # as peer id if topic != \"TEST\": i = int(msg[1]) # Colorize output by using rich syntax when needed if colorize and topic in TOPICS: color = TOPICS[topic] msg = f\"[{color}]{msg}[/{color}]\" # Single column printing. Always the case for debug stmts in tests if n_columns is None or topic == \"TEST\": print(time, msg) # Multi column printing, timing is dropped to maximize horizontal # space. Heavylifting is done through rich.column.Columns object else: cols = [\"\" for _ in range(n_columns)] msg = \"\" + msg cols[i] = msg col_width = int(width / n_columns) cols = Columns(cols, width=col_width - 1, equal=True, expand=True) print(cols) except: # Code from tests or panics does not follow format # so we print it as is if line.startswith(\"panic\"): panic = True # Output from tests is usually important so add a # horizontal line with hashes to make it more obvious if not panic: print(\"#\" * console.width) print(line, end=\"\") if __name__ == \"__main__\": typer.run(main)   dstest.py -\u003e concurrency test  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251  #!/usr/bin/env python import itertools import math import signal import subprocess import tempfile import shutil import time import os import sys import datetime from collections import defaultdict from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED from dataclasses import dataclass from pathlib import Path from typing import List, Optional, Dict, DefaultDict, Tuple import typer import rich from rich import print from rich.table import Table from rich.progress import ( Progress, TimeElapsedColumn, TimeRemainingColumn, TextColumn, BarColumn, SpinnerColumn, ) from rich.live import Live from rich.panel import Panel from rich.traceback import install install(show_locals=True) @dataclass class StatsMeter: \"\"\" Auxiliary classs to keep track of online stats including: count, mean, variance Uses Welford's algorithm to compute sample mean and sample variance incrementally. https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#On-line_algorithm \"\"\" n: int = 0 mean: float = 0.0 S: float = 0.0 def add(self, datum): self.n += 1 delta = datum - self.mean # Mk = Mk-1+ (xk – Mk-1)/k self.mean += delta / self.n # Sk = Sk-1 + (xk – Mk-1)*(xk – Mk). self.S += delta * (datum - self.mean) @property def variance(self): return self.S / self.n @property def std(self): return math.sqrt(self.variance) def print_results(results: Dict[str, Dict[str, StatsMeter]], timing=False): table = Table(show_header=True, header_style=\"bold\") table.add_column(\"Test\") table.add_column(\"Failed\", justify=\"right\") table.add_column(\"Total\", justify=\"right\") if not timing: table.add_column(\"Time\", justify=\"right\") else: table.add_column(\"Real Time\", justify=\"right\") table.add_column(\"User Time\", justify=\"right\") table.add_column(\"System Time\", justify=\"right\") for test, stats in results.items(): if stats[\"completed\"].n == 0: continue color = \"green\" if stats[\"failed\"].n == 0 else \"red\" row = [ f\"[{color}]{test}[/{color}]\", str(stats[\"failed\"].n), str(stats[\"completed\"].n), ] if not timing: row.append(f\"{stats['time'].mean:.2f}± {stats['time'].std:.2f}\") else: row.extend( [ f\"{stats['real_time'].mean:.2f}± {stats['real_time'].std:.2f}\", f\"{stats['user_time'].mean:.2f}± {stats['user_time'].std:.2f}\", f\"{stats['system_time'].mean:.2f}± {stats['system_time'].std:.2f}\", ] ) table.add_row(*row) print(table) def run_test(test: str, race: bool, timing: bool): test_cmd = [\"go\", \"test\", f\"-run={test}\"] if race: test_cmd.append(\"-race\") if timing: test_cmd = [\"time\"] + test_cmd f, path = tempfile.mkstemp() start = time.time() proc = subprocess.run(test_cmd, stdout=f, stderr=f) runtime = time.time() - start os.close(f) return test, path, proc.returncode, runtime def last_line(file: str) -\u003e str: with open(file, \"rb\") as f: f.seek(-2, os.SEEK_END) while f.read(1) != b\"\\n\": f.seek(-2, os.SEEK_CUR) line = f.readline().decode() return line # fmt: off def run_tests( tests: List[str], sequential: bool = typer.Option(False, '--sequential', '-s', help='Run all test of each group in order'), workers: int = typer.Option(1, '--workers', '-p', help='Number of parallel tasks'), iterations: int = typer.Option(10, '--iter', '-n', help='Number of iterations to run'), output: Optional[Path] = typer.Option(None, '--output', '-o', help='Output path to use'), verbose: int = typer.Option(0, '--verbose', '-v', help='Verbosity level', count=True), archive: bool = typer.Option(False, '--archive', '-a', help='Save all logs intead of only failed ones'), race: bool = typer.Option(False, '--race/--no-race', '-r/-R', help='Run with race checker'), loop: bool = typer.Option(False, '--loop', '-l', help='Run continuously'), growth: int = typer.Option(10, '--growth', '-g', help='Growth ratio of iterations when using --loop'), timing: bool = typer.Option(False, '--timing', '-t', help='Report timing, only works on macOS'), # fmt: on ): if output is None: timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") output = Path(timestamp) if race: print(\"[yellow]Running with the race detector\\n[/yellow]\") if verbose \u003e 0: print(f\"[yellow] Verbosity level set to {verbose}[/yellow]\") os.environ['VERBOSE'] = str(verbose) while True: total = iterations * len(tests) completed = 0 results = {test: defaultdict(StatsMeter) for test in tests} if sequential: test_instances = itertools.chain.from_iterable(itertools.repeat(test, iterations) for test in tests) else: test_instances = itertools.chain.from_iterable(itertools.repeat(tests, iterations)) test_instances = iter(test_instances) total_progress = Progress( \"[progress.description]{task.description}\", BarColumn(), TimeRemainingColumn(), \"[progress.percentage]{task.percentage:\u003e3.0f}%\", TimeElapsedColumn(), ) total_task = total_progress.add_task(\"[yellow]Tests[/yellow]\", total=total) task_progress = Progress( \"[progress.description]{task.description}\", SpinnerColumn(), BarColumn(), \"{task.completed}/{task.total}\", ) tasks = {test: task_progress.add_task(test, total=iterations) for test in tests} progress_table = Table.grid() progress_table.add_row(total_progress) progress_table.add_row(Panel.fit(task_progress)) with Live(progress_table, transient=True) as live: def handler(_, frame): live.stop() print('\\n') print_results(results) sys.exit(1) signal.signal(signal.SIGINT, handler) with ThreadPoolExecutor(max_workers=workers) as executor: futures = [] while completed \u003c total: n = len(futures) if n \u003c workers: for test in itertools.islice(test_instances, workers-n): futures.append(executor.submit(run_test, test, race, timing)) done, not_done = wait(futures, return_when=FIRST_COMPLETED) for future in done: test, path, rc, runtime = future.result() results[test]['completed'].add(1) results[test]['time'].add(runtime) task_progress.update(tasks[test], advance=1) dest = (output / f\"{test}_{completed}.log\").as_posix() if rc != 0: print(f\"Failed test {test}- {dest}\") task_progress.update(tasks[test], description=f\"[red]{test}[/red]\") results[test]['failed'].add(1) else: if results[test]['completed'].n == iterations and results[test]['failed'].n == 0: task_progress.update(tasks[test], description=f\"[green]{test}[/green]\") if rc != 0 or archive: output.mkdir(exist_ok=True, parents=True) shutil.copy(path, dest) if timing: line = last_line(path) real, _, user, _, system, _ = line.replace(' '*8, '').split(' ') results[test]['real_time'].add(float(real)) results[test]['user_time'].add(float(user)) results[test]['system_time'].add(float(system)) os.remove(path) completed += 1 total_progress.update(total_task, advance=1) futures = list(not_done) print_results(results, timing) if loop: iterations *= growth print(f\"[yellow]Increasing iterations to {iterations}[/yellow]\") else: break if __name__ == \"__main__\": typer.run(run_tests)   configuration  1 2 3  # ~/.zshrc  alias dslogs=\"python ~/.pyScript/dslogs.py\" alias dstest=\"python ~/.pyScript/dstest.py\"    dslogs  VERBOSE=1 go test \u003e out\ndslog out -c 6\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  ❯ dslogs --help Usage: dslogs.py [OPTIONS] [FILE] ╭─ Arguments ────────────────────────────────────────────────────── │ file [FILE] File to read, stdin otherwise [default: None] ╰────────────────────────────────────────────────────────────────── ╭─ Options ──────────────────────────────────────────────────────── │ --no-color [default: True] │ --columns -c INTEGER [default: None] // \u003erf的数量 │ --ignore -i TEXT [default: None] // 不显示某些TAG │ --just -j TEXT [default: None] // 仅显示某些TAG │ --help Show this message and exit. ╰──────────────────────────────────────────────────────────────────    dstest  dstest -v 1 -s -p 10 -n 10 -o logs -r 2A\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ❯ dstest --help Usage: dstest.py [OPTIONS] TESTS... ╭─ Arguments ───────────────────────────────────────────────────────────────────────────────────────── │ * tests TESTS... [default: None] [required] ╰───────────────────────────────────────────────────────────────────────────────────────────────────── ╭─ Options ─────────────────────────────────────────────────────────────────────────────────────────── │ --sequential -s Run all test of each group in order │ --workers -p INTEGER Number of parallel tasks [default: 1] // 线程数 │ --iter -n INTEGER Number of iterations to run [default: 10] // 重复运行同一个任务 │ --output -o PATH Output path to use [default: None] │ --verbose -v INTEGER Verbosity level [default: 0] // 是否显示Dprintf内容 │ --archive -a Save all logs intead of only failed ones │ --race -r --no-race -R Run with race checker [default: no-race] │ --loop -l Run continuously // 测完后继续无限测试 │ --growth -g INTEGER Growth ratio of iterations when using --loop [default: 10] // 和loop配合使用，iter*=growth │ --timing -t Report timing, only works on macOS │ --help Show this message and exit. ╰─────────────────────────────────────────────────────────────────────────────────────────────────────   ","description":"","tags":["Raft","分布式","6.824","6.5840"],"title":"6.824","uri":"/posts/6.824/"},{"content":"RPC  Remote Procedure Call\n 特点 RPC 与 HTTP 并不是并列关系，RPC 是远程过程调用的规约，可以用 HTTP 进行信息的传输。\nRPC 的主要目的是做到不同服务间调用方法像同一服务间调用本地方法一样。\n大致流程是编码（protobuf），传输，接收，解码\n优点  用的是 HTTP2.0，只需要一个 TCP 协议就可以使得服务器和客户端在这个 TCP 协议的多个双向 Stream 上并发地传输数据 用了 protobuf，二进制并且比 json 更小  论文架构 Client, Client-Stub, RPC-Runtime, Server-Stub, Server\n实现 IDL (Interface description language) Descript the interface.\nTLV 编码  Tag：类型 Length：长度 Value：值（也可以是 TLV 结构）   GenCode Translate the IDL to different programming language.\nNeed decode and encode logic.\n兼容性——增加新的字段不影响现有服务\n通用性——跨平台跨语言\n性能——空间时间维度，编码后的数据大小和编码时长\nEncode Conv code to byte.\nProtocol Necessary data and metadata\n0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f +—————————————————————-+ | 0| LENGTH | +—————————————————————-+ | 0| HEADER MAGIC | FLAGS | +—————————————————————-+ | SEQUENCE NUMBER | +—————————————————————-+ | 0| Header Size(/32) | … +———————————\n Header is of variable size: (and starts at offset 14)  +—————————————————————-+ | PROTOCOL ID (varint) | NUM TRANSFORMS (varint) | +—————————————————————-+ | TRANSFORM 0 ID (varint) | TRANSFORM 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | INFO 0 ID (varint) | INFO 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | | | PAYLOAD | | | +—————————————————————-+\nLENGTH: 数据包大小，不包含自身\nHEADER MAGIC:标识版本信息，协议解析时快速校验\nSEQUENCE NUMBER:表示数据包的 seqlD，可用于多路复用，单连接内递增 HEADER SIZE:头部长度，从第 14 个字节开始计算一直到 PAYLOAD 前 PROTOCOL ID:编解码方式，有 Binary 和 Compact 两种 TRANSFORM ID:压缩方式，如 zlilb 和 snappy INFO ID:传递一些定制的 meta 信息 PAYLOAD:消息体\nNetwork Transfer Application Layer Sockets API TCP/UDP IP Driver Physical Layer reference\nhttp://ddia.vonng.com/#/ch4?id=%e6%9c%8d%e5%8a%a1%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae%e6%b5%81%ef%bc%9arest%e4%b8%8erpc\n","description":"","tags":null,"title":"RPC","uri":"/posts/rpc/"},{"content":"go-zero go-zero 简介 go-zero是一个能够快速生成 API，MODEL 和 RPC 的框架。\ngo-zero 项目结构（不含 RPC） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85  . ├── api │ ├── etc │ │ └── park-api.yaml │ ├── internal │ │ ├── config │ │ │ └── config.go │ │ ├── handler │ │ │ ├── accessHandler.go │ │ │ ├── deviceInfoHandler.go │ │ │ ├── incomeHandler.go │ │ │ ├── parkingLotHandler.go │ │ │ ├── routes.go │ │ │ ├── siteInfoHandler.go │ │ │ ├── touristCarProvinceHandler.go │ │ │ ├── touristFlowHandler.go │ │ │ ├── userHandler.go │ │ │ └── wechatHandler.go │ │ ├── logic │ │ │ ├── accessLogic.go │ │ │ ├── deviceInfoLogic.go │ │ │ ├── incomeLogic.go │ │ │ ├── parkingLotLogic.go │ │ │ ├── siteInfoLogic.go │ │ │ ├── touristCarProvinceLogic.go │ │ │ ├── touristFlowLogic.go │ │ │ ├── userLogic.go │ │ │ └── wechatLogic.go │ │ ├── svc │ │ │ └── serviceContext.go │ │ └── types │ │ └── types.go │ ├── park.api │ ├── park.go │ └── park.md ├── genModel │ ├── model │ │ ├── accessModel.go │ │ ├── accessModel_gen.go │ │ ├── deviceInfoModel.go │ │ ├── deviceInfoModel_gen.go │ │ ├── incomeModel.go │ │ ├── incomeModel_gen.go │ │ ├── logErrModel.go │ │ ├── logErrModel_gen.go │ │ ├── parkingLotModel.go │ │ ├── parkingLotModel_gen.go │ │ ├── siteInfoModel.go │ │ ├── siteInfoModel_gen.go │ │ ├── touristCarProvinceModel.go │ │ ├── touristCarProvinceModel_gen.go │ │ ├── touristFlowModel.go │ │ ├── touristFlowModel_gen.go │ │ ├── userModel.go │ │ ├── userModel_gen.go │ │ ├── vars.go │ │ ├── wechatModel.go │ │ └── wechatModel_gen.go │ └── resources │ ├── genModel.sh │ └── park.sql ├── go.mod ├── go.sum └── model ├── accessModel.go ├── accessModel_gen.go ├── deviceInfoModel.go ├── deviceInfoModel_gen.go ├── incomeModel.go ├── incomeModel_gen.go ├── logErrModel.go ├── logErrModel_gen.go ├── parkingLotModel.go ├── parkingLotModel_gen.go ├── siteInfoModel.go ├── siteInfoModel_gen.go ├── touristCarProvinceModel.go ├── touristCarProvinceModel_gen.go ├── touristFlowModel.go ├── touristFlowModel_gen.go ├── userModel.go ├── userModel_gen.go ├── vars.go ├── wechatModel.go └── wechatModel_gen.go    api 文件夹用于存放外部调用，需要改动的是 *.api, etc/*.yaml, svc/serviceContext.go, logic/*，作用分别是生成 api 调用框架，写配置文件，将数据添加到 Context 供逻辑调用，逻辑实现。 genModel 文件夹用于生成数据库调用相关实现，需要改动的是resources/*.sql。 model 文件夹用于添加额外的数据库调用逻辑（将genModel/model/*复制到 model 后开改！）  简单使用 通过 goctl 生成代码框架。\nAPI 框架通过 api/*.api生成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114  //park.api syntax = \"v1\" info( title: \"parkApi\" desc: \"parkBackEnd\" author: \"loomt\" email: \"loomt_@outlook.com\" version: \"1.0\" ) type ( accessResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 接入地点 \tDate string `json:\"date\"` // 接入日期 \tNum int64 `json:\"num\"` // 接入数量 \t} incomeResp { Id int64 `json:\"id\"` Type string `json:\"type\"` // 收入类型 \tDate string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 当天收入 \t} parkingLotResp { Id int64 `json:\"id\"` Name string `json:\"name\"` // 停车场名字 \tDuration int64 `json:\"duration\"` // 停车时间（小时） \tNum int64 `json:\"num\"` // 泊车数 \t} siteInfoResp { Id int64 `json:\"id\"` Date string `json:\"date\"` // 日期 \tRevisitRate int64 `json:\"revisit_rate\"` // 重复访问率（%） \tSiteHealth int64 `json:\"site_health\"` // 站点健康度 \tRfHealth int64 `json:\"rf_health\"` // 射频健康度 \tDeviceHealth int64 `json:\"device_health\"` // 设备健康度 \tFlow int64 `json:\"flow\"` // 当日站点流量 \t} touristFlowResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 园区地点 \tDate string `json:\"date\"` // 时间 \tNum int64 `json:\"num\"` // 游客数量 \t} touristCarProvinceResp { Id int64 `json:\"id\"` Province string `json:\"province\"` // 省份 \tDate string `json:\"date\"` // 日期 \tFlowNum int64 `json:\"flow_num\"` // 人流数量 \tCarNum int64 `json:\"car_num\"` // 车辆数 \t} userReq { Id int64 `json:\"id\"` // 用户 id \t} userResp { Id int64 `json:\"id\"` // 用户 id \tUsername string `json:\"username\"` // 用户名 \t} wechatResp { Date string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 微信关注数量 \t} deviceInfoResp { Id int64 `json:\"id\"` UplinkRate float64 `json:\"uplink_rate\"` // 上行速率 \tDownlinkRate float64 `json:\"downlink_rate\"` // 下载速率 \tFlow float64 `json:\"flow\"` // 流量 \tCpuRate float64 `json:\"cpu_rate\"` // CPU 占有率 \tLongitude float64 `json:\"longitude\"` // 经度 \tLatitude float64 `json:\"latitude\"` // 纬度 \t} ) @server( prefix: api ) service park-api { @doc \"获取接入详情\" @handler accessHandler get /access returns (accessResp) @doc \"获取日收入详情\" @handler incomeHandler get /income returns (incomeResp) @doc \"获取停车详情\" @handler parkingLotHandler get /parkingLot returns (parkingLotResp) @doc \"获取站点详情\" @handler siteInfoHandler get /siteInfo returns (siteInfoResp) @doc \"获取客流量详情\" @handler touristFlowHandler get /touristFlow returns (touristFlowResp) @doc \"获取游客与车辆来源省份\" @handler touristCarProvinceHandler get /touristCarProvince returns (touristCarProvinceResp) @doc \"获取用户详情\" @handler userHandler post /user (userReq) returns (userResp) @doc \"获取微信关注详情\" @handler wechatHandler get /wechat returns (wechatResp) @doc \"获取设备信息\" @handler deviceInfoHandler get /deviceInfo returns (deviceInfoResp) }   1 2  # api goctl api go -api *.api -dir ./ --style=goZero   MODEL 框架有两种生成方式  连接数据库生成 model  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/usr/bin/env zsh # 使用方法： # ./genModel.sh usercenter user # ./genModel.sh usercenter user_auth # 再将./genModel下的文件剪切到对应服务的model目录里面，记得改package #生成的表名 tables=$2 #表生成的genmodel目录 modeldir=../model # 数据库配置 host=127.0.0.1 port=3306 dbname=$1 username=root passwd=123456 echo \"开始创建库：$dbname的表：$2\" goctl model mysql datasource -url=\"${username}:${passwd}@tcp(${host}:${port})/${dbname}\" -table=\"${tables}\" -dir=\"${modeldir}\" --style=goZero    直接用 sql 文件 (genModel/resource/*.sql) 生成 model  1 2  # genModel/resources goctl model mysql ddl -src=\"./*.sql\" -dir=\"../model\" --style=goZero   生成文档 1 2  # ./ goctl api doc -dir .   华为云部署  mysql 导入 nohup go run *.go -f etc/*.yaml 2\u003e\u00261 \u0026  ","description":"","tags":["go-zero"],"title":"go-zero 单体服务","uri":"/posts/go-zero%E5%8D%95%E4%BD%93%E6%9C%8D%E5%8A%A1/"},{"content":"记一次华为云耀云服务器公网部署问题 开了安全组，用 caddy 部署了一个小网页来测试公网访问 可以看到内网访问是正常的。也可以 ping 通\n根据华为云官网给出的指引排查了很久，绑定了弹性公网 ip，设置了安全组 Sys-FullAccess、ACL，都无法用浏览器访问。\n最后回到服务器 查询防火墙状态\n关掉防火墙就可以了 对着华为云的控制台搞了很久安全组，还以为安全组哪里配错了，最后发现是服务器防火墙的问题😭\n","description":"","tags":["云服务器"],"title":"华为云公网部署","uri":"/posts/%E5%8D%8E%E4%B8%BA%E4%BA%91%E5%85%AC%E7%BD%91%E9%83%A8%E7%BD%B2/"},{"content":" 摆烂，于是将目光看向了家里的小米 4a 千兆版路由器，准备刷个 Openwrt 玩一下。\n 去恩山论坛逛了逛，感觉刷软路由和刷手机差不太多。\n 安装 Breed（闭源免费的 BootLoader，又称“不死鸟”，有了它就能肆无忌惮地刷各种第三方包了  如果你的路由器是小米 4A 千兆版，可以直接用恩山论坛的无脑直装 Breed；如果不是，也可以去Breed 官网下载路由器的适配包并自行搜索如何通过 Telnet 连接路由器并刷入 Breed。 用 Breed 安装 OpenWrt  这里放一个小米 4A 千兆版 OpenWrt 直刷包，其他路由器的固件可以去恩山论坛逛逛。 .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 警告\n刷 OpenWrt 之前必须用 Breed 备份 eeprom（没有备份 eeprom 将导致 5G 信号奇差）\n 点击固件更新~\u003e常规固件~\u003e勾上“固件”和“EEPROM”，选择好上面的直刷包和备份的 eeprom.bin，上传即可。\n配置 OpenWrt 的各项参数（随便配一下即可  OpenWrt 可谓神通广大，作为一个在路由器上跑的 Linux，它可以装上各种插件：酸酸乳、Docker、网易云解锁灰色歌曲……\n但我折腾了一通，调教好基础的上网功能后，感觉网络状况大不如前。作为百来块的路由器，本来就没有多大的内存，感觉原厂固件的调教已经将性能都用在刀刃上了。装了 OpenWrt 后虽然上下行流量速度没有很大变化，但稳定性差了很多，便懒得继续折腾，忍痛 remake 了。\n刷回官方包（没备份 eeprom 的问题 或许 也可以通过刷回官方包的方法解决  下载小米 4A 千兆版官方包，进入 Breed~\u003e固件更新~\u003e编程器固件 (仅勾选自动重启)~\u003e上传 all.bin。\n","description":"","tags":null,"title":"小米 4A 千兆版刷 OpenWrt","uri":"/posts/%E5%B0%8F%E7%B1%B34a%E5%8D%83%E5%85%86%E7%89%88%E5%88%B7openwrt/"},{"content":"7-Zip 双击自动解压压缩文件  因为难以忍受 7zip 的右键解压操作，通过修改注册表以自动解压。\n  替换 D:\\\\000000000000\\\\7-Zip 为 your\\\\path\\\\to\\\\7-Zip 将代码塞进.reg 文件，双击即可。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421  Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\7-Zip.001\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\"   reference\nhttps://gist.github.com/zabbarob/5891200\n","description":"","tags":null,"title":"Auto7zip","uri":"/posts/auto7zip/"},{"content":" 前段时间白嫖了一个 域名 ，暑假有时间了赶紧物尽其用，于是花了一天的时间重新建了个站（其实我很久之前就用过 hexo 无脑建站，但最近发现了一个特别喜欢的Hugo主题 MemE ）\n 简略步骤 Hugo Quick Start  在 wsl 下装 Hugo  1  $ sudo apt install hugo   TL;DR 一下 Hugo 的基础命令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  $ tldr hugo hugo Template-based static site generator. Uses modules, components, and themes.More information: https://gohugo.io. - Create a new Hugo site: hugo new site {{path/to/site}} - Create a new Hugo theme (themes may also be downloaded from https://themes.gohugo.io/): hugo new theme {{theme_name}} - Create a new page: hugo new {{section_name}}/{{filename}} - Build a site to the ./public/ directory: hugo - Build a site including pages that are marked as a \"draft\": hugo --buildDrafts - Build a site to a given directory: hugo --destination {{path/to/destination}} - Build a site, start up a webserver to serve it, and automatically reload when pages are edited: hugo server   新建站点  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $ hugo new site loomt Congratulations! Your new Hugo site is created in /home/loomt/temp/loomt. Just a few more steps and you are ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. $ cd loomt $ tree . ├── archetypes │ └── default.md ├── config.toml ├── content ├── data ├── layouts ├── static └── themes   配置主题  $ git init # 将皮肤作为submodule添加，以便更新 $ git submodule add https://github.com/reuixiy/hugo-theme-meme.git themes/meme # MeME，很喜欢的一个主题 $ git submodule add https://github.com/martignoni/hugo-notice.git themes/hugo-notice # hugo-notice，插件主题（很轻，开箱即用） $ rm config.toml \u0026\u0026 cp themes/meme/config-examples/zh-cn/config.toml config.toml #覆盖配置文件 发布文章  1 2  $ hugo new posts/HelloWorld.md #会在centent下面创建markdown文件，可以直接去编辑 Content \"/home/loomt/temp/loomt/content/posts/HelloWorld.md\" created   运行本地服务  1  $ hugo server -D --verbose # 在本地运行 -D是渲染草稿 --verbose显示详细输出   目前已经完成基本配置，可以访问运行在本机的站点了 🥳\n接下来还可以将网站部署到 Github Page，Vercel 或者 Netlify 等免费的静态资源托管商。\nHugo 部署到 Github Page Hugo 是一个网站构建工具，hugo命令生成的 public 文件夹存放的是静态的部署页面，我们只需要将其放在 Github Page 中即可。建议开两个仓库，一个仓库用于存放根目录，另一个用于存放./public 文件夹的内容，以便被 Github Page 部署。\n 因为根目录可能有敏感信息和暂时不希望公开的草稿，又为了让其得到有效的版本控制，可以开一个私有仓库存放根目录，\n而 publishDir(./pubic) 作为输出的静态页面，则适合放在公开的仓库 而且 Github Page 不公开没法白嫖\n 默认看到这里的同学已经建好了仓库，并完成了仓库的初始化和配置 🤗\n下面假设更新了文章，需要同步到两个仓库。\n1 2 3 4 5 6 7 8  $ hugo --gc --cleanDestinationDir # 生成静态站点到./public的同时 清除缓存和静态站点用不着的文件 $ git add . $ git commit -m \"update source code\" $ git push $ cd public $ git add . $ git commit -m \"update Github Page\" $ git push   是不是感觉要 push 两次非常麻烦，可以写一个 push.sh 来简化操作，还可以加个 Github Actions，简化每次更新站点的步骤，具体可阅读 GitHub Actions 官方文档，actions-gh-pages 以及 reuixiy 的博客 。\n自动化部署   如果源码仓库和 Github Page 仓库都是公有的话可以阅读 actions-gh-pages 进行简单的配置。\n  如果源码仓库是私有的，Github Page 仓库是公开的话，可以参考以下配置方案。\n   配置公钥和私钥到仓库  需要生成 SSH key pair 以获取源码仓库对 Github Page 仓库修改的权限。\n$ mkdir -p ~/.ssh/blog $ cd ~/.ssh/blog $ ssh-keygen -t rsa -b 4096 -C \"yourname@users.noreply.github.com\" # 注意：不要无脑回车，最好开一个文件夹存公钥私钥，不然会覆盖掉以前的  id_rsa（私钥）  前往 Github Page 仓库，Settings \u003e Deploy Keys \u003e Add deploy key。\n需要勾选 Allow write access。\n id_rsa.pub（公钥）  前往源码仓库，Settings \u003e Secrets \u003e Actions \u003e New repository secret。\nName 需要设为 ACTIONS_DEPLOY_KEY\n新建 Workflow 配置文件  下面粘一下我的配置方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  # .github/workflows/build.ymlname:Hugo automated deploymenton:push:branches:- main # Set a branch name to trigger deploymentjobs:deploy:runs-on:ubuntu-latestpermissions:contents:writeconcurrency:group:${{ github.workflow }}-${{ github.ref }}steps:- uses:actions/checkout@v3with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:'0.92.2'extended:true- name:Buildrun:hugo --gc --minify# - name: Deploy# uses: peaceiris/actions-gh-pages@v3# # If you're changing the branch from main,# # also change the `main` in `refs/heads/main`# # below accordingly.# if: ${{ github.ref == 'refs/heads/main' }}# with:# github_token: ${{ secrets.GITHUB_TOKEN }}# publish_dir: ./public- name:Deploy # 此处需要按照自己实际修改uses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}external_repository:loomts/loomts.github.iopublish_branch: main # default:gh-pagespublish_dir:./public  推送到 Github  1 2 3  $ git add . $ git commit -m \"setup auto deploy\" $ git push   打开你的源码仓库页面，点击 Actions 查看日志，顺利的话已经搞定了，以后每次 git push Github Workflow 都会自动帮你更新网站了。\nGithub Page 绑定自定义域名 假设已经有了域名，还需要在域名的 DNS 服务商那里加一个 CNAME（用于 dns 跳转）。\n   name type value     www CNAME loomts.github.io    一段时间后，回到 Github Page 仓库，在 Settings \u003e Pages \u003e Custom domain 处填上自己的域名，等待几小时生成证书，然后勾选 Enforce HTTPS。\n还要记得添加 your domain到 static/CNAME，以生成到静态文件。。\n1  $ echo \"your domain\" \u003e static/CNAME    Custom domains are stored in a CNAME file in the root of your publishing source. You can add or update this file through your repository settings or manually. For more information, see \" Managing a custom domain for your GitHub Pages site .\" ——Github Docs\n Hugo 部署到 Vercel Vercel 可以看作是结合了 Github Page 还有 Github Actions 的用于前端框架和静态站点管的平台，直接导入 Github 仓库即可部署，感觉配置起来比 Github Action 无脑很多，很适合我，所以我已经放弃 Github Action，全面转为 Vercel 了。需要注意的是注册域名的时候要去域名注册商改一下 DNS 服务器，或者每个站点都添加一次 A 记录。\nHugo 个性化配置 皮肤配置 可以根据皮肤作者的文档改变皮肤的各种 feature，如 MeME 的 config.toml example\n.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\nconfig.toml 的 baseURL 要加 https:// ，否则生成的静态页面 css 和 js 加载会出问题。\n 自定义 CSS 和 JS  利用 hugo 的替换规则  当你需要更改某个页面的生成规则（包括 CSS 和 JS），你可以将 themes/your-theme 里面的东西复制一份到你的根目录，然后爽改逻辑，hugo 生成静态页面时在同等情况下会优先用你根目录下的文件。\n如果你想要自己新建一个 js 或者 css 文件，可以看hugo-pipes，但如果你不打算做一个开源主题，无脑在 html 文件里面堆 style 和 script 是能跑的选择！  比如，我有这样一个需求：在 Wiki 页面分层次显示我的笔记，但又不让笔记内容在主页面显示，并且 Wiki 页需要按照文件夹的内部结构展示，那就用categories的方式组织 content/wiki 的内容，仅需要改一下 MeME 主题 tree-sections 的内容，并配置一下 config.toml 即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  \u003cmain class=\"main list\" id=\"main\"\u003e \u003cdiv class=\"main-inner\"\u003e \u003cdiv class=\"content categories\"\u003e {{ if .Site.Params.displayListTitle }} \u003ch1 class=\"list-title\"\u003e {{ \"Wiki\"}} \u003c/h1\u003e \u003cdiv\u003e 存点笔记，仅作参考😶‍🌫️ \u003c/div\u003e {{ end }} \u003cdiv class=\"tree\"\u003e \u003cul class=\"list-categories\" style=\"display: block;\"\u003e {{ partial \"utils/tree-sections.html\" . }} {{ $sections := .Scratch.Get \"sections\" }} {{ $pages := .Scratch.Get \"pages\" }} {{ range $index, $page := $pages }} {{ $depth := (len (split (strings.TrimPrefix \"/\" $page) \"/\")) }} {{ with $.Site.GetPage $page }} {{ $linkTarget := .}} {{ $depthPrev := 0 }} {{ if ge $index 1 }} {{ $pagePrev := index $pages (sub $index 1) }} {{ $depthPrev = len (split (strings.TrimPrefix \"/\" $pagePrev) \"/\") }} {{ end }} {{ $depthNext := 0 }} {{ if lt $index (sub (len $pages) 1) }} {{ $pageNext := index $pages (add $index 1) }} {{ $depthNext = len (split (strings.TrimPrefix \"/\" $pageNext) \"/\") }} {{ end }} {{ if or (le $depth $depthPrev) (eq $index 0) }} \u003cli\u003e {{ end }} {{ if and (gt $depth $depthPrev) (ne $index 0) }} \u003cul class=\"list-categories\" style=\"display: block;\"\u003e \u003cli\u003e {{ end }} {{ $name := index $sections $index }} \u003cdiv class=\"category-item\"\u003e {{ .LinkTitle | default $name}} {{ if $.Site.Params.displayPostsCount }} {{ $sectionPage := .CurrentSection }} {{$.Scratch.Delete \"pages\" }} {{ range $.Site.RegularPages }} {{ if (.IsDescendant $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end}} {{ end }} {{ $pages := $.Scratch.Get \"pages\"}} \u003cspan class=\"category-count\"\u003e {{printf \"(%d)\" (len $pages)}} \u003c/span\u003e {{ end }} \u003c/div\u003e {{ if $.Site.Params.displayPosts }} {{ $sectionPage := .CurrentSection }} {{ $.Scratch.Delete \"pages\"}} {{ range $.Site.RegularPages }} {{ if (.InSection $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end }} {{ end }} {{ $pages := $.Scratch.Get \"pages\" }} {{ partial \"utils/limit-tree-posts.html\" (dict \"$\" $ \"pages\" $pages \"linkTarget\" $linkTarget) }} {{ end }} {{ if and (gt $depth $depthNext) (ne $index (sub (len $pages) 1)) }} {{ range seq (sub $depth $depthNext) }} {{ if le . (sub $depth $depthNext) }} \u003c/li\u003e \u003c/ul\u003e {{ end }} {{ end }} {{ end }} {{ if ge $depth $depthNext }} \u003c/li\u003e {{ end }} {{ end }} {{ end }} \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/main\u003e \u003cscript\u003e let lis = document.querySelectorAll(\"ul.list-categories \u003e li\"); lis.forEach(li =\u003e { li.querySelector(\".category-item\").addEventListener(\"click\", event =\u003e { event.stopPropagation(); // 阻止事件冒泡  let sonul = li.querySelector(\"ul\"); sonul.style.display = sonul.style.display === \"block\" ? \"none\" : \"block\"; if (sonul.nextElementSibling) { sonul.nextElementSibling.style.display = sonul.nextElementSibling.style.display === \"block\" ? \"none\" : \"block\"; } }); }) \u003c/script\u003e   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  [menu] ## 菜单栏 [[menu.main]] pageref = \"/posts/\" name = \"Posts\" weight = 2 pre = \"internal\" post = \"archive\" [[menu.main]] pageref = \"/tags/\" name = \"Tags\" weight = 4 pre = \"internal\" post = \"tags\" [[menu.main]] pageref = \"/about/\" name = \"About\" weight = 5 pre = \"internal\" post = \"user-circle\" [[menu.main]] # add wiki page pageref = \"/wiki/\" name = \"Wiki\" weight = 6 pre = \"internal\" post = \"wiki\" [[menu.main]] weight = 7 identifier = \"theme-switcher\" [[menu.main]] weight = 8 identifier = \"lang-switcher\" [[menu.main]] weight = 9 identifier = \"search\" post = \"search\"   Hugo + Algolia search Algolia 可以提供 AI 搜索服务，但需要在更新站点时用 POST 请求上传 algolia.json(站点信息) 给 Algolia，以帮助 Algolia 实现搜索服务。按照要求新建站点以及配置 api 即可，上传 algolia.json 可以使用hugo-algolia。因为 MeME 主题有一定的 algolia search 支持，下面仅给出上传 algolia.json 方面的配置。\n1  $ npm install hugo-algolia   但 hugo-algolia 的 toml 解析在我这里好像有点问题，可能是 config.toml 的配置已经太乱了，无法优雅地解决\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ hugo-algolia -s -t --config config.toml JSON index file was created in public/algolia.json /usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50 throw new errors.AlgoliaSearchError('Please provide an application ID. ' + usage); ^ AlgoliaSearchError: Please provide an application ID. Usage: algoliasearch(applicationID, apiKey, opts) at AlgoliaSearchNodeJS.AlgoliaSearchCore (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50:11) at AlgoliaSearchNodeJS.AlgoliaSearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearch.js:11:21) at AlgoliaSearchNodeJS.AlgoliaSearchServer (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/AlgoliaSearchServer.js:17:17) at new AlgoliaSearchNodeJS (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:83:23) at algoliasearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:68:10) at HugoAlgolia.HugoAlgolia.sendIndex (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:184:20) at HugoAlgolia.HugoAlgolia.index (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:122:12) at Object.\u003canonymous\u003e (/usr/local/lib/node_modules/hugo-algolia/bin/index.js:23:26) at Module._compile (internal/modules/cjs/loader.js:999:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1027:10)   无奈之下新建了一个 config.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13  ---baseurl:\"/\"DefaultContentLanguage:\"zh-cn\"hasCJKLanguage:truelanguageCode:\"zh-cn\"title:\"loomt's Blog\"theme:\"MeME\"metaDataFormat:\"yaml\"algolia:index:\"your index\"key:\"your admin key\"appID:\"your appID\"---  1 2 3  $ hugo-algolia -s JSON index file was created in public/algolia.json { updatedAt: '2023-01-12T14:40:31.454Z', taskID: 173970040001 }    用 Vercel 还有一个原因是白嫖国外的服务器不用备案😭\n reference\nhttps://gohugo.io/getting-started\nhttps://blog.aozaki.cc/blog/hugo-deployment-debugging\nhttps://io-oi.me/tech/hugo-vs-hexo\nhttps://github.com/MunifTanjim/minimo/issues/189\nhttps://zenlian.github.io/posts/tools/github-actions-hugo\nhttps://github.com/peaceiris/actions-gh-pages\nhttps://gohugo.io/content-management/sections\nhttps://gohugo.io/templates\nhttps://gohugo.io/hugo-pipes\n","description":"","tags":["Github Page","建站"],"title":"建站","uri":"/posts/%E5%BB%BA%E7%AB%99/"}]