[{"content":"Raft Raft is a protocol for implementing distributed consensus.\n!!guidance\npaper\ndiagram\ngif\nstructure\nlocking\nOverview Raft解决的是分布式一致性的问题\nlet’s assume it’s a server cluster, all server has 3 state\n Leader Election   at first, all server is a follower, they wanna to become a election if don' t receive heartbeat. election timeout: wait until becoming a candidate, randomized to be between 150ms and 300ms after election timeout, the follower becomes a candidate and starts a new election term(old term + 1) the candidate vote for itself, and sends out Request Vote messages to peers if the receiving peer hasn’t voted yet in this term then it votes for the candidate and the node reset its election timeout once a candidate has a majority of votes it becomes leader then the leader begins sending out Append Entries messages to its followers these messages are sent in intervals specified by the heartbeat timeout then the followers response the heartbeat until the leader crash if the the follower can’t receive heartbeat during election timeout, it will become a new candidate if two candidate become the leader at the same time, they will know that there is a same term leader in this cluster, and both of them will stop heartbeat, then a new leader born.   Log Replication   log replication done by the same Append Entries message that used for heartbeats client send a command to one node of a elected cluster，if this server is a follower, it will send this command to its leader leader save command as an entry, and replicates it to followers leader waits until a majority of nodes have written the entry leader commit(run command), and a response is sent to the client then the follower commit  Tips  heartbeat timeout » election timeout election timeout not only the timeout to start a election, but also a timeout to restart a election, so election timeout must not be to short   The paper’s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the leader sends heartbeats considerably more often than once per 150 milliseconds. Because the tester limits you to 10 heartbeats per second, you will have to use an election timeout larger than the paper’s 150 to 300 milliseconds, but not too large, because then you may fail to elect a leader within five seconds.\n  concurrence Split atomicity as much as possible, but not this condition  1 2 3 4 5 6 7  // wrong, state and currentTerm have a close relationship, they must be atomic. rf.mu.Lock() rf.state = Leader rf.mu.Unlock() rf.mu.Lock() rf.currentTerm++ rf.mu.Unlock()   Bugs  Election detail  在startEletion()函数里面，我发送的args如下\nargs := RequestVoteArgs{ Term: rf.currentTerm + 1, CandidateId: rf.me, LastLogIndex: len(rf.logs) - 1, LastLogTerm: rf.logs[len(rf.logs)-1].Term, } 投票选举时，其中一个条件是rf.votedFor != -1 \u0026\u0026 rf.votedFor != args.CandidateId \u0026\u0026 rf.currentTerm == args.Term // 在本轮选举已经投票，这一部分在逻辑上没有问题。\n1 2 3 4  if rf.currentTerm \u003e args.Term || (rf.votedFor != -1 \u0026\u0026 rf.votedFor != args.CandidateId \u0026\u0026 rf.currentTerm == args.Term) || rf.logs[len(rf.logs)-1].Term \u003e args.LastLogTerm || (rf.logs[len(rf.logs)-1].Term == args.LastLogIndex \u0026\u0026 len(rf.logs)-1 \u003e args.LastLogIndex) { reply.Term, reply.VoteGranted = rf.currentTerm, false return }   但是因为上面startElection()发送的Term为currentTerm+1，说明currentTerm没有自增。\n我是故意的，因为我觉得当candidate成为leader之后才开启一个新的term是符合常理的，但是通过debug，我发现存在两人几乎同时开始选举，candidates 互相投票的情况。\n To begin an election, a follower increments its current term and transitions to candidate state.\n 改起来倒是简单，只要先自增currentTerm再发送RequestVote就可以惹。\nTimeout 当用户完成选举时，需要立即发送heartbeat，告诉别人自己是老大。因为我是用time.Timer实现的，所以要将Timer Reset一下，保证Timer在下一毫秒 timeout 。  1 2 3 4 5 6 7 8 9  if grantedNum \u003e len(rf.peers)/2 \u0026\u0026 rf.state == Candidate { rf.state = Leader for i, _ := range rf.peers { rf.nextIndex[i] = len(rf.logs) rf.matchIndex[i] = 0 } rf.heartbeatTimer.Reset(getRightNowDuration()) DPrintf(dState, \"S%v -\u003e leader %v term\", rf.me, rf.currentTerm) }    data race\n  pay more attention to paper\n  写完lab2B之后，错误率一直保持在5%左右，然后再看了一遍论文和 Students' Guide to Raft，找到两处和我的实现不符的地方。虽然自己感觉没问题，但还是去看了一下别人的实现，好像几乎都是按照论文的实现\n If there exists an N such that N \u003e commitIndex, a majority of atchIndex[i] ≥ N, and log[N].term == currentTerm: set commitIndex = N (§5.3, §5.4).\n  Each log entry also has an integer index iden-tifying its position in the log.\n 如果直接让 leader commitIndex = lastLog.index 的话会有 concurrence 问题，没想到除了论文之外更快的方法，只能无脑遍历以更新commitIndex了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func (rf *Raft) updCommitIndex() { for N := rf.getLastLog().Index; N \u003e rf.commitIndex; N-- { cnt := 1 for p := range rf.peers { if rf.matchIndex[p] \u003e= N \u0026\u0026 rf.log[N].Term == rf.currentTerm { cnt++ } } if cnt \u003e len(rf.peers)/2 { rf.commitIndex = N rf.applyWaker \u003c- 1 break } } }   res test\n1 2 3 4 5 6 7 8 9 10  ❯ dstest -v 1 -s -p 100 -n 2000 -o logs -r 2A Running with the race detector Verbosity level set to 1 ┏━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━┓ ┃ Test ┃ Failed ┃ Total ┃ Time ┃ ┡━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━┩ │ 2A │ 0 │ 2000 │ 20.36 ± 1.55 │ └──────┴────────┴───────┴──────────────┘   ","description":"","tags":null,"title":"6.824 Lab2A","uri":"/posts/6.824-lab2/"},{"content":"Lab1 MapReduce  EndTime: 2023/2/3\n Paper MapReduce: Simplified Data Processing on Large Clusters\nMapReduce 将分布式系统处理数据的细节（并行、容错、局部性优化、负载均衡等）隐藏起来，提供一套简化方案，解决了在多台机器处理大量逻辑简单的计算（分布式计算）实现复杂的问题。\n实现 本实验可以由1个 coordinator/master 调度若干个 worker。先完成所有 map 任务，生成中间键值对并将其存在中间文件后再进行 reduce 任务，最后将 reduce 任务的结果输出到文本。\n需要我们修改的文件为 mr/*\n worker 通过 RPC 循环请求任务。 coordinator 读取 8 个给定的文件分给不同的 worker 进行 map 任务，这部分如果喜欢也可以按固定 bytes 进行切割但我懒得处理了。 worker 读取文件并扔给fmap进行处理，生成中间键值对，计算字符串的 hash 后将key-intermediate_value存在 mr-taskid-ihash(str) 里面。   fmap 函数通过编译生成的 *.so 调用\n .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\n看到一些同学是先 os.CreateTemp(\"\", tmpFileName) 存在临时文件里面，等处理完了再 rename 成mr-taskid-ihash(str)。这样应该会更加规范一些，但不创建 tempfile 在 lab1 理论上应该也是可行的。\n当文件没完全写完 worker 就 crash 时，这个任务会被 coordinator 发现并交给别的 worker 重做。因为用的是os.Create()，文件会被新的覆盖，直到 worker 成功完成任务为止。\n如果逻辑允许两个 worker 同时处理一个任务的话，就需要创建 tempFile 再 rename 的方式，因为需要保证创建的（临时）文件内容不重复。\n map 任务全部完成后 coordinator 分配 NReduce 个 reduce 任务给不同的 worker 处理。 worker读取中间文件，并将key-list(intermediate_value)扔给freduce处理成key-value 写入mr-out-ihash(str)。 coordinator 发现任务全都处理完后踢走 worker ，并在若干秒后退出。  Tips   结构\n  go 可以用 const 和 iota 代替 enum。\n  WorkerInfo 在这个实验可以省略，不需要保留 worker 的状态，但我写了就不想删了。\n  本来还想往结构体内置一个 logger 的，但RPC调用需要gob序列化，而 logger 不知道为啥会序列化失败，不知道是啥 bug ，以后再瞅瞅。\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  const ( _ = iota // MAP REDUCE WAIT: Task type \tMAP REDUCE WAIT // IDLE BUSY DONE: Task status || WorkerInfo status \tIDLE BUSY DONE ) type Coordinator struct { NMap int // map 任务的个数 \tNReduce int // reduce 任务的个数 \tDMap int // 记录map task完成的个数 \tDReduce int // 记录reduce task完成的个数 \tWorkerId int // 为新的worker分配workerIds \tTaskDone map[int]bool // 记录task是否被完成 \tMap chan *Task // 待取出的map task \tReduce chan *Task // 待取出的reduce task \tTaskMutex sync.Mutex // 用于任务分发相关数据的mutex \tDoneMutex sync.Mutex // 用于完成任务相关数据的mutex \tMutex sync.Mutex // 用于其他细节的mutex } type Task struct { StartTime time.Time NReduce int // 传给worker，用于ihash 的mod \tType int // MAP REDUCE WAIT \tStatus int // IDLE BUSY DONE \tFileName string TaskId int WorkerId int } type WorkerInfo struct { WorkerId int TaskId int Type int Status int //Lg *log.Logger \t//Why this error? \t//gob: type log.Logger has no exported fields \t//2023/01/31 14:34:13 RPC getWork failed \t//exit status 1 } // Map functions return a slice of KeyValue. type KeyValue struct { Key string Value string }   RPC写入reply的时候不能直接将reply指向一个新的地址，而是要修改reply地址的值。  1 2 3 4 5 6 7 8 9 10 11 12  //reply = \u0026GetWorkReply{\u0026Task{...}} \t//上面的方法不会返回想要的reply，因为reply指向的是新的GetWorkReply值在rpc服务器的指针。这部分客户端的内存和服务器的不一样，所以得到的是空值；下面的方法因为 reply是共享内存的，所以服务器和客户端都可以访问 \u0026reply。 \t//在RPC调用时，要避免传递指针参数，如果传递的参数是值类型，那么这个值将会被复制到另一个地址 \t*reply = GetWorkReply{Task{ StartTime: time.Now(), Type: MAP, Status: BUSY, FileName: mapTask.FileName, NReduce: c.NReduce, WorkerId: args.WorkerId, TaskId: mapTask.TaskId, }} // equal to reply.Task = \u0026Task{...}   clash test，需要coordinator在worker宕机10s后为同一个任务重新分配worker,这部分需要考虑一下注意一下 data race  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  go func(taskId int, filename string) { select { case \u003c-time.After(12 * time.Second): c.Mutex.Lock() if !c.TaskDone[taskId] { c.Mutex.Unlock() dosomething } else { c.Mutex.Unlock() dootherthing } // default:{  // }  // default不能写，如果写了就会直接跳到default，不会进入12s的case  } return }(maptask.TaskId, mapTask.FileName)   并发编程细节  因为 MapReduce 的特性，map task 可以并发，reduce task 可以并发，但两种任务不能同时并发，所以需要等到 map task 跑完才可以进行 reduce task。如果同时读写同一个变量，需要加锁。其实还可以用 chan 实现 lock-free ，以后试试，如果有时间的话。\n贴一下测试的 makefile  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # location: src/Makefile ntest := 50 lab1: @cd main;\\  for i in $$(seq 1 $(ntest)) ; do\\  bash test-mr.sh \u003e res$$i;\\  done;\\  cnt=0;\\ \tfor i in $$(seq 1 $$(expr $(ntest) - 1)); do\\ \tif cmp res$$i res$$(expr $$i + 1); then \\ \tcnt=$$(expr $$cnt + 1); \\ \tfi;\\ \tdone;\\ \techo \"same file num:\"$$(expr $$cnt + 1) ;\\ \tif [ $$cnt -eq $$(expr $(ntest) - 1) ]; then \\ \techo \"****************************************************************\";\\ \techo \"all res is the same!\";\\ \techo \"result content as follow.\";\\ \techo \"****************************************************************\";\\ \tcat main/res1;\\ \techo \"****************************************************************\";\\ \tfi   result  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  same file num:50 **************************************************************** all res is the same! result content as follow. **************************************************************** *** Starting wc test. --- wc test: PASS *** Starting indexer test. --- indexer test: PASS *** Starting map parallelism test. --- map parallelism test: PASS *** Starting reduce parallelism test. --- reduce parallelism test: PASS *** Starting job count test. --- job count test: PASS *** Starting early exit test. --- early exit test: PASS *** Starting crash test. --- crash test: PASS *** PASSED ALL TESTS ****************************************************************   ","description":"","tags":null,"title":"6.824 Lab1","uri":"/posts/6.824-lab1/"},{"content":"MIT 6.824（现在好像变成了6.5840 schedule go并发编程\nlab1 solution\nEfficient debug and test Debugging by Pretty Printing\n Humans are visual creatures so it’s a good idea to make use of visual tools like colors or columns to encode different types of information.\n  dslogs.py -\u003e build pretty printer for logs  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115  #!/usr/bin/env python import sys import shutil from typing import Optional, List, Tuple, Dict import typer from rich import print from rich.columns import Columns from rich.console import Console from rich.traceback import install # fmt: off # Mapping from topics to colors TOPICS = { \"TIMR\": \"#9a9a99\", \"VOTE\": \"#67a0b2\", \"LEAD\": \"#d0b343\", \"TERM\": \"#70c43f\", \"LOG1\": \"#4878bc\", \"LOG2\": \"#398280\", \"CMIT\": \"#98719f\", \"PERS\": \"#d08341\", \"SNAP\": \"#FD971F\", \"DROP\": \"#ff615c\", \"CLNT\": \"#00813c\", \"TEST\": \"#fe2c79\", \"INFO\": \"#ffffff\", \"WARN\": \"#d08341\", \"ERRO\": \"#fe2626\", \"TRCE\": \"#fe2626\", \"FORC\": \"#3571a4\", \"HEAR\": \"#ffcf3e\", \"STAT\": \"#cf5fb4\" } # fmt: on def list_topics(value: Optional[str]): if value is None: return value topics = value.split(\",\") for topic in topics: if topic not in TOPICS: raise typer.BadParameter(f\"topic {topic}not recognized\") return topics def main( file: typer.FileText = typer.Argument(None, help=\"File to read, stdin otherwise\"), colorize: bool = typer.Option(True, \"--no-color\"), n_columns: Optional[int] = typer.Option(None, \"--columns\", \"-c\"), ignore: Optional[str] = typer.Option(None, \"--ignore\", \"-i\", callback=list_topics), just: Optional[str] = typer.Option(None, \"--just\", \"-j\", callback=list_topics), ): topics = list(TOPICS) # We can take input from a stdin (pipes) or from a file input_ = file if file else sys.stdin # Print just some topics or exclude some topics (good for avoiding verbose ones) if just: topics = just if ignore: topics = [lvl for lvl in topics if lvl not in set(ignore)] topics = set(topics) console = Console() width = console.size.width panic = False for line in input_: try: time, topic, *msg = line.strip().split(\" \") # To ignore some topics if topic not in topics: continue msg = \" \".join(msg) # Debug calls from the test suite aren't associated with # any particular peer. Otherwise we can treat second column # as peer id if topic != \"TEST\": i = int(msg[1]) # Colorize output by using rich syntax when needed if colorize and topic in TOPICS: color = TOPICS[topic] msg = f\"[{color}]{msg}[/{color}]\" # Single column printing. Always the case for debug stmts in tests if n_columns is None or topic == \"TEST\": print(time, msg) # Multi column printing, timing is dropped to maximize horizontal # space. Heavylifting is done through rich.column.Columns object else: cols = [\"\" for _ in range(n_columns)] msg = \"\" + msg cols[i] = msg col_width = int(width / n_columns) cols = Columns(cols, width=col_width - 1, equal=True, expand=True) print(cols) except: # Code from tests or panics does not follow format # so we print it as is if line.startswith(\"panic\"): panic = True # Output from tests is usually important so add a # horizontal line with hashes to make it more obvious if not panic: print(\"#\" * console.width) print(line, end=\"\") if __name__ == \"__main__\": typer.run(main)   dstest.py -\u003e concurrency test  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251  #!/usr/bin/env python import itertools import math import signal import subprocess import tempfile import shutil import time import os import sys import datetime from collections import defaultdict from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED from dataclasses import dataclass from pathlib import Path from typing import List, Optional, Dict, DefaultDict, Tuple import typer import rich from rich import print from rich.table import Table from rich.progress import ( Progress, TimeElapsedColumn, TimeRemainingColumn, TextColumn, BarColumn, SpinnerColumn, ) from rich.live import Live from rich.panel import Panel from rich.traceback import install install(show_locals=True) @dataclass class StatsMeter: \"\"\" Auxiliary classs to keep track of online stats including: count, mean, variance Uses Welford's algorithm to compute sample mean and sample variance incrementally. https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#On-line_algorithm \"\"\" n: int = 0 mean: float = 0.0 S: float = 0.0 def add(self, datum): self.n += 1 delta = datum - self.mean # Mk = Mk-1+ (xk – Mk-1)/k self.mean += delta / self.n # Sk = Sk-1 + (xk – Mk-1)*(xk – Mk). self.S += delta * (datum - self.mean) @property def variance(self): return self.S / self.n @property def std(self): return math.sqrt(self.variance) def print_results(results: Dict[str, Dict[str, StatsMeter]], timing=False): table = Table(show_header=True, header_style=\"bold\") table.add_column(\"Test\") table.add_column(\"Failed\", justify=\"right\") table.add_column(\"Total\", justify=\"right\") if not timing: table.add_column(\"Time\", justify=\"right\") else: table.add_column(\"Real Time\", justify=\"right\") table.add_column(\"User Time\", justify=\"right\") table.add_column(\"System Time\", justify=\"right\") for test, stats in results.items(): if stats[\"completed\"].n == 0: continue color = \"green\" if stats[\"failed\"].n == 0 else \"red\" row = [ f\"[{color}]{test}[/{color}]\", str(stats[\"failed\"].n), str(stats[\"completed\"].n), ] if not timing: row.append(f\"{stats['time'].mean:.2f}± {stats['time'].std:.2f}\") else: row.extend( [ f\"{stats['real_time'].mean:.2f}± {stats['real_time'].std:.2f}\", f\"{stats['user_time'].mean:.2f}± {stats['user_time'].std:.2f}\", f\"{stats['system_time'].mean:.2f}± {stats['system_time'].std:.2f}\", ] ) table.add_row(*row) print(table) def run_test(test: str, race: bool, timing: bool): test_cmd = [\"go\", \"test\", f\"-run={test}\"] if race: test_cmd.append(\"-race\") if timing: test_cmd = [\"time\"] + test_cmd f, path = tempfile.mkstemp() start = time.time() proc = subprocess.run(test_cmd, stdout=f, stderr=f) runtime = time.time() - start os.close(f) return test, path, proc.returncode, runtime def last_line(file: str) -\u003e str: with open(file, \"rb\") as f: f.seek(-2, os.SEEK_END) while f.read(1) != b\"\\n\": f.seek(-2, os.SEEK_CUR) line = f.readline().decode() return line # fmt: off def run_tests( tests: List[str], sequential: bool = typer.Option(False, '--sequential', '-s', help='Run all test of each group in order'), workers: int = typer.Option(1, '--workers', '-p', help='Number of parallel tasks'), iterations: int = typer.Option(10, '--iter', '-n', help='Number of iterations to run'), output: Optional[Path] = typer.Option(None, '--output', '-o', help='Output path to use'), verbose: int = typer.Option(0, '--verbose', '-v', help='Verbosity level', count=True), archive: bool = typer.Option(False, '--archive', '-a', help='Save all logs intead of only failed ones'), race: bool = typer.Option(False, '--race/--no-race', '-r/-R', help='Run with race checker'), loop: bool = typer.Option(False, '--loop', '-l', help='Run continuously'), growth: int = typer.Option(10, '--growth', '-g', help='Growth ratio of iterations when using --loop'), timing: bool = typer.Option(False, '--timing', '-t', help='Report timing, only works on macOS'), # fmt: on ): if output is None: timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") output = Path(timestamp) if race: print(\"[yellow]Running with the race detector\\n[/yellow]\") if verbose \u003e 0: print(f\"[yellow] Verbosity level set to {verbose}[/yellow]\") os.environ['VERBOSE'] = str(verbose) while True: total = iterations * len(tests) completed = 0 results = {test: defaultdict(StatsMeter) for test in tests} if sequential: test_instances = itertools.chain.from_iterable(itertools.repeat(test, iterations) for test in tests) else: test_instances = itertools.chain.from_iterable(itertools.repeat(tests, iterations)) test_instances = iter(test_instances) total_progress = Progress( \"[progress.description]{task.description}\", BarColumn(), TimeRemainingColumn(), \"[progress.percentage]{task.percentage:\u003e3.0f}%\", TimeElapsedColumn(), ) total_task = total_progress.add_task(\"[yellow]Tests[/yellow]\", total=total) task_progress = Progress( \"[progress.description]{task.description}\", SpinnerColumn(), BarColumn(), \"{task.completed}/{task.total}\", ) tasks = {test: task_progress.add_task(test, total=iterations) for test in tests} progress_table = Table.grid() progress_table.add_row(total_progress) progress_table.add_row(Panel.fit(task_progress)) with Live(progress_table, transient=True) as live: def handler(_, frame): live.stop() print('\\n') print_results(results) sys.exit(1) signal.signal(signal.SIGINT, handler) with ThreadPoolExecutor(max_workers=workers) as executor: futures = [] while completed \u003c total: n = len(futures) if n \u003c workers: for test in itertools.islice(test_instances, workers-n): futures.append(executor.submit(run_test, test, race, timing)) done, not_done = wait(futures, return_when=FIRST_COMPLETED) for future in done: test, path, rc, runtime = future.result() results[test]['completed'].add(1) results[test]['time'].add(runtime) task_progress.update(tasks[test], advance=1) dest = (output / f\"{test}_{completed}.log\").as_posix() if rc != 0: print(f\"Failed test {test}- {dest}\") task_progress.update(tasks[test], description=f\"[red]{test}[/red]\") results[test]['failed'].add(1) else: if results[test]['completed'].n == iterations and results[test]['failed'].n == 0: task_progress.update(tasks[test], description=f\"[green]{test}[/green]\") if rc != 0 or archive: output.mkdir(exist_ok=True, parents=True) shutil.copy(path, dest) if timing: line = last_line(path) real, _, user, _, system, _ = line.replace(' '*8, '').split(' ') results[test]['real_time'].add(float(real)) results[test]['user_time'].add(float(user)) results[test]['system_time'].add(float(system)) os.remove(path) completed += 1 total_progress.update(total_task, advance=1) futures = list(not_done) print_results(results, timing) if loop: iterations *= growth print(f\"[yellow]Increasing iterations to {iterations}[/yellow]\") else: break if __name__ == \"__main__\": typer.run(run_tests)   configuration  1 2 3  # ~/.zshrc  alias dslogs=\"python ~/.pyScript/dslogs.py\" alias dstest=\"python ~/.pyScript/dstest.py\"    dslogs  VERBOSE=1 go test \u003e out\ndslog out -c 6\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  ❯ dslogs --help Usage: dslogs.py [OPTIONS] [FILE] ╭─ Arguments ────────────────────────────────────────────────────── │ file [FILE] File to read, stdin otherwise [default: None] ╰────────────────────────────────────────────────────────────────── ╭─ Options ──────────────────────────────────────────────────────── │ --no-color [default: True] │ --columns -c INTEGER [default: None] // \u003erf的数量 │ --ignore -i TEXT [default: None] // 不显示某些TAG │ --just -j TEXT [default: None] // 仅显示某些TAG │ --help Show this message and exit. ╰──────────────────────────────────────────────────────────────────    dstest  dstest -v 1 -s -p 10 -n 10 -o logs -r 2A\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ❯ dstest --help Usage: dstest.py [OPTIONS] TESTS... ╭─ Arguments ───────────────────────────────────────────────────────────────────────────────────────── │ * tests TESTS... [default: None] [required] ╰───────────────────────────────────────────────────────────────────────────────────────────────────── ╭─ Options ─────────────────────────────────────────────────────────────────────────────────────────── │ --sequential -s Run all test of each group in order │ --workers -p INTEGER Number of parallel tasks [default: 1] // 线程数 │ --iter -n INTEGER Number of iterations to run [default: 10] // 重复运行同一个任务 │ --output -o PATH Output path to use [default: None] │ --verbose -v INTEGER Verbosity level [default: 0] // 是否显示Dprintf内容 │ --archive -a Save all logs intead of only failed ones │ --race -r --no-race -R Run with race checker [default: no-race] │ --loop -l Run continuously // 测完后继续无限测试 │ --growth -g INTEGER Growth ratio of iterations when using --loop [default: 10] // 和loop配合使用，iter*=growth │ --timing -t Report timing, only works on macOS │ --help Show this message and exit. ╰─────────────────────────────────────────────────────────────────────────────────────────────────────   ","description":"","tags":null,"title":"6.824","uri":"/posts/6.824/"},{"content":"RPC  Remote Procedure Call\n 特点 区别于HTTP服务的RESTful风格接口，RPC主要是远程函数调用，HTTP则更关注与资源。并且RPC服务可以减少网络开销，各种意义上提高效率。\n一言以蔽之，RPC协议的主要目的是做到不同服务间调用方法像同一服务间调用本地方法一样\n优点  单一责任 扩展性 故障隔离  一言以蔽之，RPC协议的主要目的是做到不同服务间调用方法像同一服务间调用本地方法一样。\n问题 服务宕机\n网络异常\n服务时长不合预期\n理论 论文架构 User, User-Stub, RPC-Runtime, Server-Stub, Server\n实现 IDL (Interface description language) Descript the interface.\nTLV编码  Tag：类型 Length：长度 Value：值（也可以是TLV结构）   GenCode Translate the IDL to different programming language.\nNeed decode and encode logic.\n兼容性——增加新的字段不影响现有服务\n通用性——跨平台跨语言\n性能——空间时间维度，编码后的数据大小和编码时长\nEncode Conv code to byte.\nProtocol Necessary data and metadata\n0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f +—————————————————————-+ | 0| LENGTH | +—————————————————————-+ | 0| HEADER MAGIC | FLAGS | +—————————————————————-+ | SEQUENCE NUMBER | +—————————————————————-+ | 0| Header Size(/32) | … +———————————\n Header is of variable size: (and starts at offset 14)  +—————————————————————-+ | PROTOCOL ID (varint) | NUM TRANSFORMS (varint) | +—————————————————————-+ | TRANSFORM 0 ID (varint) | TRANSFORM 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | INFO 0 ID (varint) | INFO 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | | | PAYLOAD | | | +—————————————————————-+\nLENGTH: 数据包大小，不包含自身\nHEADER MAGIC:标识版本信息，协议解析时快速校验\nSEQUENCE NUMBER:表示数据包的seqlD，可用于多路复用，单连接内递增\n 多路复用(multiplexing) 在单个通信信道上传输多个信息。它可以让多个应用程序或进程在同一时间共享一个信道。以有效地利用带宽和资源，提高系统的效率。常见技术：时分多路复用TDM，波分多路复用WDM，包交换。一般通过TCP/IP实现。\n HEADER SIZE:头部长度，从第14个字节开始计算一直到PAYLOAD前 PROTOCOL ID:编解码方式，有Binary和Compact两种 TRANSFORM ID:压缩方式，如zlilb 和snappy INFO ID:传递一些定制的meta信息 PAYLOAD:消息体\nNetwork Transfer Application Layer Sockets API TCP/UDP IP Driver Physical Layer RPC框架 reference\nhttp://ddia.vonng.com/#/ch4?id=%e6%9c%8d%e5%8a%a1%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae%e6%b5%81%ef%bc%9arest%e4%b8%8erpc\n","description":"","tags":null,"title":"RPC","uri":"/posts/rpc/"},{"content":"go-zero go-zero简介 go-zero是一个能够快速生成API，MODEL和RPC的框架。\ngo-zero 项目结构（不含RPC） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85  . ├── api │ ├── etc │ │ └── park-api.yaml │ ├── internal │ │ ├── config │ │ │ └── config.go │ │ ├── handler │ │ │ ├── accessHandler.go │ │ │ ├── deviceInfoHandler.go │ │ │ ├── incomeHandler.go │ │ │ ├── parkingLotHandler.go │ │ │ ├── routes.go │ │ │ ├── siteInfoHandler.go │ │ │ ├── touristCarProvinceHandler.go │ │ │ ├── touristFlowHandler.go │ │ │ ├── userHandler.go │ │ │ └── wechatHandler.go │ │ ├── logic │ │ │ ├── accessLogic.go │ │ │ ├── deviceInfoLogic.go │ │ │ ├── incomeLogic.go │ │ │ ├── parkingLotLogic.go │ │ │ ├── siteInfoLogic.go │ │ │ ├── touristCarProvinceLogic.go │ │ │ ├── touristFlowLogic.go │ │ │ ├── userLogic.go │ │ │ └── wechatLogic.go │ │ ├── svc │ │ │ └── serviceContext.go │ │ └── types │ │ └── types.go │ ├── park.api │ ├── park.go │ └── park.md ├── genModel │ ├── model │ │ ├── accessModel.go │ │ ├── accessModel_gen.go │ │ ├── deviceInfoModel.go │ │ ├── deviceInfoModel_gen.go │ │ ├── incomeModel.go │ │ ├── incomeModel_gen.go │ │ ├── logErrModel.go │ │ ├── logErrModel_gen.go │ │ ├── parkingLotModel.go │ │ ├── parkingLotModel_gen.go │ │ ├── siteInfoModel.go │ │ ├── siteInfoModel_gen.go │ │ ├── touristCarProvinceModel.go │ │ ├── touristCarProvinceModel_gen.go │ │ ├── touristFlowModel.go │ │ ├── touristFlowModel_gen.go │ │ ├── userModel.go │ │ ├── userModel_gen.go │ │ ├── vars.go │ │ ├── wechatModel.go │ │ └── wechatModel_gen.go │ └── resources │ ├── genModel.sh │ └── park.sql ├── go.mod ├── go.sum └── model ├── accessModel.go ├── accessModel_gen.go ├── deviceInfoModel.go ├── deviceInfoModel_gen.go ├── incomeModel.go ├── incomeModel_gen.go ├── logErrModel.go ├── logErrModel_gen.go ├── parkingLotModel.go ├── parkingLotModel_gen.go ├── siteInfoModel.go ├── siteInfoModel_gen.go ├── touristCarProvinceModel.go ├── touristCarProvinceModel_gen.go ├── touristFlowModel.go ├── touristFlowModel_gen.go ├── userModel.go ├── userModel_gen.go ├── vars.go ├── wechatModel.go └── wechatModel_gen.go    api 文件夹用于存放外部调用，需要改动的是 *.api, etc/*.yaml, svc/serviceContext.go, logic/*，作用分别是生成 api 调用框架，写配置文件，将数据添加到 Context 供逻辑调用，逻辑实现。 genModel 文件夹用于生成数据库调用相关实现，需要改动的是resources/*.sql。 model 文件夹用于添加额外的数据库调用逻辑（将genModel/model/*复制到model后开改！）  简单使用 通过goctl生成代码框架。\nAPI 框架通过 api/*.api生成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114  //park.api syntax = \"v1\" info( title: \"parkApi\" desc: \"parkBackEnd\" author: \"loomt\" email: \"loomt_@outlook.com\" version: \"1.0\" ) type ( accessResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 接入地点 \tDate string `json:\"date\"` // 接入日期 \tNum int64 `json:\"num\"` // 接入数量 \t} incomeResp { Id int64 `json:\"id\"` Type string `json:\"type\"` // 收入类型 \tDate string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 当天收入 \t} parkingLotResp { Id int64 `json:\"id\"` Name string `json:\"name\"` // 停车场名字 \tDuration int64 `json:\"duration\"` // 停车时间（小时） \tNum int64 `json:\"num\"` // 泊车数 \t} siteInfoResp { Id int64 `json:\"id\"` Date string `json:\"date\"` // 日期 \tRevisitRate int64 `json:\"revisit_rate\"` // 重复访问率（%） \tSiteHealth int64 `json:\"site_health\"` // 站点健康度 \tRfHealth int64 `json:\"rf_health\"` // 射频健康度 \tDeviceHealth int64 `json:\"device_health\"` // 设备健康度 \tFlow int64 `json:\"flow\"` // 当日站点流量 \t} touristFlowResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 园区地点 \tDate string `json:\"date\"` // 时间 \tNum int64 `json:\"num\"` // 游客数量 \t} touristCarProvinceResp { Id int64 `json:\"id\"` Province string `json:\"province\"` // 省份 \tDate string `json:\"date\"` // 日期 \tFlowNum int64 `json:\"flow_num\"` // 人流数量 \tCarNum int64 `json:\"car_num\"` // 车辆数 \t} userReq { Id int64 `json:\"id\"` // 用户id \t} userResp { Id int64 `json:\"id\"` // 用户id \tUsername string `json:\"username\"` // 用户名 \t} wechatResp { Date string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 微信关注数量 \t} deviceInfoResp { Id int64 `json:\"id\"` UplinkRate float64 `json:\"uplink_rate\"` // 上行速率 \tDownlinkRate float64 `json:\"downlink_rate\"` // 下载速率 \tFlow float64 `json:\"flow\"` // 流量 \tCpuRate float64 `json:\"cpu_rate\"` // CPU占有率 \tLongitude float64 `json:\"longitude\"` // 经度 \tLatitude float64 `json:\"latitude\"` // 纬度 \t} ) @server( prefix: api ) service park-api { @doc \"获取接入详情\" @handler accessHandler get /access returns (accessResp) @doc \"获取日收入详情\" @handler incomeHandler get /income returns (incomeResp) @doc \"获取停车详情\" @handler parkingLotHandler get /parkingLot returns (parkingLotResp) @doc \"获取站点详情\" @handler siteInfoHandler get /siteInfo returns (siteInfoResp) @doc \"获取客流量详情\" @handler touristFlowHandler get /touristFlow returns (touristFlowResp) @doc \"获取游客与车辆来源省份\" @handler touristCarProvinceHandler get /touristCarProvince returns (touristCarProvinceResp) @doc \"获取用户详情\" @handler userHandler post /user (userReq) returns (userResp) @doc \"获取微信关注详情\" @handler wechatHandler get /wechat returns (wechatResp) @doc \"获取设备信息\" @handler deviceInfoHandler get /deviceInfo returns (deviceInfoResp) }   1 2  # api goctl api go -api *.api -dir ./ --style=goZero   MODEL 框架有两种生成方式  连接数据库生成model  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/usr/bin/env zsh # 使用方法： # ./genModel.sh usercenter user # ./genModel.sh usercenter user_auth # 再将./genModel下的文件剪切到对应服务的model目录里面，记得改package #生成的表名 tables=$2 #表生成的genmodel目录 modeldir=../model # 数据库配置 host=127.0.0.1 port=3306 dbname=$1 username=root passwd=123456 echo \"开始创建库：$dbname的表：$2\" goctl model mysql datasource -url=\"${username}:${passwd}@tcp(${host}:${port})/${dbname}\" -table=\"${tables}\" -dir=\"${modeldir}\" --style=goZero    直接用 sql 文件(genModel/resource/*.sql)生成 model  1 2  # genModel/resources goctl model mysql ddl -src=\"./*.sql\" -dir=\"../model\" --style=goZero   生成文档 1 2  # ./ goctl api doc -dir .   华为云部署  mysql 导入 nohup go run *.go -f etc/*.yaml 2\u003e\u00261 \u0026  ","description":"","tags":null,"title":"go-zero单体服务","uri":"/posts/go-zero%E5%8D%95%E4%BD%93%E6%9C%8D%E5%8A%A1/"},{"content":"记一次华为云耀云服务器公网部署问题 开了安全组，用 caddy 部署了一个小网页来测试公网访问 可以看到内网访问是正常的。也可以 ping 通\n根据华为云官网给出的指引排查了很久，绑定了弹性公网 ip，设置了安全组 Sys-FullAccess、ACL，都无法用浏览器访问。\n最后回到服务器 查询防火墙状态\n关掉防火墙就可以了 对着华为云的控制台搞了很久安全组，还以为安全组哪里配错了，最后发现是服务器防火墙的问题😭\n","description":"","tags":null,"title":"华为云公网部署","uri":"/posts/%E5%8D%8E%E4%B8%BA%E4%BA%91%E5%85%AC%E7%BD%91%E9%83%A8%E7%BD%B2/"},{"content":" 摆烂，于是将目光看向了家里的小米4a千兆版路由器，准备刷个Openwrt玩一下。\n 去恩山论坛逛了逛，感觉刷软路由和刷手机差不太多。\n 安装Breed（闭源免费的BootLoader，又称“不死鸟”，有了它就能肆无忌惮地刷各种第三方包了  如果你的路由器是小米4A千兆版，可以直接用恩山论坛的无脑直装Breed；如果不是，也可以去Breed官网下载路由器的适配包并自行搜索如何通过Telnet连接路由器并刷入Breed。 用Breed安装OpenWrt  这里放一个小米4A千兆版OpenWrt直刷包，其他路由器的固件可以去恩山论坛逛逛。 .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 警告\n刷OpenWrt之前必须用Breed备份eeprom（没有备份eeprom将导致5G信号奇差）\n 点击固件更新~\u003e常规固件~\u003e勾上“固件”和“EEPROM”，选择好上面的直刷包和备份的eeprom.bin，上传即可。\n配置OpenWrt的各项参数（随便配一下即可  OpenWrt可谓神通广大，作为一个在路由器上跑的Linux，它可以装上各种插件：酸酸乳、Docker、网易云解锁灰色歌曲……\n但我折腾了一通，调教好基础的上网功能后，感觉网络状况大不如前。作为百来块的路由器，本来就没有多大的内存，感觉原厂固件的调教已经将性能都用在刀刃上了。装了OpenWrt后虽然上下行流量速度没有很大变化，但稳定性差了很多，便懒得继续折腾，忍痛remake了。\n刷回官方包（没备份eeprom的问题 或许 也可以通过刷回官方包的方法解决  下载小米4A千兆版官方包，进入Breed~\u003e固件更新~\u003e编程器固件(仅勾选自动重启)~\u003e上传all.bin。\n","description":"","tags":null,"title":"小米4A千兆版刷OpenWrt","uri":"/posts/%E5%B0%8F%E7%B1%B34a%E5%8D%83%E5%85%86%E7%89%88%E5%88%B7openwrt/"},{"content":"7-Zip双击自动解压压缩文件  因为难以忍受7zip的右键解压操作，通过修改注册表以自动解压。\n  替换 D:\\\\000000000000\\\\7-Zip 为 your\\\\path\\\\to\\\\7-Zip 将代码塞进.reg文件，双击即可。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421  Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\7-Zip.001\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\"   reference\nhttps://gist.github.com/zabbarob/5891200\n","description":"","tags":null,"title":"Auto7zip","uri":"/posts/auto7zip/"},{"content":" 前段时间白嫖了一个 域名 ，暑假有时间了赶紧物尽其用，于是花了一天的时间重新建了个站（其实我很久之前就用过 hexo 无脑建站，但最近发现了一个特别喜欢的Hugo主题 MemE ）\n 简略步骤 Hugo Quick Start  在 wsl 下装 Hugo  1  $ sudo apt install hugo   TL;DR 一下 Hugo 的基础命令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  $ tldr hugo hugo Template-based static site generator. Uses modules, components, and themes.More information: https://gohugo.io. - Create a new Hugo site: hugo new site {{path/to/site}} - Create a new Hugo theme (themes may also be downloaded from https://themes.gohugo.io/): hugo new theme {{theme_name}} - Create a new page: hugo new {{section_name}}/{{filename}} - Build a site to the ./public/ directory: hugo - Build a site including pages that are marked as a \"draft\": hugo --buildDrafts - Build a site to a given directory: hugo --destination {{path/to/destination}} - Build a site, start up a webserver to serve it, and automatically reload when pages are edited: hugo server   新建站点  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $ hugo new site loomt Congratulations! Your new Hugo site is created in /home/loomt/temp/loomt. Just a few more steps and you are ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. $ cd loomt $ tree . ├── archetypes │ └── default.md ├── config.toml ├── content ├── data ├── layouts ├── static └── themes   配置主题  $ git init # 将皮肤作为submodule添加，以便更新 $ git submodule add https://github.com/reuixiy/hugo-theme-meme.git themes/meme # MeME，很喜欢的一个主题 $ git submodule add https://github.com/martignoni/hugo-notice.git themes/hugo-notice # hugo-notice，插件主题（很轻，开箱即用） $ rm config.toml \u0026\u0026 cp themes/meme/config-examples/zh-cn/config.toml config.toml #覆盖配置文件 发布文章  1 2  $ hugo new posts/HelloWorld.md #会在centent下面创建markdown文件，可以直接去编辑 Content \"/home/loomt/temp/loomt/content/posts/HelloWorld.md\" created   运行本地服务  1  $ hugo server -D --verbose # 在本地运行 -D是渲染草稿 --verbose显示详细输出   目前已经完成基本配置，可以访问运行在本机的站点了 🥳\n接下来还可以将网站部署到 Github Page，Vercel 或者 Netlify 等免费的静态资源托管商。\nHugo 部署到 Github Page Hugo 是一个网站构建工具，hugo命令生成的 public 文件夹存放的是静态的部署页面，我们只需要将其放在 Github Page 中即可。建议开两个仓库，一个仓库用于存放根目录，另一个用于存放./public 文件夹的内容，以便被 Github Page 部署。\n 因为根目录可能有敏感信息和暂时不希望公开的草稿，又为了让其得到有效的版本控制，可以开一个私有仓库存放根目录，\n而 publishDir(./pubic) 作为输出的静态页面，则适合放在公开的仓库 而且 Github Page 不公开没法白嫖\n 默认看到这里的同学已经建好了仓库，并完成了仓库的初始化和配置 🤗\n下面假设更新了文章，需要同步到两个仓库。\n1 2 3 4 5 6 7 8  $ hugo --gc --cleanDestinationDir # 生成静态站点到./public的同时 清除缓存和静态站点用不着的文件 $ git add . $ git commit -m \"update source code\" $ git push $ cd public $ git add . $ git commit -m \"update Github Page\" $ git push   是不是感觉要 push 两次非常麻烦，可以写一个 push.sh 来简化操作，还可以加个 Github Actions，简化每次更新站点的步骤，具体可阅读 GitHub Actions 官方文档，actions-gh-pages 以及 reuixiy 的博客 。\n自动化部署   如果源码仓库和 Github Page 仓库都是公有的话可以阅读 actions-gh-pages 进行简单的配置。\n  如果源码仓库是私有的，Github Page 仓库是公开的话，可以参考以下配置方案。\n   配置公钥和私钥到仓库  需要生成 SSH key pair 以获取源码仓库对 Github Page 仓库修改的权限。\n$ mkdir -p ~/.ssh/blog $ cd ~/.ssh/blog $ ssh-keygen -t rsa -b 4096 -C \"yourname@users.noreply.github.com\" # 注意：不要无脑回车，最好开一个文件夹存公钥私钥，不然会覆盖掉以前的  id_rsa（私钥）  前往 Github Page 仓库，Settings \u003e Deploy Keys \u003e Add deploy key。\n需要勾选 Allow write access。\n id_rsa.pub （公钥）  前往源码仓库，Settings \u003e Secrets \u003e Actions \u003e New repository secret。\nName 需要设为 ACTIONS_DEPLOY_KEY\n新建 Workflow 配置文件  下面粘一下我的配置方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  # .github/workflows/build.ymlname:Hugo automated deploymenton:push:branches:- main # Set a branch name to trigger deploymentjobs:deploy:runs-on:ubuntu-latestpermissions:contents:writeconcurrency:group:${{ github.workflow }}-${{ github.ref }}steps:- uses:actions/checkout@v3with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:'0.92.2'extended:true- name:Buildrun:hugo --gc --minify# - name: Deploy# uses: peaceiris/actions-gh-pages@v3# # If you're changing the branch from main,# # also change the `main` in `refs/heads/main`# # below accordingly.# if: ${{ github.ref == 'refs/heads/main' }}# with:# github_token: ${{ secrets.GITHUB_TOKEN }}# publish_dir: ./public- name:Deploy # 此处需要按照自己实际修改uses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}external_repository:loomts/loomts.github.iopublish_branch: main # default:gh-pagespublish_dir:./public  推送到 Github  1 2 3  $ git add . $ git commit -m \"setup auto deploy\" $ git push   打开你的源码仓库页面，点击 Actions 查看日志，顺利的话已经搞定了，以后每次 git push Github Workflow 都会自动帮你更新网站了。\nGithub Page 绑定自定义域名 假设已经有了域名，还需要在域名的 DNS 服务商那里加一个 CNAME （用于 dns 跳转）。\n   name type value     www CNAME loomts.github.io    一段时间后，回到 Github Page 仓库，在 Settings \u003e Pages \u003e Custom domain 处填上自己的域名，等待几小时生成证书，然后勾选 Enforce HTTPS。\n还要记得添加 your domain 到 static/CNAME ，以生成到静态文件。\n1  $ echo \"your domain\" \u003e static/CNAME    Custom domains are stored in a CNAME file in the root of your publishing source. You can add or update this file through your repository settings or manually. For more information, see \" Managing a custom domain for your GitHub Pages site .\" ——Github Docs\n Hugo 部署到 Vercel Vercel 可以看作是结合了 Github Page 还有 Github Actions 的用于前端框架和静态站点管的平台，直接导入 Github 仓库即可部署，感觉配置起来比 Github Action 无脑很多，很适合我，所以我已经放弃 Github Action，全面转为 Vercel 了。需要注意的是注册域名的时候要去域名注册商改一下 DNS 服务器，或者每个站点都添加一次 A 记录。\nHugo 个性化配置 皮肤配置 可以根据皮肤作者的文档改变皮肤的各种 feature，如 MeME 的 config.toml example\n.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\nconfig.toml 的 baseURL 要加 https:// ，否则生成的静态页面 css 和 js 加载会出问题。\n 自定义 CSS 和 JS  利用 hugo 的替换规则  当你需要更改某个页面的生成规则（包括 CSS 和 JS），你可以将 themes/your-theme 里面的东西复制一份到你的根目录，然后爽改逻辑，hugo 生成静态页面时在同等情况下会优先用你根目录下的文件。\n如果你想要自己新建一个 js 或者 css 文件，可以看hugo-pipes，但如果你不打算做一个开源主题，无脑在 html 文件里面堆 style 和 script 是能跑的选择！  比如，我有这样一个需求：在 Wiki 页面分层次显示我的笔记，但又不让笔记内容在主页面显示，并且 Wiki 页需要按照文件夹的内部结构展示，那就用categories的方式组织 content/wiki 的内容，仅需要改一下 MeME 主题 tree-sections 的内容，并配置一下 config.toml 即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  \u003cmain class=\"main list\" id=\"main\"\u003e \u003cdiv class=\"main-inner\"\u003e \u003cdiv class=\"content categories\"\u003e {{ if .Site.Params.displayListTitle }} \u003ch1 class=\"list-title\"\u003e {{ \"Wiki\"}} \u003c/h1\u003e \u003cdiv\u003e 存点笔记，仅作参考😶‍🌫️ \u003c/div\u003e {{ end }} \u003cdiv class=\"tree\"\u003e \u003cul class=\"list-categories\" style=\"display: block;\"\u003e {{ partial \"utils/tree-sections.html\" . }} {{ $sections := .Scratch.Get \"sections\" }} {{ $pages := .Scratch.Get \"pages\" }} {{ range $index, $page := $pages }} {{ $depth := (len (split (strings.TrimPrefix \"/\" $page) \"/\")) }} {{ with $.Site.GetPage $page }} {{ $linkTarget := .}} {{ $depthPrev := 0 }} {{ if ge $index 1 }} {{ $pagePrev := index $pages (sub $index 1) }} {{ $depthPrev = len (split (strings.TrimPrefix \"/\" $pagePrev) \"/\") }} {{ end }} {{ $depthNext := 0 }} {{ if lt $index (sub (len $pages) 1) }} {{ $pageNext := index $pages (add $index 1) }} {{ $depthNext = len (split (strings.TrimPrefix \"/\" $pageNext) \"/\") }} {{ end }} {{ if or (le $depth $depthPrev) (eq $index 0) }} \u003cli\u003e {{ end }} {{ if and (gt $depth $depthPrev) (ne $index 0) }} \u003cul class=\"list-categories\" style=\"display: block;\"\u003e \u003cli\u003e {{ end }} {{ $name := index $sections $index }} \u003cdiv class=\"category-item\"\u003e {{ .LinkTitle | default $name}} {{ if $.Site.Params.displayPostsCount }} {{ $sectionPage := .CurrentSection }} {{$.Scratch.Delete \"pages\" }} {{ range $.Site.RegularPages }} {{ if (.IsDescendant $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end}} {{ end }} {{ $pages := $.Scratch.Get \"pages\"}} \u003cspan class=\"category-count\"\u003e {{printf \"(%d)\" (len $pages)}} \u003c/span\u003e {{ end }} \u003c/div\u003e {{ if $.Site.Params.displayPosts }} {{ $sectionPage := .CurrentSection }} {{ $.Scratch.Delete \"pages\"}} {{ range $.Site.RegularPages }} {{ if (.InSection $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end }} {{ end }} {{ $pages := $.Scratch.Get \"pages\" }} {{ partial \"utils/limit-tree-posts.html\" (dict \"$\" $ \"pages\" $pages \"linkTarget\" $linkTarget) }} {{ end }} {{ if and (gt $depth $depthNext) (ne $index (sub (len $pages) 1)) }} {{ range seq (sub $depth $depthNext) }} {{ if le . (sub $depth $depthNext) }} \u003c/li\u003e \u003c/ul\u003e {{ end }} {{ end }} {{ end }} {{ if ge $depth $depthNext }} \u003c/li\u003e {{ end }} {{ end }} {{ end }} \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/main\u003e \u003cscript\u003e let lis = document.querySelectorAll(\"ul.list-categories \u003e li\"); lis.forEach(li =\u003e { li.querySelector(\".category-item\").addEventListener(\"click\", event =\u003e { event.stopPropagation(); // 阻止事件冒泡  let sonul = li.querySelector(\"ul\"); sonul.style.display = sonul.style.display === \"block\" ? \"none\" : \"block\"; if (sonul.nextElementSibling) { sonul.nextElementSibling.style.display = sonul.nextElementSibling.style.display === \"block\" ? \"none\" : \"block\"; } }); }) \u003c/script\u003e   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  [menu] ## 菜单栏 [[menu.main]] pageref = \"/posts/\" name = \"Posts\" weight = 2 pre = \"internal\" post = \"archive\" [[menu.main]] pageref = \"/tags/\" name = \"Tags\" weight = 4 pre = \"internal\" post = \"tags\" [[menu.main]] pageref = \"/about/\" name = \"About\" weight = 5 pre = \"internal\" post = \"user-circle\" [[menu.main]] # add wiki page pageref = \"/wiki/\" name = \"Wiki\" weight = 6 pre = \"internal\" post = \"wiki\" [[menu.main]] weight = 7 identifier = \"theme-switcher\" [[menu.main]] weight = 8 identifier = \"lang-switcher\" [[menu.main]] weight = 9 identifier = \"search\" post = \"search\"   Hugo + Algolia search Algolia 可以提供 AI 搜索服务，但需要在更新站点时用 POST 请求上传 algolia.json(站点信息)给 Algolia，以帮助 Algolia 实现搜索服务。按照要求新建站点以及配置 api 即可，上传 algolia.json 可以使用hugo-algolia。因为MeME主题有一定的algolia search支持，下面仅给出上传algolia.json方面的配置。\n1  $ npm install hugo-algolia   但 hugo-algolia 的 toml 解析在我这里好像有点问题，可能是 config.toml 的配置已经太乱了，无法优雅地解决\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ hugo-algolia -s -t --config config.toml JSON index file was created in public/algolia.json /usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50 throw new errors.AlgoliaSearchError('Please provide an application ID. ' + usage); ^ AlgoliaSearchError: Please provide an application ID. Usage: algoliasearch(applicationID, apiKey, opts) at AlgoliaSearchNodeJS.AlgoliaSearchCore (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50:11) at AlgoliaSearchNodeJS.AlgoliaSearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearch.js:11:21) at AlgoliaSearchNodeJS.AlgoliaSearchServer (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/AlgoliaSearchServer.js:17:17) at new AlgoliaSearchNodeJS (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:83:23) at algoliasearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:68:10) at HugoAlgolia.HugoAlgolia.sendIndex (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:184:20) at HugoAlgolia.HugoAlgolia.index (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:122:12) at Object.\u003canonymous\u003e (/usr/local/lib/node_modules/hugo-algolia/bin/index.js:23:26) at Module._compile (internal/modules/cjs/loader.js:999:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1027:10)   无奈之下新建了一个 config.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13  ---baseurl:\"/\"DefaultContentLanguage:\"zh-cn\"hasCJKLanguage:truelanguageCode:\"zh-cn\"title:\"loomt's Blog\"theme:\"MeME\"metaDataFormat:\"yaml\"algolia:index:\"your index\"key:\"your admin key\"appID:\"your appID\"---  1 2 3  $ hugo-algolia -s JSON index file was created in public/algolia.json { updatedAt: '2023-01-12T14:40:31.454Z', taskID: 173970040001 }    用 Vercel 还有一个原因是白嫖国外的服务器不用备案😭\n reference\nhttps://gohugo.io/getting-started\nhttps://blog.aozaki.cc/blog/hugo-deployment-debugging\nhttps://io-oi.me/tech/hugo-vs-hexo\nhttps://github.com/MunifTanjim/minimo/issues/189\nhttps://zenlian.github.io/posts/tools/github-actions-hugo\nhttps://github.com/peaceiris/actions-gh-pages\nhttps://gohugo.io/content-management/sections\nhttps://gohugo.io/templates\nhttps://gohugo.io/hugo-pipes\n","description":"","tags":["Github Page","建站"],"title":"建站","uri":"/posts/%E5%BB%BA%E7%AB%99/"}]