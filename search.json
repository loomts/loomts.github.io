[{"content":" 前置芝士\n Task 完成 Raft 的快照功能（涉及到较多的与 Service 层的交互。\n 为什么要有 snapshot?  snapshot 可以将 log 压缩，比如将 10 个 log 压缩成 9 个（当两个 log 修改的 key 值一样时）。 snapshot 可以减少 Raft 层 log 的长度，帮助进度较慢的 Raft 节点快速恢复状态机（减短 raft 中 log 的长度）。snapshot 区别于持久化 log，后者主要是不让宕机的 raft 丢失太多日志。   在 2D 中，snapshot 会涉及到 raft 层与 service 层的多次交互，看这个 diagram of Raft interactions 或许可以帮助理解 Raft 协议不同层次的功能与特性。 在 2D 中，snapshot 作用于每一个 Raft 节点，我们需要记录 snapshot 最后一个 index 和 term，用于一致性检查。  Step  Snapshot() 被 service 层调用，约莫 10 次 commit 调用一次，用于保存快照。需要注意的是快照是 service 传给 raft 层的，而不是我们在 raft 层写入日志创建的，我们不需要创建快照，仅需要处理 Service 层传进来的 snapshot，进行日志截断和快照持久化。  1 2 3 4 5 6 7 8 9 10 11  func (rf *Raft) Snapshot(index int, snapshot []byte) { rf.mu.Lock() defer rf.mu.Unlock() if rf.lastIncludedIndex() \u003e= index { return } rf.log = rf.log[index-rf.lastIncludedIndex():] rf.setLastIncludedIndex(index) rf.persister.SaveStateAndSnapshot(rf.getEncodeStateL(), snapshot) DPrintf(dSnap, \"S%v last: %v\", rf.me, index) }   2. InstallSnapshot：\n  Leader 方面，当$nextIndex[Follower] \\leq Leader.lastIncludeIndex$的时候，由于 Leader 已经没有这部分的日志，Leader 会发送 InstallSnapshot RPC 给 Follower，请求 Follower 安装快照（快速追赶），并且在成功收到返回值后，Leader 会更新 nextIndex 和 matchIndex\n  Follower 方面，如果 Follower 收到 Leader 的任期没有过期的话，只能执行。与论文不同的是：不需要考虑分块发送 snapshot，所以offset 和done都不需要考虑，相应的，在实现的时候也不需要考虑第 2,3,4 点 implementation。最后另起一个 go routine 传 snapshot 以及其他必要参数给 applyCh 让 service 更新状态机（发送给 service 后 service 不会立刻拿 snapshot 更新状态机，会先调用 CondInstallsnapshot 来询问 Follower 在这期间有没有 commit，若没有，才会用 snapshot 更新状态机。\n   CondInstallSnapshot：若 $lastIncludedIndex\\leq commitIndex$ ，则返回false，此时 service 不会应用 snapshot；否则剪短自己的 log，并更新 snapshot、lastIncludedTerm 和 lastIncludedIndex，并进行持久化。  tips：   在持久化的时候考虑 lastIncludedIndex 和 lastIncludedTerm，并应用到 commitIndex 和 lastApplied。\n  因为我们要删掉已经被 snapshot 的 log，所以需要改变 log 的索引方式。\n  对 condInstallsnapshot 的解释：Follower 收到 InstallSnapshot，向服务器请求应用 snapshot 的时候，如果服务器发送 condInstallSnapshot 的那一刻 lastCommit 还没被修改的话，就保证了原子操作。为什么需要保证原子操作？因为节点通过 applychan 向 service 通信的情况有两种，一种是 commit 到状态机，另一种是 snapshot 到状态机，两者是并行的，互不干扰。只要 raft 节点在发送 snapshot channel 到 service 接收到这个 channel 之间有 commit channel，也就是当 $lastIncludedIndex\\leq commitIndex$ 的时候，snapshot 发送的 log 就很有可能被应用到状态机了。\n  ","description":"","tags":null,"title":"6.824 Lab2D","uri":"/posts/6.824-lab2d/"},{"content":" 前置芝士\n Task 完成 Raft 的持久化。\nStep 如果前面做得好，只需要完成持久化。\n 持久化至 Service 层  1  persist()   Crash 后从 Service 层恢复  1  readPersist(data []byte)   如果和我一样前面差点意思，就要小修一下 guide   AppendEntries Handler 中，Follower 引入 XTerm 和 XIndex 来快速调整 nextIndex。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  if args.PrevLogIndex \u003e rf.getLastLogL().Index { reply.Success, reply.Term = false, rf.currentTerm reply.XIndex = rf.getLastLogL().Index + 1 // Follower's nextIndex  return } // entry logAt prevLogIndex whose term doesn't match prevLogTerm DPrintf(dInfo, \"S%v prevLogTerm:%v, prevLogIndex:%v,log[prevLogIndex].Term:%v\", rf.me, args.PrevLogTerm, args.PrevLogIndex, rf.logAt(args.PrevLogIndex).Term) if args.PrevLogTerm != rf.logAt(args.PrevLogIndex).Term { reply.Success, reply.Term = false, rf.currentTerm reply.XIndex, reply.XTerm = rf.commitIndex+1, rf.logAt(args.PrevLogIndex).Term for i := args.PrevLogIndex; i \u003e rf.commitIndex+1; i-- { if reply.XTerm != rf.logAt(i-1).Term { reply.XIndex = i return } } DPrintf(dInfo, \"S%v XIndex = %v\", rf.me, rf.commitIndex+1) return }    Leader 对 XTerm 和 XIndex 的处理  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  if rf.sendAppendEntries(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if reply.Term \u003e rf.currentTerm { //changeState but not update election timer  } else if args.Term == rf.currentTerm { if reply.Success { // update nextIndex, matchIndex \u0026 commit  } else if reply.Term == rf.currentTerm{ // adjust nextIndex  if reply.XIndex != NULL { DPrintf(dHeart, \"S%v \u003c- S%v heartbeat XIndex:%v, XTerm:%v\", rf.me, peer, reply.XIndex, reply.XTerm) if reply.XTerm == NULL { rf.nextIndex[peer] = reply.XIndex } else { ok := false for i := rf.nextIndex[peer] - 1; i \u003e rf.lastIncludedIndex() \u0026\u0026 reply.XTerm \u003c= rf.logAt(i).Term; i-- { if rf.logAt(i).Term == reply.XTerm { ok = true rf.nextIndex[peer] = i + 1 break } } if !ok { rf.nextIndex[peer] = reply.XIndex } } } } } }    electionTimer 不能在每次变成 Follower 的时候重置。   If election timeout elapses without receiving AppendEntries RPC from current Leader or granting vote to Candidate: convert to Candidate.\n  The distinction turns out to matter a lot, as the former implementation can result in significantly reduced liveness in certain situations.\n electionTimer 重置仅在以下情况发生：\n 刚成为 Candidate。 给别人投票后。 Follower 收到 AppendEntries 或者 InstallSnapshot，并且 args.Term 等于自己当前的 term（在前置芝士有谈到，其实这个 bug 是我在 2C 的时候才修的）。  我在 Follower 收到 AppendEntries 或者 InstallSnapshot，并且 args.Term 大于 currentTerm 的时候也重置了 electionTimer。改为不重置后，直观的结果是跑 2C 的 test 平均快了 15s，并且不会出现fail to reach agreement了。\n","description":"","tags":null,"title":"6.824 Lab2C","uri":"/posts/6.824-lab2c/"},{"content":" 前置芝士\n Task 处理日志，具体来说是接收 Service 层发来的日志，日志复制，应用日志。\n涉及到一点 Raft 层与 Service 层的交互，比如 Leader 接受 command 并保存为日志；Apply 日志到 Service 层。\nStep  选举的时候需要额外注意一个限制：只投票给 log 比自己新的 Candidate。 Leader 接受 command，append 进 log，返回此 command 的下标，此时 log 在状态机中还没被应用。 心跳时顺便发送日志给 Follower（需严格按照论文）。   AppendEntries RPC 参数中的 log 需要深拷贝才能免遭 data race。 发送的 log 并不是从头开始，而是从 nextIndex 开始。 在不可靠网络中，收到 RPC 结果的时候可能已经过了几个任期，此时需要先检查一下 args.Term 还等不等于 currentTerm，但在此之前，如果返回的任期比 currentTerm 还要大，那么无论是不是不可靠网络，这个 Leader 都要转为 Follower（同样的，因为不确定他有没有资格成为 Candidate，所以没有必要将其转为 Candidate，反正任期增加后总会有 Candidate 产生）；如果返回的任期小于等于 currentTerm，那么 Leader 只需要正常处理。  1 2 3 4 5 6 7 8 9 10 11 12 13  if rf.sendAppendEntries(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if reply.Term \u003e rf.currentTerm { //changeState but not update election timer  } else if args.Term == rf.currentTerm { if reply.Success { // update nextIndex, matchIndex \u0026 commit  } else if reply.Term == rf.currentTerm{ // adjust nextIndex  rf.nextIndex[peer] = max(1,rf.nextIndex[peer]-1) } }   Follower 进行日志复制（需严格按照论文）。  1 2 3 4 5 6 7 8 9 10 11 12 13  prevLogIndex := rf.nextIndex[i] - 1 prevLogTerm := rf.logAt(prevLogIndex).Term args := \u0026AppendEntriesArgs{ Term: rf.currentTerm, LeaderId: rf.me, PrevLogIndex: prevLogIndex, PrevLogTerm: prevLogTerm, Entries: make([]Entry, rf.getLastLogL().Index-prevLogIndex), LeaderCommit: rf.commitIndex, } // 必须要复制一遍才能免遭 data race copy(args.Entries, rf.log[prevLogIndex+1-rf.lastIncludedIndex():]) go rf.foraHeartbeat(i, args)   AppendEntries RPC 回复后应如何改变自身状态。   先进行一个 term 的处理  1 2 3 4 5 6 7 8 9 10  if args.Term \u003c rf.currentTerm { reply.Term, reply.Success = rf.currentTerm, false return } if args.Term \u003e rf.currentTerm { rf.changeStateL(Follower, args.Term, NULL) } else { rf.changeStateL(Follower, rf.currentTerm, rf.votedFor) rf.electionTimer.Reset(getElectionDuration()) }    再看看自己的 log 与 RPC 传来的 entries 有没有冲突，有的话以 Leader 为准；返回参数调整自己在 Leader 那边的 nextIndex，直到和 Leader prevLogIndex 的 term 一致为止，才能真正 append entries。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // last log index is too short // entry logAt prevLogIndex whose term doesn't match prevLogTerm if args.PrevLogIndex \u003e rf.getLastLogL().Index || args.PrevLogTerm != rf.logAt(args.PrevLogIndex).Term{ reply.Success, reply.Term = false, rf.currentTerm return } // log 比 Leader 短 || log 比 Leader 长并且存在不匹配 -\u003e 截断并补上 needReplace := rf.getLastLogL().Index \u003c= args.PrevLogIndex+len(args.Entries) if len(args.Entries) \u003e 0 { for i := args.PrevLogIndex + 1; i \u003c= args.PrevLogIndex+len(args.Entries); i++ { // idx and term can identify a log  if rf.getLastLogL().Index \u003e= i \u0026\u0026 rf.logAt(i).Term != args.Entries[i-args.PrevLogIndex-1].Term { needReplace = true break } } if needReplace { rf.log = append(rf.log[:args.PrevLogIndex+1-rf.lastIncludedIndex()], args.Entries...) } }    commit 自己的日志。  1 2 3 4 5 6 7 8 9 10 11  if args.LeaderCommit \u003e rf.commitIndex { rf.commitIndex = args.LeaderCommit if len(args.Entries) \u003e 0 { rf.commitIndex = min(rf.commitIndex, args.Entries[len(args.Entries)-1].Index) } DPrintf(dInfo, \"S%v lastIndex:%v, commIndex:%v, lastApplied:%v\", rf.me, rf.getLastLogL().Index, rf.commitIndex, rf.lastApplied) if rf.commitIndex \u003e rf.lastApplied { rf.applyWaker \u003c- 1 } } reply.Term, reply.Success = rf.currentTerm, true   Leader 方面，只有当大部分 Follower 的 matchIndex 更新（log 存到 Follower）了，Leader 的 commitIndex 才能同步更新。这部分我直接从后往前遍历，因为日志的任期是按顺序增长的，所以如果遇到日志任期小于当前任期直接 break，因为 Leader 只能将自己任期的日志 commit，对于其他任期的日志，只能被动 commit。在 lab 中，没有需要 Leader及时更新旧 commit 的情况，所以不做特殊处理（在成为 Leader 的时候发一个空日志）。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  for i := rf.getLastLogL().Index; i \u003e rf.commitIndex; i-- { if rf.logAt(i).Term != rf.currentTerm { break } cnt := 1 for p := range rf.peers { if p != rf.me \u0026\u0026 rf.matchIndex[p] \u003e= i { cnt++ } } if cnt \u003e len(rf.peers)/2 { rf.commitIndex = i rf.applyWaker \u003c- 1 break } }   Tips  在 currentTerm \u003c args.Term 的时候，我们其实是不需要重置选举时间的，因为如果出现了一个 Leader 比自己任期大，说明自己没有给他投过票，但他得到了半数节点的支持，说明至少半数节点有成为 Candidate 的潜质，并且如果自己真的开始选举的话，会发送无用的 RPC，降低 Raft 的运行效率。   If you follow the rule from Figure 2, the servers with the more up-to-date logs won’t be interrupted by outdated servers’ elections, and so are more likely to complete the election and become the Leader.\n 发送 heartbeat 的时候需要注意自己还是不是 Leader。  因为我忽略了这个点，导致 Leader crash 再恢复的时候有很小的概率出现一个有点怪的 bug：恢复的一瞬间，Leader 想将自己积累已久的日志发给其他节点，被拒收后发现自己的 term 过期了，于是将自己转为 Follower…… 好像没什么问题，但无法完成一致性检验，通过打 log 发现 Leader 在转为 Follower 后的一瞬间发送了最后一波心跳，于是检查代码，发现我在发送心跳给不同的 peer 的时候用的是 go routine 套 go routine，未能保证原子操作，在将要发送心跳的时候，Leader 已经不再是 Leader 了，但还是做出了 Leader 的行为，所以需要在发送前核验自己的 Leader 身份。\n在 updateCommit 的时候我想直接判断成功返回 AppendEntries RPC 的 Follower 数量，如果超过一半就更新 Leader commitIndex = lastLog.index，但因为发送和接受 RPC 并非原子，可能会存在前面的 Follower 未包含后面新增的 log 的情况。   If there exists an N such that N \u003e commitIndex, a majority of matchIndex[i] ≥ N, and log[N].term == currentTerm: set commitIndex = N (§5.3, §5.4).\n ","description":"","tags":null,"title":"6.824 Lab2B","uri":"/posts/6.824-lab2b/"},{"content":" 前置芝士\n Task 完成各种情况的领导人选举。\n我们首先需要熟悉一下 Raft 的工作原理，建议先过一遍 前置芝士。\nStep  先完善 Raft 结构和 Make 函数，再结合 Gif 思考单个节点的状态。 节点开始时的状态是 Follower，election timeout 后，状态会改为 Candidate。我们应该如何设计选举超时，当然是开一个 go routinerf.ticker() 对超时进行检测。那么是用time.Sleep还是time.Timer实现呢？官方的建议是用 sleep，但我用的是 timer，也能够正常实现，并且我还实现了 sleep 的版本，感觉速度上相差无几。   ticker  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func (rf *Raft) ticker() { for !rf.killed() { select { case \u003c-rf.heartbeatTimer.C: rf.mu.Lock() if rf.state == Leader { go rf.startHeartbeat() } rf.mu.Unlock() rf.heartbeatTimer.Reset(getHeartbeatDuration()) case \u003c-rf.electionTimer.C: rf.mu.Lock() if rf.state != Leader { go rf.startElection() } rf.mu.Unlock() rf.electionTimer.Reset(getElectionDuration()) } }   节点成为 Candidate 后并发发送 RequestVote RPC，自己如何处理 RPC 返回的结果，如何判断投给自己的节点数量是否超过半数？   Leader election  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  func (rf *Raft) foraVote(peer int, args *RequestVoteArgs, cnt *int) { reply := RequestVoteReply{} DPrintf(dVote, \"S%v -\u003e S%v send vote\", rf.me, peer) if rf.sendRequestVote(peer, args, \u0026reply) { rf.mu.Lock() defer rf.mu.Unlock() if args.Term == rf.currentTerm \u0026\u0026 rf.state == Candidate { if reply.VoteGranted { DPrintf(dVote, \"S%v \u003c- S%v voted\", rf.me, peer) *cnt++ if *cnt \u003e len(rf.peers)/2 { for i := range rf.peers { rf.nextIndex[i] = rf.getLastLogL().Index + 1 rf.matchIndex[i] = 0 } rf.changeStateL(Leader) } } else if reply.Term \u003e rf.currentTerm { DPrintf(dVote, \"S%v \u003c- S%v ~voted\", rf.me, peer) rf.changeStateL(Follower, reply.Term, NULL) rf.persist() } } } }   peer 节点从哪些方面处理投票逻辑，任期？日志情况（2B）？   Follower RequestVote RPC handler  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.mu.Lock() defer rf.mu.Unlock() defer rf.persist() // currTerm higher || voted \tif rf.currentTerm \u003e args.Term || (rf.votedFor != NULL \u0026\u0026 rf.currentTerm == args.Term) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } if rf.currentTerm \u003c args.Term { rf.changeStateL(Follower, args.Term, NULL) } // check log Leader \t// Candidate lastLogTerm to short || (lastLogTerm=rf.lastLogTerm \u0026\u0026 Candidate lastLogIndex to short) \tif rf.getLastLogL().Term \u003e args.LastLogTerm || (rf.getLastLogL().Term == args.LastLogTerm \u0026\u0026 rf.getLastLogL().Index \u003e args.LastLogIndex) { reply.Term, reply.VoteGranted = rf.currentTerm, false return } rf.changeStateL(Follower, args.Term, args.CandidateId) rf.electionTimer.Reset(getElectionDuration()) reply.Term, reply.VoteGranted = rf.currentTerm, true }   Tips   Candidate 选举前要先自增 currentTerm。\n  在 2A 中，我们处理 RequestVote Handler 的时候还不需要关注日志的新旧（2B），rf.persist() 也还不需要关注（2C），仅需要思考任期应该如何处理。\n  因为处理投票 RPC 的返回时需要加锁保证 rf 结构的原子读取和写入，顺便就可以进行投票数量的计数。\n  Candidate 成为 Leader 时，需要及时发送 heartbeat，告诉别人自己是老大，阻止他们的选举。\n  heartbeat 频率不能太高，控制在每秒 10 次以内，否则会突然宕机（但其实我亲测 heartbeatTimeout 设为 60ms，election 设为 rand(180)+180，test 了 1k 次没一次是 fail 的）。\n The paper’s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the Leader sends heartbeats considerably more often than once per 150 milliseconds (e.g., once per 10 milliseconds). Because the tester limits you tens of heartbeats per second, you will have to use an election timeout larger than the paper’s 150 to 300 milliseconds, but not too large, because then you may fail to elect a Leader within five seconds.\n   ","description":"","tags":null,"title":"6.824 Lab2A","uri":"/posts/6.824-lab2a/"},{"content":"Raft Raft 是一个实现分布式共识的协议，主要解决的是分布式一致性的问题。\nOverview 假设现在有一个 Raft 架构的服务。在实验中，Client 首先发送请求给 Service 层，然后 Service 层解析请求为command，将command发送给 Raft 层的 Leader。Leader 在一定时间内通知 Service 层 apply 包含这个command的日志，Service 层才可以将这条日志保存到状态机，进而返回对应的结果给 Client。并且因为 Raft 层不应该存储过多的 log，所以 Service 层还会将 applied 的 log 压缩成快照，以便快速应用。\n我们的任务就是用 go 实现基础的 Raft 架构。\n 领导人选举   最初，所有节点都是 Follower，如果在election timeout内未收到当前term的heartbeat，就会转为 Candidate。 election timeout: 选举超时时间，大概是heartbeat timeout的 3 倍。 转为 Candidate 之后，term++，给自己投票，并发送请求投票的 RPC 给 peer 节点。 收到请求 RPC 的 peer 满足以下两个条件才可以投票： - peer 任期小于 Candidate 的任期或者 peer 任期等于 Candidate 并且当前任期没投过。 - peer 的 log 没有 Candidate 新。 Candidate 得到的票数超过半数的 peer 就可以成为 Leader，因为上述限制，一个集群同一个term只会选出一个 Leader。 Leader 每隔一次heartbeat timeout就发送一次包含 snapshot 或 log 的 heartbeat，发送快照还是日志根据 peer 的 nextIndex 而定。  nextIndex 是 Leader 对 peer 日志长度的乐观推测，成为 Leader 后会对所有 peer 的 nextIndex 赋值为自己的 lastLogIndex+1，而后会根据 heartbeat 结果更改 nextIndex。 lastIncludeIndex 每个节点都有，表示 snapshot 包含的最后一个日志的下标，初始为 0。 如果 $nextIndex \\leq lastIncludedIndex$ ，发送 InstallSnapshot RPC，否则发送 AppendEntries RPC。   Follower 需要对 Leader 发送的心跳进行处理。   日志复制    Service 层会通过 Start(cmd) 发送 command 给 Leader。\n  Leader 需要保存 command 至 log，并在心跳的时候向 Follower 发送他没有的 log。\n  Leader 等待一半以上的 Follower 写入自己的日志，再进行 commit。\n 判断 Follower 写入日志的标准是 matchIndex，上面有提到 nextIndex 是 Leader 对 peer 日志长度的乐观推测，matchIndex 则是相对悲观的推测，只有在 AppendEntries RPC 返回成功后 Leader 才会更新相应 Follower 的 matchIndex。 并且考虑 RPC 调用的非线性返回，需要在修改 matchIndex 的时候判断需要修改的值是否真的大于当前的 matchIndex 的值。    Leader commit 后修改 commitIndex 的值，并另开一个 go routine 将从lastApplied+1 到 commitIndex 的值推到 applyCh，再修改lastApplied = commitIndex。\n  Follower 在 Leader commit 后也会以 Leader 的 commitIndex 作为限制 commit 自己的 log，并和 Leader 一样，将日志交给 service apply。\n   日志压缩   Service 层在若干 commit 后，会压缩已提交的日志，并通过 Snapshot(index,snapshot) 提醒 raft 层。 raft 层则需要进行一些处理，比如删掉被压缩的日志，改变日志的索引方式，持久化 snapshot 的信息（但不需要保存 snapshot，snapshot 仅存在 Service 层）。 对于 Leader，在 heartbeat 时，若满足 $nextIndex \\leq lastIncludedIndex$ ，则通过 persister.ReadSnapshot() 读取 snapshot 给 Follower。 如果 Follower term \u003c= Leader term，只能接受 snapshot，并删掉被压缩的日志，改变日志的索引方式，持久化 snapshot 的信息。  Tips   注意 data race，对大部分 rf 结构的修改和读取都要上锁。\n  所有 RPC 都要检测任期，并对过期状态进行处理。\n  在 lab2D 中，需要改变下标的索引方式。\n   Each log entry also has an integer index iden-tifying its position in the log.\n 但这个其实很容易改，所以推荐在 2D 之前不要去管下标的问题，直接用 log 数组自己的下标就可以了。\nres reference\nhttps://thesquareplanet.com/blog/students-guide-to-raft/\nhttps://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf\nhttps://pdos.csail.mit.edu/6.824/notes/raft_diagram.pdf\nhttp://thesecretlivesofdata.com/raft/\nhttps://pdos.csail.mit.edu/6.824/labs/raft-structure.txt\nhttps://pdos.csail.mit.edu/6.824/labs/raft-locking.txt\nhttps://blog.josejg.com/debugging-pretty/\nhttps://flaneur2020.github.io/2020/11/07/mit6-824-raft/\nhttps://github.com/OneSizeFitsQuorum/MIT6.824-2021/blob/master/docs/lab2.md\n","description":"","tags":null,"title":"6.824 Lab2","uri":"/posts/6.824-lab2/"},{"content":"Lab1 MapReduce Paper MapReduce: Simplified Data Processing on Large Clusters\nMapReduce 将分布式系统处理数据的细节（并行、容错、局部性优化、负载均衡等）隐藏起来，提供一套简化方案，解决了在多台机器处理大量逻辑简单的计算（分布式计算）实现复杂的问题。\n实现 本实验可以由 1 个 coordinator/master 调度若干个 worker。先完成所有 map 任务，生成中间键值对并将其存在中间文件后再进行 reduce 任务，最后将 reduce 任务的结果输出到文本。\n需要我们修改的文件为 mr/*\n worker 通过 RPC 循环请求任务。 coordinator 读取 8 个给定的文件分给不同的 worker 进行 map 任务，这部分如果喜欢也可以按固定 bytes 进行切割但我懒得处理了。 worker 读取文件并扔给fmap进行处理，生成中间键值对，计算字符串的 hash 后将key-intermediate_value存在 mr-taskid-ihash(str) 里面。   fmap 函数通过编译生成的 *.so 调用\n .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\n看到一些同学是先 os.CreateTemp(\"\", tmpFileName) 存在临时文件里面，等处理完了再 rename 成mr-taskid-ihash(str)。这样应该会更加规范一些，但不创建 tempfile 在 lab1 理论上应该也是可行的。\n当文件没完全写完 worker 就 crash 时，这个任务会被 coordinator 发现并交给别的 worker 重做。因为用的是os.Create()，文件会被新的覆盖，直到 worker 成功完成任务为止。\n如果逻辑允许两个 worker 同时处理一个任务的话，就需要创建 tempFile 再 rename 的方式，因为需要保证创建的（临时）文件内容不重复。\n map 任务全部完成后 coordinator 分配 NReduce 个 reduce 任务给不同的 worker 处理。 worker 读取中间文件，并将key-list(intermediate_value)扔给freduce处理成key-value 写入mr-out-ihash(str)。 coordinator 发现任务全都处理完后踢走 worker，并在若干秒后退出。  Tips   结构\n  go 可以用 const 和 iota 代替 enum。\n  WorkerInfo 在这个实验可以省略，不需要保留 worker 的状态，但我写了就不想删了。\n  本来还想往结构体内置一个 logger 的，但 RPC 调用需要 gob 序列化，而 logger 不知道为啥会序列化失败，不知道是啥 bug，以后再瞅瞅。\n    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  const ( _ = iota // MAP REDUCE WAIT: Task type \tMAP REDUCE WAIT // IDLE BUSY DONE: Task status || WorkerInfo status \tIDLE BUSY DONE ) type Coordinator struct { NMap int // map 任务的个数 \tNReduce int // reduce 任务的个数 \tDMap int // 记录 map task 完成的个数 \tDReduce int // 记录 reduce task 完成的个数 \tWorkerId int // 为新的 worker 分配 workerIds \tTaskDone map[int]bool // 记录 task 是否被完成 \tMap chan *Task // 待取出的 map task \tReduce chan *Task // 待取出的 reduce task \tTaskMutex sync.Mutex // 用于任务分发相关数据的 mutex \tDoneMutex sync.Mutex // 用于完成任务相关数据的 mutex \tMutex sync.Mutex // 用于其他细节的 mutex } type Task struct { StartTime time.Time NReduce int // 传给 worker，用于 ihash 的 mod \tType int // MAP REDUCE WAIT \tStatus int // IDLE BUSY DONE \tFileName string TaskId int WorkerId int } type WorkerInfo struct { WorkerId int TaskId int Type int Status int //Lg *log.Logger \t//Why this error? \t//gob: type log.Logger has no exported fields \t//2023/01/31 14:34:13 RPC getWork failed \t//exit status 1 } // Map functions return a slice of KeyValue. type KeyValue struct { Key string Value string }   RPC 写入 reply 的时候不能直接将 reply 指向一个新的地址，而是要修改 reply 地址的值。  1 2 3 4 5 6 7 8 9 10 11 12  //reply = \u0026GetWorkReply{\u0026Task{...}} \t//上面的方法不会返回想要的 reply，因为 reply 指向的是新的 GetWorkReply 值在 rpc 服务器的指针。这部分客户端的内存和服务器的不一样，所以得到的是空值；下面的方法因为 reply 是共享内存的，所以服务器和客户端都可以访问 \u0026reply。 \t//在 RPC 调用时，要避免传递指针参数，如果传递的参数是值类型，那么这个值将会被复制到另一个地址 \t*reply = GetWorkReply{Task{ StartTime: time.Now(), Type: MAP, Status: BUSY, FileName: mapTask.FileName, NReduce: c.NReduce, WorkerId: args.WorkerId, TaskId: mapTask.TaskId, }} // equal to reply.Task = \u0026Task{...}   clash test，需要 coordinator 在 worker 宕机 10s 后为同一个任务重新分配 worker，这部分需要考虑一下注意一下 data race  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  go func(taskId int, filename string) { select { case \u003c-time.After(12 * time.Second): c.Mutex.Lock() if !c.TaskDone[taskId] { c.Mutex.Unlock() dosomething } else { c.Mutex.Unlock() dootherthing } // default:{  // }  // default 不能写，如果写了就会直接跳到 default，不会进入 12s 的 case  } return }(maptask.TaskId, mapTask.FileName)   并发编程细节  因为 MapReduce 的特性，map task 可以并发，reduce task 可以并发，但两种任务不能同时并发，所以需要等到 map task 跑完才可以进行 reduce task。如果同时读写同一个变量，需要加锁。其实还可以用 chan 实现 lock-free，以后试试，如果有时间的话。\n贴一下测试的 makefile  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # location: src/Makefile ntest := 50 lab1: @cd main;\\  for i in $$(seq 1 $(ntest)) ; do\\  bash test-mr.sh \u003e res$$i;\\  done;\\  cnt=0;\\ \tfor i in $$(seq 1 $$(expr $(ntest) - 1)); do\\ \tif cmp res$$i res$$(expr $$i + 1); then \\ \tcnt=$$(expr $$cnt + 1); \\ \tfi;\\ \tdone;\\ \techo \"same file num:\"$$(expr $$cnt + 1) ;\\ \tif [ $$cnt -eq $$(expr $(ntest) - 1) ]; then \\ \techo \"****************************************************************\";\\ \techo \"all res is the same!\";\\ \techo \"result content as follow.\";\\ \techo \"****************************************************************\";\\ \tcat main/res1;\\ \techo \"****************************************************************\";\\ \tfi   result  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  same file num:50 **************************************************************** all res is the same! result content as follow. **************************************************************** *** Starting wc test. --- wc test: PASS *** Starting indexer test. --- indexer test: PASS *** Starting map parallelism test. --- map parallelism test: PASS *** Starting reduce parallelism test. --- reduce parallelism test: PASS *** Starting job count test. --- job count test: PASS *** Starting early exit test. --- early exit test: PASS *** Starting crash test. --- crash test: PASS *** PASSED ALL TESTS ****************************************************************   ","description":"","tags":null,"title":"6.824 Lab1","uri":"/posts/6.824-lab1/"},{"content":"MIT 6.824（现在好像变成了 6.5840 schedule go 并发编程\nlab1 solution\nEfficient debug and test Debugging by Pretty Printing\n Humans are visual creatures so it’s a good idea to make use of visual tools like colors or columns to encode different types of information.\n  dslogs.py -\u003e build pretty printer for logs  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115  #!/usr/bin/env python import sys import shutil from typing import Optional, List, Tuple, Dict import typer from rich import print from rich.columns import Columns from rich.console import Console from rich.traceback import install # fmt: off # Mapping from topics to colors TOPICS = { \"TIMR\": \"#9a9a99\", \"VOTE\": \"#67a0b2\", \"LEAD\": \"#d0b343\", \"TERM\": \"#70c43f\", \"LOG1\": \"#4878bc\", \"LOG2\": \"#398280\", \"CMIT\": \"#98719f\", \"PERS\": \"#d08341\", \"SNAP\": \"#FD971F\", \"DROP\": \"#ff615c\", \"CLNT\": \"#00813c\", \"TEST\": \"#fe2c79\", \"INFO\": \"#ffffff\", \"WARN\": \"#d08341\", \"ERRO\": \"#fe2626\", \"TRCE\": \"#fe2626\", \"FORC\": \"#3571a4\", \"HEAR\": \"#ffcf3e\", \"STAT\": \"#cf5fb4\" } # fmt: on def list_topics(value: Optional[str]): if value is None: return value topics = value.split(\",\") for topic in topics: if topic not in TOPICS: raise typer.BadParameter(f\"topic {topic}not recognized\") return topics def main( file: typer.FileText = typer.Argument(None, help=\"File to read, stdin otherwise\"), colorize: bool = typer.Option(True, \"--no-color\"), n_columns: Optional[int] = typer.Option(None, \"--columns\", \"-c\"), ignore: Optional[str] = typer.Option(None, \"--ignore\", \"-i\", callback=list_topics), just: Optional[str] = typer.Option(None, \"--just\", \"-j\", callback=list_topics), ): topics = list(TOPICS) # We can take input from a stdin (pipes) or from a file input_ = file if file else sys.stdin # Print just some topics or exclude some topics (good for avoiding verbose ones) if just: topics = just if ignore: topics = [lvl for lvl in topics if lvl not in set(ignore)] topics = set(topics) console = Console() width = console.size.width panic = False for line in input_: try: time, topic, *msg = line.strip().split(\" \") # To ignore some topics if topic not in topics: continue msg = \" \".join(msg) # Debug calls from the test suite aren't associated with # any particular peer. Otherwise we can treat second column # as peer id if topic != \"TEST\": i = int(msg[1]) # Colorize output by using rich syntax when needed if colorize and topic in TOPICS: color = TOPICS[topic] msg = f\"[{color}]{msg}[/{color}]\" # Single column printing. Always the case for debug stmts in tests if n_columns is None or topic == \"TEST\": print(time, msg) # Multi column printing, timing is dropped to maximize horizontal # space. Heavylifting is done through rich.column.Columns object else: cols = [\"\" for _ in range(n_columns)] msg = \"\" + msg cols[i] = msg col_width = int(width / n_columns) cols = Columns(cols, width=col_width - 1, equal=True, expand=True) print(cols) except: # Code from tests or panics does not follow format # so we print it as is if line.startswith(\"panic\"): panic = True # Output from tests is usually important so add a # horizontal line with hashes to make it more obvious if not panic: print(\"#\" * console.width) print(line, end=\"\") if __name__ == \"__main__\": typer.run(main)   dstest.py -\u003e concurrency test  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251  #!/usr/bin/env python import itertools import math import signal import subprocess import tempfile import shutil import time import os import sys import datetime from collections import defaultdict from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED from dataclasses import dataclass from pathlib import Path from typing import List, Optional, Dict, DefaultDict, Tuple import typer import rich from rich import print from rich.table import Table from rich.progress import ( Progress, TimeElapsedColumn, TimeRemainingColumn, TextColumn, BarColumn, SpinnerColumn, ) from rich.live import Live from rich.panel import Panel from rich.traceback import install install(show_locals=True) @dataclass class StatsMeter: \"\"\" Auxiliary classs to keep track of online stats including: count, mean, variance Uses Welford's algorithm to compute sample mean and sample variance incrementally. https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#On-line_algorithm \"\"\" n: int = 0 mean: float = 0.0 S: float = 0.0 def add(self, datum): self.n += 1 delta = datum - self.mean # Mk = Mk-1+ (xk – Mk-1)/k self.mean += delta / self.n # Sk = Sk-1 + (xk – Mk-1)*(xk – Mk). self.S += delta * (datum - self.mean) @property def variance(self): return self.S / self.n @property def std(self): return math.sqrt(self.variance) def print_results(results: Dict[str, Dict[str, StatsMeter]], timing=False): table = Table(show_header=True, header_style=\"bold\") table.add_column(\"Test\") table.add_column(\"Failed\", justify=\"right\") table.add_column(\"Total\", justify=\"right\") if not timing: table.add_column(\"Time\", justify=\"right\") else: table.add_column(\"Real Time\", justify=\"right\") table.add_column(\"User Time\", justify=\"right\") table.add_column(\"System Time\", justify=\"right\") for test, stats in results.items(): if stats[\"completed\"].n == 0: continue color = \"green\" if stats[\"failed\"].n == 0 else \"red\" row = [ f\"[{color}]{test}[/{color}]\", str(stats[\"failed\"].n), str(stats[\"completed\"].n), ] if not timing: row.append(f\"{stats['time'].mean:.2f}± {stats['time'].std:.2f}\") else: row.extend( [ f\"{stats['real_time'].mean:.2f}± {stats['real_time'].std:.2f}\", f\"{stats['user_time'].mean:.2f}± {stats['user_time'].std:.2f}\", f\"{stats['system_time'].mean:.2f}± {stats['system_time'].std:.2f}\", ] ) table.add_row(*row) print(table) def run_test(test: str, race: bool, timing: bool): test_cmd = [\"go\", \"test\", f\"-run={test}\"] if race: test_cmd.append(\"-race\") if timing: test_cmd = [\"time\"] + test_cmd f, path = tempfile.mkstemp() start = time.time() proc = subprocess.run(test_cmd, stdout=f, stderr=f) runtime = time.time() - start os.close(f) return test, path, proc.returncode, runtime def last_line(file: str) -\u003e str: with open(file, \"rb\") as f: f.seek(-2, os.SEEK_END) while f.read(1) != b\"\\n\": f.seek(-2, os.SEEK_CUR) line = f.readline().decode() return line # fmt: off def run_tests( tests: List[str], sequential: bool = typer.Option(False, '--sequential', '-s', help='Run all test of each group in order'), workers: int = typer.Option(1, '--workers', '-p', help='Number of parallel tasks'), iterations: int = typer.Option(10, '--iter', '-n', help='Number of iterations to run'), output: Optional[Path] = typer.Option(None, '--output', '-o', help='Output path to use'), verbose: int = typer.Option(0, '--verbose', '-v', help='Verbosity level', count=True), archive: bool = typer.Option(False, '--archive', '-a', help='Save all logs intead of only failed ones'), race: bool = typer.Option(False, '--race/--no-race', '-r/-R', help='Run with race checker'), loop: bool = typer.Option(False, '--loop', '-l', help='Run continuously'), growth: int = typer.Option(10, '--growth', '-g', help='Growth ratio of iterations when using --loop'), timing: bool = typer.Option(False, '--timing', '-t', help='Report timing, only works on macOS'), # fmt: on ): if output is None: timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") output = Path(timestamp) if race: print(\"[yellow]Running with the race detector\\n[/yellow]\") if verbose \u003e 0: print(f\"[yellow] Verbosity level set to {verbose}[/yellow]\") os.environ['VERBOSE'] = str(verbose) while True: total = iterations * len(tests) completed = 0 results = {test: defaultdict(StatsMeter) for test in tests} if sequential: test_instances = itertools.chain.from_iterable(itertools.repeat(test, iterations) for test in tests) else: test_instances = itertools.chain.from_iterable(itertools.repeat(tests, iterations)) test_instances = iter(test_instances) total_progress = Progress( \"[progress.description]{task.description}\", BarColumn(), TimeRemainingColumn(), \"[progress.percentage]{task.percentage:\u003e3.0f}%\", TimeElapsedColumn(), ) total_task = total_progress.add_task(\"[yellow]Tests[/yellow]\", total=total) task_progress = Progress( \"[progress.description]{task.description}\", SpinnerColumn(), BarColumn(), \"{task.completed}/{task.total}\", ) tasks = {test: task_progress.add_task(test, total=iterations) for test in tests} progress_table = Table.grid() progress_table.add_row(total_progress) progress_table.add_row(Panel.fit(task_progress)) with Live(progress_table, transient=True) as live: def handler(_, frame): live.stop() print('\\n') print_results(results) sys.exit(1) signal.signal(signal.SIGINT, handler) with ThreadPoolExecutor(max_workers=workers) as executor: futures = [] while completed \u003c total: n = len(futures) if n \u003c workers: for test in itertools.islice(test_instances, workers-n): futures.append(executor.submit(run_test, test, race, timing)) done, not_done = wait(futures, return_when=FIRST_COMPLETED) for future in done: test, path, rc, runtime = future.result() results[test]['completed'].add(1) results[test]['time'].add(runtime) task_progress.update(tasks[test], advance=1) dest = (output / f\"{test}_{completed}.log\").as_posix() if rc != 0: print(f\"Failed test {test}- {dest}\") task_progress.update(tasks[test], description=f\"[red]{test}[/red]\") results[test]['failed'].add(1) else: if results[test]['completed'].n == iterations and results[test]['failed'].n == 0: task_progress.update(tasks[test], description=f\"[green]{test}[/green]\") if rc != 0 or archive: output.mkdir(exist_ok=True, parents=True) shutil.copy(path, dest) if timing: line = last_line(path) real, _, user, _, system, _ = line.replace(' '*8, '').split(' ') results[test]['real_time'].add(float(real)) results[test]['user_time'].add(float(user)) results[test]['system_time'].add(float(system)) os.remove(path) completed += 1 total_progress.update(total_task, advance=1) futures = list(not_done) print_results(results, timing) if loop: iterations *= growth print(f\"[yellow]Increasing iterations to {iterations}[/yellow]\") else: break if __name__ == \"__main__\": typer.run(run_tests)   configuration  1 2 3  # ~/.zshrc  alias dslogs=\"python ~/.pyScript/dslogs.py\" alias dstest=\"python ~/.pyScript/dstest.py\"    dslogs  VERBOSE=1 go test \u003e out\ndslog out -c 6\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  ❯ dslogs --help Usage: dslogs.py [OPTIONS] [FILE] ╭─ Arguments ────────────────────────────────────────────────────── │ file [FILE] File to read, stdin otherwise [default: None] ╰────────────────────────────────────────────────────────────────── ╭─ Options ──────────────────────────────────────────────────────── │ --no-color [default: True] │ --columns -c INTEGER [default: None] // \u003erf的数量 │ --ignore -i TEXT [default: None] // 不显示某些TAG │ --just -j TEXT [default: None] // 仅显示某些TAG │ --help Show this message and exit. ╰──────────────────────────────────────────────────────────────────    dstest  dstest -v 1 -s -p 10 -n 10 -o logs -r 2A\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  ❯ dstest --help Usage: dstest.py [OPTIONS] TESTS... ╭─ Arguments ───────────────────────────────────────────────────────────────────────────────────────── │ * tests TESTS... [default: None] [required] ╰───────────────────────────────────────────────────────────────────────────────────────────────────── ╭─ Options ─────────────────────────────────────────────────────────────────────────────────────────── │ --sequential -s Run all test of each group in order │ --workers -p INTEGER Number of parallel tasks [default: 1] // 线程数 │ --iter -n INTEGER Number of iterations to run [default: 10] // 重复运行同一个任务 │ --output -o PATH Output path to use [default: None] │ --verbose -v INTEGER Verbosity level [default: 0] // 是否显示Dprintf内容 │ --archive -a Save all logs intead of only failed ones │ --race -r --no-race -R Run with race checker [default: no-race] │ --loop -l Run continuously // 测完后继续无限测试 │ --growth -g INTEGER Growth ratio of iterations when using --loop [default: 10] // 和loop配合使用，iter*=growth │ --timing -t Report timing, only works on macOS │ --help Show this message and exit. ╰─────────────────────────────────────────────────────────────────────────────────────────────────────   ","description":"","tags":null,"title":"6.824","uri":"/posts/6.824/"},{"content":"RPC  Remote Procedure Call\n 特点 区别于HTTP服务的RESTful风格接口，RPC主要是远程函数调用，HTTP则更关注与资源。并且RPC服务可以减少网络开销，各种意义上提高效率。\n一言以蔽之，RPC协议的主要目的是做到不同服务间调用方法像同一服务间调用本地方法一样\n优点  单一责任 扩展性 故障隔离  一言以蔽之，RPC协议的主要目的是做到不同服务间调用方法像同一服务间调用本地方法一样。\n问题 服务宕机\n网络异常\n服务时长不合预期\n理论 论文架构 User, User-Stub, RPC-Runtime, Server-Stub, Server\n实现 IDL (Interface description language) Descript the interface.\nTLV编码  Tag：类型 Length：长度 Value：值（也可以是TLV结构）   GenCode Translate the IDL to different programming language.\nNeed decode and encode logic.\n兼容性——增加新的字段不影响现有服务\n通用性——跨平台跨语言\n性能——空间时间维度，编码后的数据大小和编码时长\nEncode Conv code to byte.\nProtocol Necessary data and metadata\n0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f +—————————————————————-+ | 0| LENGTH | +—————————————————————-+ | 0| HEADER MAGIC | FLAGS | +—————————————————————-+ | SEQUENCE NUMBER | +—————————————————————-+ | 0| Header Size(/32) | … +———————————\n Header is of variable size: (and starts at offset 14)  +—————————————————————-+ | PROTOCOL ID (varint) | NUM TRANSFORMS (varint) | +—————————————————————-+ | TRANSFORM 0 ID (varint) | TRANSFORM 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | INFO 0 ID (varint) | INFO 0 DATA … +—————————————————————-+ | … … | +—————————————————————-+ | | | PAYLOAD | | | +—————————————————————-+\nLENGTH: 数据包大小，不包含自身\nHEADER MAGIC:标识版本信息，协议解析时快速校验\nSEQUENCE NUMBER:表示数据包的seqlD，可用于多路复用，单连接内递增\n 多路复用(multiplexing) 在单个通信信道上传输多个信息。它可以让多个应用程序或进程在同一时间共享一个信道。以有效地利用带宽和资源，提高系统的效率。常见技术：时分多路复用TDM，波分多路复用WDM，包交换。一般通过TCP/IP实现。\n HEADER SIZE:头部长度，从第14个字节开始计算一直到PAYLOAD前 PROTOCOL ID:编解码方式，有Binary和Compact两种 TRANSFORM ID:压缩方式，如zlilb 和snappy INFO ID:传递一些定制的meta信息 PAYLOAD:消息体\nNetwork Transfer Application Layer Sockets API TCP/UDP IP Driver Physical Layer RPC框架 reference\nhttp://ddia.vonng.com/#/ch4?id=%e6%9c%8d%e5%8a%a1%e4%b8%ad%e7%9a%84%e6%95%b0%e6%8d%ae%e6%b5%81%ef%bc%9arest%e4%b8%8erpc\n","description":"","tags":null,"title":"RPC","uri":"/posts/rpc/"},{"content":"go-zero go-zero简介 go-zero是一个能够快速生成API，MODEL和RPC的框架。\ngo-zero 项目结构（不含RPC） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85  . ├── api │ ├── etc │ │ └── park-api.yaml │ ├── internal │ │ ├── config │ │ │ └── config.go │ │ ├── handler │ │ │ ├── accessHandler.go │ │ │ ├── deviceInfoHandler.go │ │ │ ├── incomeHandler.go │ │ │ ├── parkingLotHandler.go │ │ │ ├── routes.go │ │ │ ├── siteInfoHandler.go │ │ │ ├── touristCarProvinceHandler.go │ │ │ ├── touristFlowHandler.go │ │ │ ├── userHandler.go │ │ │ └── wechatHandler.go │ │ ├── logic │ │ │ ├── accessLogic.go │ │ │ ├── deviceInfoLogic.go │ │ │ ├── incomeLogic.go │ │ │ ├── parkingLotLogic.go │ │ │ ├── siteInfoLogic.go │ │ │ ├── touristCarProvinceLogic.go │ │ │ ├── touristFlowLogic.go │ │ │ ├── userLogic.go │ │ │ └── wechatLogic.go │ │ ├── svc │ │ │ └── serviceContext.go │ │ └── types │ │ └── types.go │ ├── park.api │ ├── park.go │ └── park.md ├── genModel │ ├── model │ │ ├── accessModel.go │ │ ├── accessModel_gen.go │ │ ├── deviceInfoModel.go │ │ ├── deviceInfoModel_gen.go │ │ ├── incomeModel.go │ │ ├── incomeModel_gen.go │ │ ├── logErrModel.go │ │ ├── logErrModel_gen.go │ │ ├── parkingLotModel.go │ │ ├── parkingLotModel_gen.go │ │ ├── siteInfoModel.go │ │ ├── siteInfoModel_gen.go │ │ ├── touristCarProvinceModel.go │ │ ├── touristCarProvinceModel_gen.go │ │ ├── touristFlowModel.go │ │ ├── touristFlowModel_gen.go │ │ ├── userModel.go │ │ ├── userModel_gen.go │ │ ├── vars.go │ │ ├── wechatModel.go │ │ └── wechatModel_gen.go │ └── resources │ ├── genModel.sh │ └── park.sql ├── go.mod ├── go.sum └── model ├── accessModel.go ├── accessModel_gen.go ├── deviceInfoModel.go ├── deviceInfoModel_gen.go ├── incomeModel.go ├── incomeModel_gen.go ├── logErrModel.go ├── logErrModel_gen.go ├── parkingLotModel.go ├── parkingLotModel_gen.go ├── siteInfoModel.go ├── siteInfoModel_gen.go ├── touristCarProvinceModel.go ├── touristCarProvinceModel_gen.go ├── touristFlowModel.go ├── touristFlowModel_gen.go ├── userModel.go ├── userModel_gen.go ├── vars.go ├── wechatModel.go └── wechatModel_gen.go    api 文件夹用于存放外部调用，需要改动的是 *.api, etc/*.yaml, svc/serviceContext.go, logic/*，作用分别是生成 api 调用框架，写配置文件，将数据添加到 Context 供逻辑调用，逻辑实现。 genModel 文件夹用于生成数据库调用相关实现，需要改动的是resources/*.sql。 model 文件夹用于添加额外的数据库调用逻辑（将genModel/model/*复制到model后开改！）  简单使用 通过goctl生成代码框架。\nAPI 框架通过 api/*.api生成 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114  //park.api syntax = \"v1\" info( title: \"parkApi\" desc: \"parkBackEnd\" author: \"loomt\" email: \"loomt_@outlook.com\" version: \"1.0\" ) type ( accessResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 接入地点 \tDate string `json:\"date\"` // 接入日期 \tNum int64 `json:\"num\"` // 接入数量 \t} incomeResp { Id int64 `json:\"id\"` Type string `json:\"type\"` // 收入类型 \tDate string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 当天收入 \t} parkingLotResp { Id int64 `json:\"id\"` Name string `json:\"name\"` // 停车场名字 \tDuration int64 `json:\"duration\"` // 停车时间（小时） \tNum int64 `json:\"num\"` // 泊车数 \t} siteInfoResp { Id int64 `json:\"id\"` Date string `json:\"date\"` // 日期 \tRevisitRate int64 `json:\"revisit_rate\"` // 重复访问率（%） \tSiteHealth int64 `json:\"site_health\"` // 站点健康度 \tRfHealth int64 `json:\"rf_health\"` // 射频健康度 \tDeviceHealth int64 `json:\"device_health\"` // 设备健康度 \tFlow int64 `json:\"flow\"` // 当日站点流量 \t} touristFlowResp { Id int64 `json:\"id\"` Location string `json:\"location\"` // 园区地点 \tDate string `json:\"date\"` // 时间 \tNum int64 `json:\"num\"` // 游客数量 \t} touristCarProvinceResp { Id int64 `json:\"id\"` Province string `json:\"province\"` // 省份 \tDate string `json:\"date\"` // 日期 \tFlowNum int64 `json:\"flow_num\"` // 人流数量 \tCarNum int64 `json:\"car_num\"` // 车辆数 \t} userReq { Id int64 `json:\"id\"` // 用户id \t} userResp { Id int64 `json:\"id\"` // 用户id \tUsername string `json:\"username\"` // 用户名 \t} wechatResp { Date string `json:\"date\"` // 日期 \tNum int64 `json:\"num\"` // 微信关注数量 \t} deviceInfoResp { Id int64 `json:\"id\"` UplinkRate float64 `json:\"uplink_rate\"` // 上行速率 \tDownlinkRate float64 `json:\"downlink_rate\"` // 下载速率 \tFlow float64 `json:\"flow\"` // 流量 \tCpuRate float64 `json:\"cpu_rate\"` // CPU占有率 \tLongitude float64 `json:\"longitude\"` // 经度 \tLatitude float64 `json:\"latitude\"` // 纬度 \t} ) @server( prefix: api ) service park-api { @doc \"获取接入详情\" @handler accessHandler get /access returns (accessResp) @doc \"获取日收入详情\" @handler incomeHandler get /income returns (incomeResp) @doc \"获取停车详情\" @handler parkingLotHandler get /parkingLot returns (parkingLotResp) @doc \"获取站点详情\" @handler siteInfoHandler get /siteInfo returns (siteInfoResp) @doc \"获取客流量详情\" @handler touristFlowHandler get /touristFlow returns (touristFlowResp) @doc \"获取游客与车辆来源省份\" @handler touristCarProvinceHandler get /touristCarProvince returns (touristCarProvinceResp) @doc \"获取用户详情\" @handler userHandler post /user (userReq) returns (userResp) @doc \"获取微信关注详情\" @handler wechatHandler get /wechat returns (wechatResp) @doc \"获取设备信息\" @handler deviceInfoHandler get /deviceInfo returns (deviceInfoResp) }   1 2  # api goctl api go -api *.api -dir ./ --style=goZero   MODEL 框架有两种生成方式  连接数据库生成model  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #!/usr/bin/env zsh # 使用方法： # ./genModel.sh usercenter user # ./genModel.sh usercenter user_auth # 再将./genModel下的文件剪切到对应服务的model目录里面，记得改package #生成的表名 tables=$2 #表生成的genmodel目录 modeldir=../model # 数据库配置 host=127.0.0.1 port=3306 dbname=$1 username=root passwd=123456 echo \"开始创建库：$dbname的表：$2\" goctl model mysql datasource -url=\"${username}:${passwd}@tcp(${host}:${port})/${dbname}\" -table=\"${tables}\" -dir=\"${modeldir}\" --style=goZero    直接用 sql 文件(genModel/resource/*.sql)生成 model  1 2  # genModel/resources goctl model mysql ddl -src=\"./*.sql\" -dir=\"../model\" --style=goZero   生成文档 1 2  # ./ goctl api doc -dir .   华为云部署  mysql 导入 nohup go run *.go -f etc/*.yaml 2\u003e\u00261 \u0026  ","description":"","tags":null,"title":"go-zero单体服务","uri":"/posts/go-zero%E5%8D%95%E4%BD%93%E6%9C%8D%E5%8A%A1/"},{"content":"记一次华为云耀云服务器公网部署问题 开了安全组，用 caddy 部署了一个小网页来测试公网访问 可以看到内网访问是正常的。也可以 ping 通\n根据华为云官网给出的指引排查了很久，绑定了弹性公网 ip，设置了安全组 Sys-FullAccess、ACL，都无法用浏览器访问。\n最后回到服务器 查询防火墙状态\n关掉防火墙就可以了 对着华为云的控制台搞了很久安全组，还以为安全组哪里配错了，最后发现是服务器防火墙的问题😭\n","description":"","tags":null,"title":"华为云公网部署","uri":"/posts/%E5%8D%8E%E4%B8%BA%E4%BA%91%E5%85%AC%E7%BD%91%E9%83%A8%E7%BD%B2/"},{"content":" 摆烂，于是将目光看向了家里的小米4a千兆版路由器，准备刷个Openwrt玩一下。\n 去恩山论坛逛了逛，感觉刷软路由和刷手机差不太多。\n 安装Breed（闭源免费的BootLoader，又称“不死鸟”，有了它就能肆无忌惮地刷各种第三方包了  如果你的路由器是小米4A千兆版，可以直接用恩山论坛的无脑直装Breed；如果不是，也可以去Breed官网下载路由器的适配包并自行搜索如何通过Telnet连接路由器并刷入Breed。 用Breed安装OpenWrt  这里放一个小米4A千兆版OpenWrt直刷包，其他路由器的固件可以去恩山论坛逛逛。 .notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 警告\n刷OpenWrt之前必须用Breed备份eeprom（没有备份eeprom将导致5G信号奇差）\n 点击固件更新~\u003e常规固件~\u003e勾上“固件”和“EEPROM”，选择好上面的直刷包和备份的eeprom.bin，上传即可。\n配置OpenWrt的各项参数（随便配一下即可  OpenWrt可谓神通广大，作为一个在路由器上跑的Linux，它可以装上各种插件：酸酸乳、Docker、网易云解锁灰色歌曲……\n但我折腾了一通，调教好基础的上网功能后，感觉网络状况大不如前。作为百来块的路由器，本来就没有多大的内存，感觉原厂固件的调教已经将性能都用在刀刃上了。装了OpenWrt后虽然上下行流量速度没有很大变化，但稳定性差了很多，便懒得继续折腾，忍痛remake了。\n刷回官方包（没备份eeprom的问题 或许 也可以通过刷回官方包的方法解决  下载小米4A千兆版官方包，进入Breed~\u003e固件更新~\u003e编程器固件(仅勾选自动重启)~\u003e上传all.bin。\n","description":"","tags":null,"title":"小米4A千兆版刷OpenWrt","uri":"/posts/%E5%B0%8F%E7%B1%B34a%E5%8D%83%E5%85%86%E7%89%88%E5%88%B7openwrt/"},{"content":"7-Zip双击自动解压压缩文件  因为难以忍受7zip的右键解压操作，通过修改注册表以自动解压。\n  替换 D:\\\\000000000000\\\\7-Zip 为 your\\\\path\\\\to\\\\7-Zip 将代码塞进.reg文件，双击即可。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421  Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\7-Zip.001\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.001\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.7z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.arj\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.bzip2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cab\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.cpio\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.deb\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.dmg\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.fat\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.gzip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.hfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.iso\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lha\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzh\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.lzma\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.ntfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.rpm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.squashfs\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.swm\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.taz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tbz2\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tgz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.tpz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.txz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.vhd\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.wim\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xar\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.xz\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.z\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell] @=\"extract\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract] @=\"Extract to Folder\" [HKEY_CLASSES_ROOT\\7-Zip.zip\\shell\\extract\\command] @=\"\\\"D:\\\\000000000000\\\\7-Zip\\\\7zG.exe\\\" x \\\"%1\\\" -o*\"   reference\nhttps://gist.github.com/zabbarob/5891200\n","description":"","tags":null,"title":"Auto7zip","uri":"/posts/auto7zip/"},{"content":" 前段时间白嫖了一个 域名 ，暑假有时间了赶紧物尽其用，于是花了一天的时间重新建了个站（其实我很久之前就用过 hexo 无脑建站，但最近发现了一个特别喜欢的Hugo主题 MemE ）\n 简略步骤 Hugo Quick Start  在 wsl 下装 Hugo  1  $ sudo apt install hugo   TL;DR 一下 Hugo 的基础命令  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  $ tldr hugo hugo Template-based static site generator. Uses modules, components, and themes.More information: https://gohugo.io. - Create a new Hugo site: hugo new site {{path/to/site}} - Create a new Hugo theme (themes may also be downloaded from https://themes.gohugo.io/): hugo new theme {{theme_name}} - Create a new page: hugo new {{section_name}}/{{filename}} - Build a site to the ./public/ directory: hugo - Build a site including pages that are marked as a \"draft\": hugo --buildDrafts - Build a site to a given directory: hugo --destination {{path/to/destination}} - Build a site, start up a webserver to serve it, and automatically reload when pages are edited: hugo server   新建站点  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $ hugo new site loomt Congratulations! Your new Hugo site is created in /home/loomt/temp/loomt. Just a few more steps and you are ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. $ cd loomt $ tree . ├── archetypes │ └── default.md ├── config.toml ├── content ├── data ├── layouts ├── static └── themes   配置主题  $ git init # 将皮肤作为submodule添加，以便更新 $ git submodule add https://github.com/reuixiy/hugo-theme-meme.git themes/meme # MeME，很喜欢的一个主题 $ git submodule add https://github.com/martignoni/hugo-notice.git themes/hugo-notice # hugo-notice，插件主题（很轻，开箱即用） $ rm config.toml \u0026\u0026 cp themes/meme/config-examples/zh-cn/config.toml config.toml #覆盖配置文件 发布文章  1 2  $ hugo new posts/HelloWorld.md #会在centent下面创建markdown文件，可以直接去编辑 Content \"/home/loomt/temp/loomt/content/posts/HelloWorld.md\" created   运行本地服务  1  $ hugo server -D --verbose # 在本地运行 -D是渲染草稿 --verbose显示详细输出   目前已经完成基本配置，可以访问运行在本机的站点了 🥳\n接下来还可以将网站部署到 Github Page，Vercel 或者 Netlify 等免费的静态资源托管商。\nHugo 部署到 Github Page Hugo 是一个网站构建工具，hugo命令生成的 public 文件夹存放的是静态的部署页面，我们只需要将其放在 Github Page 中即可。建议开两个仓库，一个仓库用于存放根目录，另一个用于存放./public 文件夹的内容，以便被 Github Page 部署。\n 因为根目录可能有敏感信息和暂时不希望公开的草稿，又为了让其得到有效的版本控制，可以开一个私有仓库存放根目录，\n而 publishDir(./pubic) 作为输出的静态页面，则适合放在公开的仓库 而且 Github Page 不公开没法白嫖\n 默认看到这里的同学已经建好了仓库，并完成了仓库的初始化和配置 🤗\n下面假设更新了文章，需要同步到两个仓库。\n1 2 3 4 5 6 7 8  $ hugo --gc --cleanDestinationDir # 生成静态站点到./public的同时 清除缓存和静态站点用不着的文件 $ git add . $ git commit -m \"update source code\" $ git push $ cd public $ git add . $ git commit -m \"update Github Page\" $ git push   是不是感觉要 push 两次非常麻烦，可以写一个 push.sh 来简化操作，还可以加个 Github Actions，简化每次更新站点的步骤，具体可阅读 GitHub Actions 官方文档，actions-gh-pages 以及 reuixiy 的博客 。\n自动化部署   如果源码仓库和 Github Page 仓库都是公有的话可以阅读 actions-gh-pages 进行简单的配置。\n  如果源码仓库是私有的，Github Page 仓库是公开的话，可以参考以下配置方案。\n   配置公钥和私钥到仓库  需要生成 SSH key pair 以获取源码仓库对 Github Page 仓库修改的权限。\n$ mkdir -p ~/.ssh/blog $ cd ~/.ssh/blog $ ssh-keygen -t rsa -b 4096 -C \"yourname@users.noreply.github.com\" # 注意：不要无脑回车，最好开一个文件夹存公钥私钥，不然会覆盖掉以前的  id_rsa（私钥）  前往 Github Page 仓库，Settings \u003e Deploy Keys \u003e Add deploy key。\n需要勾选 Allow write access。\n id_rsa.pub （公钥）  前往源码仓库，Settings \u003e Secrets \u003e Actions \u003e New repository secret。\nName 需要设为 ACTIONS_DEPLOY_KEY\n新建 Workflow 配置文件  下面粘一下我的配置方案\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  # .github/workflows/build.ymlname:Hugo automated deploymenton:push:branches:- main # Set a branch name to trigger deploymentjobs:deploy:runs-on:ubuntu-latestpermissions:contents:writeconcurrency:group:${{ github.workflow }}-${{ github.ref }}steps:- uses:actions/checkout@v3with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:'0.92.2'extended:true- name:Buildrun:hugo --gc --minify# - name: Deploy# uses: peaceiris/actions-gh-pages@v3# # If you're changing the branch from main,# # also change the `main` in `refs/heads/main`# # below accordingly.# if: ${{ github.ref == 'refs/heads/main' }}# with:# github_token: ${{ secrets.GITHUB_TOKEN }}# publish_dir: ./public- name:Deploy # 此处需要按照自己实际修改uses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}external_repository:loomts/loomts.github.iopublish_branch: main # default:gh-pagespublish_dir:./public  推送到 Github  1 2 3  $ git add . $ git commit -m \"setup auto deploy\" $ git push   打开你的源码仓库页面，点击 Actions 查看日志，顺利的话已经搞定了，以后每次 git push Github Workflow 都会自动帮你更新网站了。\nGithub Page 绑定自定义域名 假设已经有了域名，还需要在域名的 DNS 服务商那里加一个 CNAME （用于 dns 跳转）。\n   name type value     www CNAME loomts.github.io    一段时间后，回到 Github Page 仓库，在 Settings \u003e Pages \u003e Custom domain 处填上自己的域名，等待几小时生成证书，然后勾选 Enforce HTTPS。\n还要记得添加 your domain 到 static/CNAME ，以生成到静态文件。\n1  $ echo \"your domain\" \u003e static/CNAME    Custom domains are stored in a CNAME file in the root of your publishing source. You can add or update this file through your repository settings or manually. For more information, see \" Managing a custom domain for your GitHub Pages site .\" ——Github Docs\n Hugo 部署到 Vercel Vercel 可以看作是结合了 Github Page 还有 Github Actions 的用于前端框架和静态站点管的平台，直接导入 Github 仓库即可部署，感觉配置起来比 Github Action 无脑很多，很适合我，所以我已经放弃 Github Action，全面转为 Vercel 了。需要注意的是注册域名的时候要去域名注册商改一下 DNS 服务器，或者每个站点都添加一次 A 记录。\nHugo 个性化配置 皮肤配置 可以根据皮肤作者的文档改变皮肤的各种 feature，如 MeME 的 config.toml example\n.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative} 提示\nconfig.toml 的 baseURL 要加 https:// ，否则生成的静态页面 css 和 js 加载会出问题。\n 自定义 CSS 和 JS  利用 hugo 的替换规则  当你需要更改某个页面的生成规则（包括 CSS 和 JS），你可以将 themes/your-theme 里面的东西复制一份到你的根目录，然后爽改逻辑，hugo 生成静态页面时在同等情况下会优先用你根目录下的文件。\n如果你想要自己新建一个 js 或者 css 文件，可以看hugo-pipes，但如果你不打算做一个开源主题，无脑在 html 文件里面堆 style 和 script 是能跑的选择！  比如，我有这样一个需求：在 Wiki 页面分层次显示我的笔记，但又不让笔记内容在主页面显示，并且 Wiki 页需要按照文件夹的内部结构展示，那就用categories的方式组织 content/wiki 的内容，仅需要改一下 MeME 主题 tree-sections 的内容，并配置一下 config.toml 即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  \u003cmain class=\"main list\" id=\"main\"\u003e \u003cdiv class=\"main-inner\"\u003e \u003cdiv class=\"content categories\"\u003e {{ if .Site.Params.displayListTitle }} \u003ch1 class=\"list-title\"\u003e {{ \"Wiki\"}} \u003c/h1\u003e \u003cdiv\u003e 存点笔记，仅作参考😶‍🌫️ \u003c/div\u003e {{ end }} \u003cdiv class=\"tree\"\u003e \u003cul class=\"list-categories\" style=\"display: block;\"\u003e {{ partial \"utils/tree-sections.html\" . }} {{ $sections := .Scratch.Get \"sections\" }} {{ $pages := .Scratch.Get \"pages\" }} {{ range $index, $page := $pages }} {{ $depth := (len (split (strings.TrimPrefix \"/\" $page) \"/\")) }} {{ with $.Site.GetPage $page }} {{ $linkTarget := .}} {{ $depthPrev := 0 }} {{ if ge $index 1 }} {{ $pagePrev := index $pages (sub $index 1) }} {{ $depthPrev = len (split (strings.TrimPrefix \"/\" $pagePrev) \"/\") }} {{ end }} {{ $depthNext := 0 }} {{ if lt $index (sub (len $pages) 1) }} {{ $pageNext := index $pages (add $index 1) }} {{ $depthNext = len (split (strings.TrimPrefix \"/\" $pageNext) \"/\") }} {{ end }} {{ if or (le $depth $depthPrev) (eq $index 0) }} \u003cli\u003e {{ end }} {{ if and (gt $depth $depthPrev) (ne $index 0) }} \u003cul class=\"list-categories\" style=\"display: block;\"\u003e \u003cli\u003e {{ end }} {{ $name := index $sections $index }} \u003cdiv class=\"category-item\"\u003e {{ .LinkTitle | default $name}} {{ if $.Site.Params.displayPostsCount }} {{ $sectionPage := .CurrentSection }} {{$.Scratch.Delete \"pages\" }} {{ range $.Site.RegularPages }} {{ if (.IsDescendant $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end}} {{ end }} {{ $pages := $.Scratch.Get \"pages\"}} \u003cspan class=\"category-count\"\u003e {{printf \"(%d)\" (len $pages)}} \u003c/span\u003e {{ end }} \u003c/div\u003e {{ if $.Site.Params.displayPosts }} {{ $sectionPage := .CurrentSection }} {{ $.Scratch.Delete \"pages\"}} {{ range $.Site.RegularPages }} {{ if (.InSection $sectionPage)}} {{ $.Scratch.Add \"pages\" (slice .) }} {{ end }} {{ end }} {{ $pages := $.Scratch.Get \"pages\" }} {{ partial \"utils/limit-tree-posts.html\" (dict \"$\" $ \"pages\" $pages \"linkTarget\" $linkTarget) }} {{ end }} {{ if and (gt $depth $depthNext) (ne $index (sub (len $pages) 1)) }} {{ range seq (sub $depth $depthNext) }} {{ if le . (sub $depth $depthNext) }} \u003c/li\u003e \u003c/ul\u003e {{ end }} {{ end }} {{ end }} {{ if ge $depth $depthNext }} \u003c/li\u003e {{ end }} {{ end }} {{ end }} \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/main\u003e \u003cscript\u003e let lis = document.querySelectorAll(\"ul.list-categories \u003e li\"); lis.forEach(li =\u003e { li.querySelector(\".category-item\").addEventListener(\"click\", event =\u003e { event.stopPropagation(); // 阻止事件冒泡  let sonul = li.querySelector(\"ul\"); sonul.style.display = sonul.style.display === \"block\" ? \"none\" : \"block\"; if (sonul.nextElementSibling) { sonul.nextElementSibling.style.display = sonul.nextElementSibling.style.display === \"block\" ? \"none\" : \"block\"; } }); }) \u003c/script\u003e   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  [menu] ## 菜单栏 [[menu.main]] pageref = \"/posts/\" name = \"Posts\" weight = 2 pre = \"internal\" post = \"archive\" [[menu.main]] pageref = \"/tags/\" name = \"Tags\" weight = 4 pre = \"internal\" post = \"tags\" [[menu.main]] pageref = \"/about/\" name = \"About\" weight = 5 pre = \"internal\" post = \"user-circle\" [[menu.main]] # add wiki page pageref = \"/wiki/\" name = \"Wiki\" weight = 6 pre = \"internal\" post = \"wiki\" [[menu.main]] weight = 7 identifier = \"theme-switcher\" [[menu.main]] weight = 8 identifier = \"lang-switcher\" [[menu.main]] weight = 9 identifier = \"search\" post = \"search\"   Hugo + Algolia search Algolia 可以提供 AI 搜索服务，但需要在更新站点时用 POST 请求上传 algolia.json(站点信息)给 Algolia，以帮助 Algolia 实现搜索服务。按照要求新建站点以及配置 api 即可，上传 algolia.json 可以使用hugo-algolia。因为MeME主题有一定的algolia search支持，下面仅给出上传algolia.json方面的配置。\n1  $ npm install hugo-algolia   但 hugo-algolia 的 toml 解析在我这里好像有点问题，可能是 config.toml 的配置已经太乱了，无法优雅地解决\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ hugo-algolia -s -t --config config.toml JSON index file was created in public/algolia.json /usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50 throw new errors.AlgoliaSearchError('Please provide an application ID. ' + usage); ^ AlgoliaSearchError: Please provide an application ID. Usage: algoliasearch(applicationID, apiKey, opts) at AlgoliaSearchNodeJS.AlgoliaSearchCore (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearchCore.js:50:11) at AlgoliaSearchNodeJS.AlgoliaSearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/AlgoliaSearch.js:11:21) at AlgoliaSearchNodeJS.AlgoliaSearchServer (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/AlgoliaSearchServer.js:17:17) at new AlgoliaSearchNodeJS (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:83:23) at algoliasearch (/usr/local/lib/node_modules/hugo-algolia/node_modules/algoliasearch/src/server/builds/node.js:68:10) at HugoAlgolia.HugoAlgolia.sendIndex (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:184:20) at HugoAlgolia.HugoAlgolia.index (/usr/local/lib/node_modules/hugo-algolia/lib/index.js:122:12) at Object.\u003canonymous\u003e (/usr/local/lib/node_modules/hugo-algolia/bin/index.js:23:26) at Module._compile (internal/modules/cjs/loader.js:999:30) at Object.Module._extensions..js (internal/modules/cjs/loader.js:1027:10)   无奈之下新建了一个 config.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13  ---baseurl:\"/\"DefaultContentLanguage:\"zh-cn\"hasCJKLanguage:truelanguageCode:\"zh-cn\"title:\"loomt's Blog\"theme:\"MeME\"metaDataFormat:\"yaml\"algolia:index:\"your index\"key:\"your admin key\"appID:\"your appID\"---  1 2 3  $ hugo-algolia -s JSON index file was created in public/algolia.json { updatedAt: '2023-01-12T14:40:31.454Z', taskID: 173970040001 }    用 Vercel 还有一个原因是白嫖国外的服务器不用备案😭\n reference\nhttps://gohugo.io/getting-started\nhttps://blog.aozaki.cc/blog/hugo-deployment-debugging\nhttps://io-oi.me/tech/hugo-vs-hexo\nhttps://github.com/MunifTanjim/minimo/issues/189\nhttps://zenlian.github.io/posts/tools/github-actions-hugo\nhttps://github.com/peaceiris/actions-gh-pages\nhttps://gohugo.io/content-management/sections\nhttps://gohugo.io/templates\nhttps://gohugo.io/hugo-pipes\n","description":"","tags":["Github Page","建站"],"title":"建站","uri":"/posts/%E5%BB%BA%E7%AB%99/"}]